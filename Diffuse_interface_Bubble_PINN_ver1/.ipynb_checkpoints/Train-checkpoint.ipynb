{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "423f86f8-8eb5-43eb-b349-59e693608263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training PDE\n",
      "Executing Pass 1\n",
      "Current Final Time: 0.01 Current Learning Rate:  0.0005\n",
      "Iteration: 200 \tTotal Loss: tensor(9775965.)\n",
      "\tBC Loss:  tensor(7.9600) \tNS PDE Loss:  tensor(9775957.)\n",
      "Iteration: 400 \tTotal Loss: tensor(2748577.7500)\n",
      "\tBC Loss:  tensor(9.0298) \tNS PDE Loss:  tensor(2748568.7500)\n",
      "Iteration: 600 \tTotal Loss: tensor(1634478.1250)\n",
      "\tBC Loss:  tensor(9.3201) \tNS PDE Loss:  tensor(1634468.7500)\n",
      "Iteration: 800 \tTotal Loss: tensor(1243754.6250)\n",
      "\tBC Loss:  tensor(9.4868) \tNS PDE Loss:  tensor(1243745.1250)\n",
      "Iteration: 1000 \tTotal Loss: tensor(1057625.5000)\n",
      "\tBC Loss:  tensor(9.6364) \tNS PDE Loss:  tensor(1057615.8750)\n",
      "Iteration: 1200 \tTotal Loss: tensor(930962.5000)\n",
      "\tBC Loss:  tensor(9.7408) \tNS PDE Loss:  tensor(930952.7500)\n",
      "Iteration: 1400 \tTotal Loss: tensor(851521.3125)\n",
      "\tBC Loss:  tensor(9.8135) \tNS PDE Loss:  tensor(851511.5000)\n",
      "Iteration: 1600 \tTotal Loss: tensor(734953.6875)\n",
      "\tBC Loss:  tensor(9.9020) \tNS PDE Loss:  tensor(734943.8125)\n",
      "Iteration: 1800 \tTotal Loss: tensor(684679.3125)\n",
      "\tBC Loss:  tensor(9.9746) \tNS PDE Loss:  tensor(684669.3125)\n",
      "Iteration: 2000 \tTotal Loss: tensor(653343.)\n",
      "\tBC Loss:  tensor(10.0334) \tNS PDE Loss:  tensor(653332.9375)\n",
      "Iteration: 2200 \tTotal Loss: tensor(631161.6875)\n",
      "\tBC Loss:  tensor(10.0946) \tNS PDE Loss:  tensor(631151.5625)\n",
      "Iteration: 2400 \tTotal Loss: tensor(606966.0625)\n",
      "\tBC Loss:  tensor(10.1445) \tNS PDE Loss:  tensor(606955.9375)\n",
      "Iteration: 2600 \tTotal Loss: tensor(587394.1875)\n",
      "\tBC Loss:  tensor(10.1931) \tNS PDE Loss:  tensor(587384.)\n",
      "Iteration: 2800 \tTotal Loss: tensor(576967.1250)\n",
      "\tBC Loss:  tensor(10.2487) \tNS PDE Loss:  tensor(576956.8750)\n",
      "Iteration: 3000 \tTotal Loss: tensor(529798.)\n",
      "\tBC Loss:  tensor(10.3021) \tNS PDE Loss:  tensor(529787.6875)\n",
      "Iteration: 3200 \tTotal Loss: tensor(503492.8438)\n",
      "\tBC Loss:  tensor(10.3926) \tNS PDE Loss:  tensor(503482.4375)\n",
      "Iteration: 3400 \tTotal Loss: tensor(477498.4688)\n",
      "\tBC Loss:  tensor(10.4935) \tNS PDE Loss:  tensor(477487.9688)\n",
      "Iteration: 3600 \tTotal Loss: tensor(443155.8750)\n",
      "\tBC Loss:  tensor(10.6651) \tNS PDE Loss:  tensor(443145.2188)\n",
      "Iteration: 3800 \tTotal Loss: tensor(412604.7188)\n",
      "\tBC Loss:  tensor(10.8083) \tNS PDE Loss:  tensor(412593.9062)\n",
      "Iteration: 4000 \tTotal Loss: tensor(394840.4688)\n",
      "\tBC Loss:  tensor(10.9528) \tNS PDE Loss:  tensor(394829.5312)\n",
      "Iteration: 4200 \tTotal Loss: tensor(369744.4375)\n",
      "\tBC Loss:  tensor(11.0921) \tNS PDE Loss:  tensor(369733.3438)\n",
      "Iteration: 4400 \tTotal Loss: tensor(349036.1250)\n",
      "\tBC Loss:  tensor(11.2583) \tNS PDE Loss:  tensor(349024.8750)\n",
      "Iteration: 4600 \tTotal Loss: tensor(340971.2500)\n",
      "\tBC Loss:  tensor(11.4482) \tNS PDE Loss:  tensor(340959.8125)\n",
      "Iteration: 4800 \tTotal Loss: tensor(325932.4062)\n",
      "\tBC Loss:  tensor(11.5840) \tNS PDE Loss:  tensor(325920.8125)\n",
      "Iteration: 5000 \tTotal Loss: tensor(308163.5938)\n",
      "\tBC Loss:  tensor(11.6892) \tNS PDE Loss:  tensor(308151.9062)\n",
      "Iteration: 5200 \tTotal Loss: tensor(315287.1875)\n",
      "\tBC Loss:  tensor(11.7699) \tNS PDE Loss:  tensor(315275.4062)\n",
      "Iteration: 5400 \tTotal Loss: tensor(295361.1250)\n",
      "\tBC Loss:  tensor(11.8531) \tNS PDE Loss:  tensor(295349.2812)\n",
      "Iteration: 5600 \tTotal Loss: tensor(283071.4688)\n",
      "\tBC Loss:  tensor(11.9191) \tNS PDE Loss:  tensor(283059.5625)\n",
      "Iteration: 5800 \tTotal Loss: tensor(271190.0312)\n",
      "\tBC Loss:  tensor(12.0009) \tNS PDE Loss:  tensor(271178.0312)\n",
      "Iteration: 6000 \tTotal Loss: tensor(272205.5312)\n",
      "\tBC Loss:  tensor(12.0194) \tNS PDE Loss:  tensor(272193.5000)\n",
      "Iteration: 6200 \tTotal Loss: tensor(258100.3594)\n",
      "\tBC Loss:  tensor(12.0153) \tNS PDE Loss:  tensor(258088.3438)\n",
      "Iteration: 6400 \tTotal Loss: tensor(295451.6562)\n",
      "\tBC Loss:  tensor(12.0722) \tNS PDE Loss:  tensor(295439.5938)\n",
      "Iteration: 6600 \tTotal Loss: tensor(245022.9688)\n",
      "\tBC Loss:  tensor(12.1062) \tNS PDE Loss:  tensor(245010.8594)\n",
      "Iteration: 6800 \tTotal Loss: tensor(234471.2031)\n",
      "\tBC Loss:  tensor(12.1427) \tNS PDE Loss:  tensor(234459.0625)\n",
      "Iteration: 7000 \tTotal Loss: tensor(229853.7188)\n",
      "\tBC Loss:  tensor(12.2192) \tNS PDE Loss:  tensor(229841.5000)\n",
      "Iteration: 7200 \tTotal Loss: tensor(222361.2969)\n",
      "\tBC Loss:  tensor(12.3039) \tNS PDE Loss:  tensor(222349.)\n",
      "Iteration: 7400 \tTotal Loss: tensor(218913.9062)\n",
      "\tBC Loss:  tensor(12.3200) \tNS PDE Loss:  tensor(218901.5938)\n",
      "Iteration: 7600 \tTotal Loss: tensor(212323.1719)\n",
      "\tBC Loss:  tensor(12.3932) \tNS PDE Loss:  tensor(212310.7812)\n",
      "Iteration: 7800 \tTotal Loss: tensor(202705.6875)\n",
      "\tBC Loss:  tensor(12.4478) \tNS PDE Loss:  tensor(202693.2344)\n",
      "Iteration: 8000 \tTotal Loss: tensor(197289.7656)\n",
      "\tBC Loss:  tensor(12.5067) \tNS PDE Loss:  tensor(197277.2656)\n",
      "Iteration: 8200 \tTotal Loss: tensor(225366.1250)\n",
      "\tBC Loss:  tensor(12.5342) \tNS PDE Loss:  tensor(225353.5938)\n",
      "Iteration: 8400 \tTotal Loss: tensor(204873.2656)\n",
      "\tBC Loss:  tensor(12.5971) \tNS PDE Loss:  tensor(204860.6719)\n",
      "Iteration: 8600 \tTotal Loss: tensor(186804.6562)\n",
      "\tBC Loss:  tensor(12.6388) \tNS PDE Loss:  tensor(186792.0156)\n",
      "Iteration: 8800 \tTotal Loss: tensor(181223.5156)\n",
      "\tBC Loss:  tensor(12.6865) \tNS PDE Loss:  tensor(181210.8281)\n",
      "Iteration: 9000 \tTotal Loss: tensor(215862.9688)\n",
      "\tBC Loss:  tensor(12.7522) \tNS PDE Loss:  tensor(215850.2188)\n",
      "Iteration: 9200 \tTotal Loss: tensor(173041.6094)\n",
      "\tBC Loss:  tensor(12.8123) \tNS PDE Loss:  tensor(173028.7969)\n",
      "Iteration: 9400 \tTotal Loss: tensor(178249.3750)\n",
      "\tBC Loss:  tensor(12.8873) \tNS PDE Loss:  tensor(178236.4844)\n",
      "Iteration: 9600 \tTotal Loss: tensor(164387.8438)\n",
      "\tBC Loss:  tensor(12.9055) \tNS PDE Loss:  tensor(164374.9375)\n",
      "Iteration: 9800 \tTotal Loss: tensor(156005.8281)\n",
      "\tBC Loss:  tensor(12.9779) \tNS PDE Loss:  tensor(155992.8438)\n",
      "Iteration: 10000 \tTotal Loss: tensor(156581.9844)\n",
      "\tBC Loss:  tensor(13.0465) \tNS PDE Loss:  tensor(156568.9375)\n",
      "Iteration: 10200 \tTotal Loss: tensor(157520.1562)\n",
      "\tBC Loss:  tensor(13.1196) \tNS PDE Loss:  tensor(157507.0312)\n",
      "Iteration: 10400 \tTotal Loss: tensor(154412.2656)\n",
      "\tBC Loss:  tensor(13.1986) \tNS PDE Loss:  tensor(154399.0625)\n",
      "Iteration: 10600 \tTotal Loss: tensor(146334.5312)\n",
      "\tBC Loss:  tensor(13.2881) \tNS PDE Loss:  tensor(146321.2500)\n",
      "Iteration: 10800 \tTotal Loss: tensor(147437.4375)\n",
      "\tBC Loss:  tensor(13.3477) \tNS PDE Loss:  tensor(147424.0938)\n",
      "Iteration: 11000 \tTotal Loss: tensor(173285.7500)\n",
      "\tBC Loss:  tensor(13.4473) \tNS PDE Loss:  tensor(173272.2969)\n",
      "Iteration: 11200 \tTotal Loss: tensor(140512.3906)\n",
      "\tBC Loss:  tensor(13.5047) \tNS PDE Loss:  tensor(140498.8906)\n",
      "Iteration: 11400 \tTotal Loss: tensor(145333.3594)\n",
      "\tBC Loss:  tensor(13.5910) \tNS PDE Loss:  tensor(145319.7656)\n",
      "Iteration: 11600 \tTotal Loss: tensor(148142.9688)\n",
      "\tBC Loss:  tensor(13.6355) \tNS PDE Loss:  tensor(148129.3281)\n",
      "Iteration: 11800 \tTotal Loss: tensor(133369.8906)\n",
      "\tBC Loss:  tensor(13.6952) \tNS PDE Loss:  tensor(133356.2031)\n",
      "Iteration: 12000 \tTotal Loss: tensor(131939.4531)\n",
      "\tBC Loss:  tensor(13.7710) \tNS PDE Loss:  tensor(131925.6875)\n",
      "Iteration: 12200 \tTotal Loss: tensor(128053.0938)\n",
      "\tBC Loss:  tensor(13.8372) \tNS PDE Loss:  tensor(128039.2578)\n",
      "Iteration: 12400 \tTotal Loss: tensor(136278.6875)\n",
      "\tBC Loss:  tensor(13.8900) \tNS PDE Loss:  tensor(136264.7969)\n",
      "Iteration: 12600 \tTotal Loss: tensor(124112.0703)\n",
      "\tBC Loss:  tensor(13.9338) \tNS PDE Loss:  tensor(124098.1328)\n",
      "Iteration: 12800 \tTotal Loss: tensor(126640.0234)\n",
      "\tBC Loss:  tensor(13.9836) \tNS PDE Loss:  tensor(126626.0391)\n",
      "Iteration: 13000 \tTotal Loss: tensor(123203.5391)\n",
      "\tBC Loss:  tensor(14.0359) \tNS PDE Loss:  tensor(123189.5000)\n",
      "Iteration: 13200 \tTotal Loss: tensor(119674.6797)\n",
      "\tBC Loss:  tensor(14.1061) \tNS PDE Loss:  tensor(119660.5703)\n",
      "Iteration: 13400 \tTotal Loss: tensor(121899.9375)\n",
      "\tBC Loss:  tensor(14.1937) \tNS PDE Loss:  tensor(121885.7422)\n",
      "Iteration: 13600 \tTotal Loss: tensor(115331.8516)\n",
      "\tBC Loss:  tensor(14.2258) \tNS PDE Loss:  tensor(115317.6250)\n",
      "Iteration: 13800 \tTotal Loss: tensor(112867.1953)\n",
      "\tBC Loss:  tensor(14.2653) \tNS PDE Loss:  tensor(112852.9297)\n",
      "Iteration: 14000 \tTotal Loss: tensor(112803.4062)\n",
      "\tBC Loss:  tensor(14.3104) \tNS PDE Loss:  tensor(112789.0938)\n",
      "Iteration: 14200 \tTotal Loss: tensor(108291.6016)\n",
      "\tBC Loss:  tensor(14.3877) \tNS PDE Loss:  tensor(108277.2109)\n",
      "Iteration: 14400 \tTotal Loss: tensor(113693.3672)\n",
      "\tBC Loss:  tensor(14.4186) \tNS PDE Loss:  tensor(113678.9453)\n",
      "Iteration: 14600 \tTotal Loss: tensor(133281.5938)\n",
      "\tBC Loss:  tensor(14.4515) \tNS PDE Loss:  tensor(133267.1406)\n",
      "Iteration: 14800 \tTotal Loss: tensor(106375.1094)\n",
      "\tBC Loss:  tensor(14.4865) \tNS PDE Loss:  tensor(106360.6250)\n",
      "Iteration: 15000 \tTotal Loss: tensor(106173.6562)\n",
      "\tBC Loss:  tensor(14.5620) \tNS PDE Loss:  tensor(106159.0938)\n",
      "Iteration: 15200 \tTotal Loss: tensor(103983.7891)\n",
      "\tBC Loss:  tensor(14.5596) \tNS PDE Loss:  tensor(103969.2266)\n",
      "Iteration: 15400 \tTotal Loss: tensor(102538.5156)\n",
      "\tBC Loss:  tensor(14.6177) \tNS PDE Loss:  tensor(102523.8984)\n",
      "Iteration: 15600 \tTotal Loss: tensor(149471.9844)\n",
      "\tBC Loss:  tensor(14.7045) \tNS PDE Loss:  tensor(149457.2812)\n",
      "Iteration: 15800 \tTotal Loss: tensor(107701.0703)\n",
      "\tBC Loss:  tensor(14.7233) \tNS PDE Loss:  tensor(107686.3438)\n",
      "Iteration: 16000 \tTotal Loss: tensor(140157.7969)\n",
      "\tBC Loss:  tensor(14.7551) \tNS PDE Loss:  tensor(140143.0469)\n",
      "Iteration: 16200 \tTotal Loss: tensor(96146.7500)\n",
      "\tBC Loss:  tensor(14.7873) \tNS PDE Loss:  tensor(96131.9609)\n",
      "Iteration: 16400 \tTotal Loss: tensor(95248.6484)\n",
      "\tBC Loss:  tensor(14.8402) \tNS PDE Loss:  tensor(95233.8047)\n",
      "Iteration: 16600 \tTotal Loss: tensor(97665.6953)\n",
      "\tBC Loss:  tensor(14.9135) \tNS PDE Loss:  tensor(97650.7812)\n",
      "Iteration: 16800 \tTotal Loss: tensor(94493.1094)\n",
      "\tBC Loss:  tensor(14.9242) \tNS PDE Loss:  tensor(94478.1875)\n",
      "Iteration: 17000 \tTotal Loss: tensor(92138.3516)\n",
      "\tBC Loss:  tensor(14.9229) \tNS PDE Loss:  tensor(92123.4297)\n",
      "Iteration: 17200 \tTotal Loss: tensor(88049.1719)\n",
      "\tBC Loss:  tensor(14.9569) \tNS PDE Loss:  tensor(88034.2188)\n",
      "Iteration: 17400 \tTotal Loss: tensor(86194.8828)\n",
      "\tBC Loss:  tensor(15.0539) \tNS PDE Loss:  tensor(86179.8281)\n",
      "Iteration: 17600 \tTotal Loss: tensor(86423.6172)\n",
      "\tBC Loss:  tensor(15.1474) \tNS PDE Loss:  tensor(86408.4688)\n",
      "Iteration: 17800 \tTotal Loss: tensor(82867.8906)\n",
      "\tBC Loss:  tensor(15.1704) \tNS PDE Loss:  tensor(82852.7188)\n",
      "Iteration: 18000 \tTotal Loss: tensor(82368.6719)\n",
      "\tBC Loss:  tensor(15.2521) \tNS PDE Loss:  tensor(82353.4219)\n",
      "Iteration: 18200 \tTotal Loss: tensor(79430.5234)\n",
      "\tBC Loss:  tensor(15.2614) \tNS PDE Loss:  tensor(79415.2656)\n",
      "Iteration: 18400 \tTotal Loss: tensor(76873.4375)\n",
      "\tBC Loss:  tensor(15.3023) \tNS PDE Loss:  tensor(76858.1328)\n",
      "Iteration: 18600 \tTotal Loss: tensor(86693.0938)\n",
      "\tBC Loss:  tensor(15.3479) \tNS PDE Loss:  tensor(86677.7422)\n",
      "Iteration: 18800 \tTotal Loss: tensor(84033.4609)\n",
      "\tBC Loss:  tensor(15.3679) \tNS PDE Loss:  tensor(84018.0938)\n",
      "Iteration: 19000 \tTotal Loss: tensor(75854.3750)\n",
      "\tBC Loss:  tensor(15.4167) \tNS PDE Loss:  tensor(75838.9609)\n",
      "Iteration: 19200 \tTotal Loss: tensor(104464.3594)\n",
      "\tBC Loss:  tensor(15.4573) \tNS PDE Loss:  tensor(104448.8984)\n",
      "Iteration: 19400 \tTotal Loss: tensor(71772.7891)\n",
      "\tBC Loss:  tensor(15.4762) \tNS PDE Loss:  tensor(71757.3125)\n",
      "Iteration: 19600 \tTotal Loss: tensor(70432.4375)\n",
      "\tBC Loss:  tensor(15.5131) \tNS PDE Loss:  tensor(70416.9219)\n",
      "Iteration: 19800 \tTotal Loss: tensor(69129.7734)\n",
      "\tBC Loss:  tensor(15.5482) \tNS PDE Loss:  tensor(69114.2266)\n",
      "Iteration: 20000 \tTotal Loss: tensor(68940.2266)\n",
      "\tBC Loss:  tensor(15.5589) \tNS PDE Loss:  tensor(68924.6641)\n",
      "Iteration: 20200 \tTotal Loss: tensor(72536.6250)\n",
      "\tBC Loss:  tensor(15.5832) \tNS PDE Loss:  tensor(72521.0391)\n",
      "Iteration: 20400 \tTotal Loss: tensor(63811.4336)\n",
      "\tBC Loss:  tensor(15.6033) \tNS PDE Loss:  tensor(63795.8320)\n",
      "Iteration: 20600 \tTotal Loss: tensor(64055.9180)\n",
      "\tBC Loss:  tensor(15.6483) \tNS PDE Loss:  tensor(64040.2695)\n",
      "Iteration: 20800 \tTotal Loss: tensor(65209.1680)\n",
      "\tBC Loss:  tensor(15.6804) \tNS PDE Loss:  tensor(65193.4883)\n",
      "Iteration: 21000 \tTotal Loss: tensor(61799.0078)\n",
      "\tBC Loss:  tensor(15.6860) \tNS PDE Loss:  tensor(61783.3203)\n",
      "Iteration: 21200 \tTotal Loss: tensor(60185.7656)\n",
      "\tBC Loss:  tensor(15.6775) \tNS PDE Loss:  tensor(60170.0898)\n",
      "Iteration: 21400 \tTotal Loss: tensor(57648.0156)\n",
      "\tBC Loss:  tensor(15.6815) \tNS PDE Loss:  tensor(57632.3359)\n",
      "Iteration: 21600 \tTotal Loss: tensor(59919.5547)\n",
      "\tBC Loss:  tensor(15.6916) \tNS PDE Loss:  tensor(59903.8633)\n",
      "Iteration: 21800 \tTotal Loss: tensor(56436.6016)\n",
      "\tBC Loss:  tensor(15.7119) \tNS PDE Loss:  tensor(56420.8906)\n",
      "Iteration: 22000 \tTotal Loss: tensor(54566.5977)\n",
      "\tBC Loss:  tensor(15.7236) \tNS PDE Loss:  tensor(54550.8750)\n",
      "Iteration: 22200 \tTotal Loss: tensor(57521.0820)\n",
      "\tBC Loss:  tensor(15.7453) \tNS PDE Loss:  tensor(57505.3359)\n",
      "Iteration: 22400 \tTotal Loss: tensor(64033.0469)\n",
      "\tBC Loss:  tensor(15.8062) \tNS PDE Loss:  tensor(64017.2422)\n",
      "Iteration: 22600 \tTotal Loss: tensor(53808.9805)\n",
      "\tBC Loss:  tensor(15.8092) \tNS PDE Loss:  tensor(53793.1719)\n",
      "Iteration: 22800 \tTotal Loss: tensor(55234.3789)\n",
      "\tBC Loss:  tensor(15.8417) \tNS PDE Loss:  tensor(55218.5391)\n",
      "Iteration: 23000 \tTotal Loss: tensor(53509.6406)\n",
      "\tBC Loss:  tensor(15.8638) \tNS PDE Loss:  tensor(53493.7773)\n",
      "Iteration: 23200 \tTotal Loss: tensor(51079.1719)\n",
      "\tBC Loss:  tensor(15.8689) \tNS PDE Loss:  tensor(51063.3047)\n",
      "Iteration: 23400 \tTotal Loss: tensor(51496.8867)\n",
      "\tBC Loss:  tensor(15.8781) \tNS PDE Loss:  tensor(51481.0078)\n",
      "Iteration: 23600 \tTotal Loss: tensor(50605.8438)\n",
      "\tBC Loss:  tensor(15.9286) \tNS PDE Loss:  tensor(50589.9141)\n",
      "Iteration: 23800 \tTotal Loss: tensor(48740.1719)\n",
      "\tBC Loss:  tensor(15.9376) \tNS PDE Loss:  tensor(48724.2344)\n",
      "Iteration: 24000 \tTotal Loss: tensor(49457.5703)\n",
      "\tBC Loss:  tensor(15.9084) \tNS PDE Loss:  tensor(49441.6602)\n",
      "Iteration: 24200 \tTotal Loss: tensor(49304.9688)\n",
      "\tBC Loss:  tensor(15.9046) \tNS PDE Loss:  tensor(49289.0625)\n",
      "Iteration: 24400 \tTotal Loss: tensor(51671.3828)\n",
      "\tBC Loss:  tensor(15.8988) \tNS PDE Loss:  tensor(51655.4844)\n",
      "Iteration: 24600 \tTotal Loss: tensor(47937.9883)\n",
      "\tBC Loss:  tensor(15.9189) \tNS PDE Loss:  tensor(47922.0703)\n",
      "Iteration: 24800 \tTotal Loss: tensor(53205.7109)\n",
      "\tBC Loss:  tensor(15.9236) \tNS PDE Loss:  tensor(53189.7891)\n",
      "Iteration: 25000 \tTotal Loss: tensor(47339.5547)\n",
      "\tBC Loss:  tensor(15.9558) \tNS PDE Loss:  tensor(47323.5977)\n",
      "Iteration: 25200 \tTotal Loss: tensor(48014.0117)\n",
      "\tBC Loss:  tensor(15.9533) \tNS PDE Loss:  tensor(47998.0586)\n",
      "Iteration: 25400 \tTotal Loss: tensor(48002.8086)\n",
      "\tBC Loss:  tensor(15.9626) \tNS PDE Loss:  tensor(47986.8477)\n",
      "Iteration: 25600 \tTotal Loss: tensor(46954.2148)\n",
      "\tBC Loss:  tensor(15.9685) \tNS PDE Loss:  tensor(46938.2461)\n",
      "Iteration: 25800 \tTotal Loss: tensor(46479.8711)\n",
      "\tBC Loss:  tensor(16.0235) \tNS PDE Loss:  tensor(46463.8477)\n",
      "Iteration: 26000 \tTotal Loss: tensor(45513.8164)\n",
      "\tBC Loss:  tensor(16.0378) \tNS PDE Loss:  tensor(45497.7773)\n",
      "Iteration: 26200 \tTotal Loss: tensor(46013.6875)\n",
      "\tBC Loss:  tensor(16.0591) \tNS PDE Loss:  tensor(45997.6289)\n",
      "Iteration: 26400 \tTotal Loss: tensor(44557.0586)\n",
      "\tBC Loss:  tensor(16.0927) \tNS PDE Loss:  tensor(44540.9648)\n",
      "Iteration: 26600 \tTotal Loss: tensor(47093.0117)\n",
      "\tBC Loss:  tensor(16.0983) \tNS PDE Loss:  tensor(47076.9141)\n",
      "Iteration: 26800 \tTotal Loss: tensor(42938.7031)\n",
      "\tBC Loss:  tensor(16.1134) \tNS PDE Loss:  tensor(42922.5898)\n",
      "Iteration: 27000 \tTotal Loss: tensor(44486.4453)\n",
      "\tBC Loss:  tensor(16.1168) \tNS PDE Loss:  tensor(44470.3281)\n",
      "Iteration: 27200 \tTotal Loss: tensor(45325.3633)\n",
      "\tBC Loss:  tensor(16.1308) \tNS PDE Loss:  tensor(45309.2344)\n",
      "Iteration: 27400 \tTotal Loss: tensor(56698.9727)\n",
      "\tBC Loss:  tensor(16.1435) \tNS PDE Loss:  tensor(56682.8281)\n",
      "Iteration: 27600 \tTotal Loss: tensor(43457.8984)\n",
      "\tBC Loss:  tensor(16.1480) \tNS PDE Loss:  tensor(43441.7500)\n",
      "Iteration: 27800 \tTotal Loss: tensor(45725.2539)\n",
      "\tBC Loss:  tensor(16.1976) \tNS PDE Loss:  tensor(45709.0547)\n",
      "Iteration: 28000 \tTotal Loss: tensor(42059.3242)\n",
      "\tBC Loss:  tensor(16.2090) \tNS PDE Loss:  tensor(42043.1133)\n",
      "Iteration: 28200 \tTotal Loss: tensor(43081.9648)\n",
      "\tBC Loss:  tensor(16.2265) \tNS PDE Loss:  tensor(43065.7383)\n",
      "Iteration: 28400 \tTotal Loss: tensor(41886.0156)\n",
      "\tBC Loss:  tensor(16.2559) \tNS PDE Loss:  tensor(41869.7578)\n",
      "Iteration: 28600 \tTotal Loss: tensor(42111.7500)\n",
      "\tBC Loss:  tensor(16.2669) \tNS PDE Loss:  tensor(42095.4844)\n",
      "Iteration: 28800 \tTotal Loss: tensor(40459.8203)\n",
      "\tBC Loss:  tensor(16.2791) \tNS PDE Loss:  tensor(40443.5430)\n",
      "Iteration: 29000 \tTotal Loss: tensor(41821.4648)\n",
      "\tBC Loss:  tensor(16.2934) \tNS PDE Loss:  tensor(41805.1719)\n",
      "Iteration: 29200 \tTotal Loss: tensor(39510.5586)\n",
      "\tBC Loss:  tensor(16.3091) \tNS PDE Loss:  tensor(39494.2500)\n",
      "Iteration: 29400 \tTotal Loss: tensor(44382.0156)\n",
      "\tBC Loss:  tensor(16.3341) \tNS PDE Loss:  tensor(44365.6797)\n",
      "Iteration: 29600 \tTotal Loss: tensor(40275.5781)\n",
      "\tBC Loss:  tensor(16.3550) \tNS PDE Loss:  tensor(40259.2227)\n",
      "Iteration: 29800 \tTotal Loss: tensor(38692.8984)\n",
      "\tBC Loss:  tensor(16.3889) \tNS PDE Loss:  tensor(38676.5078)\n",
      "Iteration: 30000 \tTotal Loss: tensor(42951.0039)\n",
      "\tBC Loss:  tensor(16.4297) \tNS PDE Loss:  tensor(42934.5742)\n",
      "Iteration: 30200 \tTotal Loss: tensor(50915.5938)\n",
      "\tBC Loss:  tensor(16.4577) \tNS PDE Loss:  tensor(50899.1367)\n",
      "Iteration: 30400 \tTotal Loss: tensor(46341.8359)\n",
      "\tBC Loss:  tensor(16.4778) \tNS PDE Loss:  tensor(46325.3594)\n",
      "Iteration: 30600 \tTotal Loss: tensor(41090.4492)\n",
      "\tBC Loss:  tensor(16.5031) \tNS PDE Loss:  tensor(41073.9453)\n",
      "Iteration: 30800 \tTotal Loss: tensor(37953.5352)\n",
      "\tBC Loss:  tensor(16.5356) \tNS PDE Loss:  tensor(37937.)\n",
      "Iteration: 31000 \tTotal Loss: tensor(37975.0312)\n",
      "\tBC Loss:  tensor(16.5826) \tNS PDE Loss:  tensor(37958.4492)\n",
      "Iteration: 31200 \tTotal Loss: tensor(37846.6133)\n",
      "\tBC Loss:  tensor(16.5988) \tNS PDE Loss:  tensor(37830.0156)\n",
      "Iteration: 31400 \tTotal Loss: tensor(37363.3125)\n",
      "\tBC Loss:  tensor(16.6093) \tNS PDE Loss:  tensor(37346.7031)\n",
      "Iteration: 31600 \tTotal Loss: tensor(38089.4922)\n",
      "\tBC Loss:  tensor(16.6409) \tNS PDE Loss:  tensor(38072.8516)\n",
      "Iteration: 31800 \tTotal Loss: tensor(38278.2891)\n",
      "\tBC Loss:  tensor(16.6750) \tNS PDE Loss:  tensor(38261.6133)\n",
      "Iteration: 32000 \tTotal Loss: tensor(37541.2148)\n",
      "\tBC Loss:  tensor(16.6850) \tNS PDE Loss:  tensor(37524.5312)\n",
      "Iteration: 32200 \tTotal Loss: tensor(36232.3398)\n",
      "\tBC Loss:  tensor(16.7103) \tNS PDE Loss:  tensor(36215.6289)\n",
      "Iteration: 32400 \tTotal Loss: tensor(36011.0977)\n",
      "\tBC Loss:  tensor(16.7292) \tNS PDE Loss:  tensor(35994.3672)\n",
      "Iteration: 32600 \tTotal Loss: tensor(37936.2383)\n",
      "\tBC Loss:  tensor(16.7444) \tNS PDE Loss:  tensor(37919.4922)\n",
      "Iteration: 32800 \tTotal Loss: tensor(35201.2266)\n",
      "\tBC Loss:  tensor(16.7895) \tNS PDE Loss:  tensor(35184.4375)\n",
      "Iteration: 33000 \tTotal Loss: tensor(36481.1055)\n",
      "\tBC Loss:  tensor(16.8101) \tNS PDE Loss:  tensor(36464.2969)\n",
      "Iteration: 33200 \tTotal Loss: tensor(35959.9531)\n",
      "\tBC Loss:  tensor(16.8311) \tNS PDE Loss:  tensor(35943.1211)\n",
      "Iteration: 33400 \tTotal Loss: tensor(35273.3086)\n",
      "\tBC Loss:  tensor(16.8525) \tNS PDE Loss:  tensor(35256.4570)\n",
      "Iteration: 33600 \tTotal Loss: tensor(34670.0195)\n",
      "\tBC Loss:  tensor(16.8756) \tNS PDE Loss:  tensor(34653.1445)\n",
      "Iteration: 33800 \tTotal Loss: tensor(34136.9297)\n",
      "\tBC Loss:  tensor(16.9145) \tNS PDE Loss:  tensor(34120.0156)\n",
      "Iteration: 34000 \tTotal Loss: tensor(35447.1016)\n",
      "\tBC Loss:  tensor(16.9533) \tNS PDE Loss:  tensor(35430.1484)\n",
      "Iteration: 34200 \tTotal Loss: tensor(34145.5859)\n",
      "\tBC Loss:  tensor(16.9909) \tNS PDE Loss:  tensor(34128.5938)\n",
      "Iteration: 34400 \tTotal Loss: tensor(36460.0117)\n",
      "\tBC Loss:  tensor(16.9979) \tNS PDE Loss:  tensor(36443.0156)\n",
      "Iteration: 34600 \tTotal Loss: tensor(33498.6484)\n",
      "\tBC Loss:  tensor(17.0191) \tNS PDE Loss:  tensor(33481.6289)\n",
      "Iteration: 34800 \tTotal Loss: tensor(34476.3555)\n",
      "\tBC Loss:  tensor(17.0348) \tNS PDE Loss:  tensor(34459.3203)\n",
      "Iteration: 35000 \tTotal Loss: tensor(33559.8008)\n",
      "\tBC Loss:  tensor(17.0610) \tNS PDE Loss:  tensor(33542.7383)\n",
      "Iteration: 35200 \tTotal Loss: tensor(34419.2617)\n",
      "\tBC Loss:  tensor(17.0858) \tNS PDE Loss:  tensor(34402.1758)\n",
      "Iteration: 35400 \tTotal Loss: tensor(33100.0859)\n",
      "\tBC Loss:  tensor(17.1389) \tNS PDE Loss:  tensor(33082.9453)\n",
      "Iteration: 35600 \tTotal Loss: tensor(43844.4297)\n",
      "\tBC Loss:  tensor(17.1513) \tNS PDE Loss:  tensor(43827.2773)\n",
      "Iteration: 35800 \tTotal Loss: tensor(33771.6875)\n",
      "\tBC Loss:  tensor(17.1646) \tNS PDE Loss:  tensor(33754.5234)\n",
      "Iteration: 36000 \tTotal Loss: tensor(32836.9688)\n",
      "\tBC Loss:  tensor(17.1884) \tNS PDE Loss:  tensor(32819.7812)\n",
      "Iteration: 36200 \tTotal Loss: tensor(36360.8125)\n",
      "\tBC Loss:  tensor(17.1845) \tNS PDE Loss:  tensor(36343.6289)\n",
      "Iteration: 36400 \tTotal Loss: tensor(32303.3867)\n",
      "\tBC Loss:  tensor(17.2402) \tNS PDE Loss:  tensor(32286.1465)\n",
      "Iteration: 36600 \tTotal Loss: tensor(33402.9180)\n",
      "\tBC Loss:  tensor(17.2624) \tNS PDE Loss:  tensor(33385.6562)\n",
      "Iteration: 36800 \tTotal Loss: tensor(41418.5742)\n",
      "\tBC Loss:  tensor(17.2831) \tNS PDE Loss:  tensor(41401.2930)\n",
      "Iteration: 37000 \tTotal Loss: tensor(30607.7051)\n",
      "\tBC Loss:  tensor(17.3015) \tNS PDE Loss:  tensor(30590.4043)\n",
      "Iteration: 37200 \tTotal Loss: tensor(31385.0625)\n",
      "\tBC Loss:  tensor(17.2993) \tNS PDE Loss:  tensor(31367.7637)\n",
      "Iteration: 37400 \tTotal Loss: tensor(31776.8789)\n",
      "\tBC Loss:  tensor(17.3358) \tNS PDE Loss:  tensor(31759.5430)\n",
      "Iteration: 37600 \tTotal Loss: tensor(30628.5312)\n",
      "\tBC Loss:  tensor(17.3762) \tNS PDE Loss:  tensor(30611.1543)\n",
      "Iteration: 37800 \tTotal Loss: tensor(33774.0312)\n",
      "\tBC Loss:  tensor(17.3904) \tNS PDE Loss:  tensor(33756.6406)\n",
      "Iteration: 38000 \tTotal Loss: tensor(30458.7012)\n",
      "\tBC Loss:  tensor(17.4124) \tNS PDE Loss:  tensor(30441.2891)\n",
      "Iteration: 38200 \tTotal Loss: tensor(29512.6484)\n",
      "\tBC Loss:  tensor(17.4081) \tNS PDE Loss:  tensor(29495.2402)\n",
      "Iteration: 38400 \tTotal Loss: tensor(32256.6562)\n",
      "\tBC Loss:  tensor(17.3947) \tNS PDE Loss:  tensor(32239.2617)\n",
      "Iteration: 38600 \tTotal Loss: tensor(29262.8633)\n",
      "\tBC Loss:  tensor(17.4104) \tNS PDE Loss:  tensor(29245.4531)\n",
      "Iteration: 38800 \tTotal Loss: tensor(28792.1641)\n",
      "\tBC Loss:  tensor(17.4262) \tNS PDE Loss:  tensor(28774.7383)\n",
      "Iteration: 39000 \tTotal Loss: tensor(29556.2734)\n",
      "\tBC Loss:  tensor(17.4381) \tNS PDE Loss:  tensor(29538.8359)\n",
      "Iteration: 39200 \tTotal Loss: tensor(29491.7324)\n",
      "\tBC Loss:  tensor(17.4620) \tNS PDE Loss:  tensor(29474.2695)\n",
      "Iteration: 39400 \tTotal Loss: tensor(27438.0352)\n",
      "\tBC Loss:  tensor(17.4926) \tNS PDE Loss:  tensor(27420.5430)\n",
      "Iteration: 39600 \tTotal Loss: tensor(29271.2422)\n",
      "\tBC Loss:  tensor(17.5136) \tNS PDE Loss:  tensor(29253.7285)\n",
      "Iteration: 39800 \tTotal Loss: tensor(26426.3477)\n",
      "\tBC Loss:  tensor(17.5356) \tNS PDE Loss:  tensor(26408.8125)\n",
      "Iteration: 40000 \tTotal Loss: tensor(26753.5469)\n",
      "\tBC Loss:  tensor(17.5689) \tNS PDE Loss:  tensor(26735.9785)\n",
      "Iteration: 40200 \tTotal Loss: tensor(27377.2910)\n",
      "\tBC Loss:  tensor(17.5682) \tNS PDE Loss:  tensor(27359.7227)\n",
      "Iteration: 40400 \tTotal Loss: tensor(31403.8418)\n",
      "\tBC Loss:  tensor(17.5819) \tNS PDE Loss:  tensor(31386.2598)\n",
      "Iteration: 40600 \tTotal Loss: tensor(29142.9551)\n",
      "\tBC Loss:  tensor(17.6082) \tNS PDE Loss:  tensor(29125.3477)\n",
      "Iteration: 40800 \tTotal Loss: tensor(26682.8496)\n",
      "\tBC Loss:  tensor(17.6403) \tNS PDE Loss:  tensor(26665.2090)\n",
      "Iteration: 41000 \tTotal Loss: tensor(28020.9629)\n",
      "\tBC Loss:  tensor(17.6548) \tNS PDE Loss:  tensor(28003.3086)\n",
      "Iteration: 41200 \tTotal Loss: tensor(23949.7910)\n",
      "\tBC Loss:  tensor(17.6775) \tNS PDE Loss:  tensor(23932.1133)\n",
      "Iteration: 41400 \tTotal Loss: tensor(25111.2285)\n",
      "\tBC Loss:  tensor(17.6883) \tNS PDE Loss:  tensor(25093.5410)\n",
      "Iteration: 41600 \tTotal Loss: tensor(29616.2305)\n",
      "\tBC Loss:  tensor(17.7123) \tNS PDE Loss:  tensor(29598.5176)\n",
      "Iteration: 41800 \tTotal Loss: tensor(23778.1445)\n",
      "\tBC Loss:  tensor(17.7252) \tNS PDE Loss:  tensor(23760.4199)\n",
      "Iteration: 42000 \tTotal Loss: tensor(25168.0664)\n",
      "\tBC Loss:  tensor(17.7413) \tNS PDE Loss:  tensor(25150.3242)\n",
      "Iteration: 42200 \tTotal Loss: tensor(26908.3613)\n",
      "\tBC Loss:  tensor(17.7699) \tNS PDE Loss:  tensor(26890.5918)\n",
      "Iteration: 42400 \tTotal Loss: tensor(31110.4844)\n",
      "\tBC Loss:  tensor(17.7849) \tNS PDE Loss:  tensor(31092.6992)\n",
      "Iteration: 42600 \tTotal Loss: tensor(23096.9785)\n",
      "\tBC Loss:  tensor(17.8099) \tNS PDE Loss:  tensor(23079.1680)\n",
      "Iteration: 42800 \tTotal Loss: tensor(24090.6113)\n",
      "\tBC Loss:  tensor(17.8257) \tNS PDE Loss:  tensor(24072.7852)\n",
      "Iteration: 43000 \tTotal Loss: tensor(23606.3926)\n",
      "\tBC Loss:  tensor(17.8562) \tNS PDE Loss:  tensor(23588.5371)\n",
      "Iteration: 43200 \tTotal Loss: tensor(22148.0645)\n",
      "\tBC Loss:  tensor(17.8755) \tNS PDE Loss:  tensor(22130.1895)\n",
      "Iteration: 43400 \tTotal Loss: tensor(21795.7148)\n",
      "\tBC Loss:  tensor(17.8916) \tNS PDE Loss:  tensor(21777.8223)\n",
      "Iteration: 43600 \tTotal Loss: tensor(24066.1191)\n",
      "\tBC Loss:  tensor(17.9040) \tNS PDE Loss:  tensor(24048.2148)\n",
      "Iteration: 43800 \tTotal Loss: tensor(32241.6914)\n",
      "\tBC Loss:  tensor(17.9360) \tNS PDE Loss:  tensor(32223.7559)\n",
      "Iteration: 44000 \tTotal Loss: tensor(21614.2090)\n",
      "\tBC Loss:  tensor(17.9795) \tNS PDE Loss:  tensor(21596.2285)\n",
      "Iteration: 44200 \tTotal Loss: tensor(21989.4492)\n",
      "\tBC Loss:  tensor(17.9841) \tNS PDE Loss:  tensor(21971.4648)\n",
      "Iteration: 44400 \tTotal Loss: tensor(24559.6680)\n",
      "\tBC Loss:  tensor(18.0137) \tNS PDE Loss:  tensor(24541.6543)\n",
      "Iteration: 44600 \tTotal Loss: tensor(21932.1855)\n",
      "\tBC Loss:  tensor(18.0380) \tNS PDE Loss:  tensor(21914.1484)\n",
      "Iteration: 44800 \tTotal Loss: tensor(21016.0840)\n",
      "\tBC Loss:  tensor(18.0524) \tNS PDE Loss:  tensor(20998.0312)\n",
      "Iteration: 45000 \tTotal Loss: tensor(22748.7500)\n",
      "\tBC Loss:  tensor(18.0611) \tNS PDE Loss:  tensor(22730.6895)\n",
      "Iteration: 45200 \tTotal Loss: tensor(21499.1484)\n",
      "\tBC Loss:  tensor(18.0991) \tNS PDE Loss:  tensor(21481.0488)\n",
      "Iteration: 45400 \tTotal Loss: tensor(23923.9297)\n",
      "\tBC Loss:  tensor(18.1161) \tNS PDE Loss:  tensor(23905.8145)\n",
      "Iteration: 45600 \tTotal Loss: tensor(22633.7012)\n",
      "\tBC Loss:  tensor(18.1248) \tNS PDE Loss:  tensor(22615.5762)\n",
      "Iteration: 45800 \tTotal Loss: tensor(28061.7266)\n",
      "\tBC Loss:  tensor(18.1368) \tNS PDE Loss:  tensor(28043.5898)\n",
      "Iteration: 46000 \tTotal Loss: tensor(21761.4609)\n",
      "\tBC Loss:  tensor(18.1586) \tNS PDE Loss:  tensor(21743.3027)\n",
      "Iteration: 46200 \tTotal Loss: tensor(20076.2031)\n",
      "\tBC Loss:  tensor(18.1798) \tNS PDE Loss:  tensor(20058.0234)\n",
      "Iteration: 46400 \tTotal Loss: tensor(19509.9453)\n",
      "\tBC Loss:  tensor(18.1901) \tNS PDE Loss:  tensor(19491.7559)\n",
      "Iteration: 46600 \tTotal Loss: tensor(23025.1445)\n",
      "\tBC Loss:  tensor(18.2155) \tNS PDE Loss:  tensor(23006.9297)\n",
      "Iteration: 46800 \tTotal Loss: tensor(23589.3125)\n",
      "\tBC Loss:  tensor(18.2366) \tNS PDE Loss:  tensor(23571.0762)\n",
      "Iteration: 47000 \tTotal Loss: tensor(19805.1582)\n",
      "\tBC Loss:  tensor(18.2766) \tNS PDE Loss:  tensor(19786.8809)\n",
      "Iteration: 47200 \tTotal Loss: tensor(19714.5391)\n",
      "\tBC Loss:  tensor(18.2779) \tNS PDE Loss:  tensor(19696.2617)\n",
      "Iteration: 47400 \tTotal Loss: tensor(24142.0332)\n",
      "\tBC Loss:  tensor(18.2988) \tNS PDE Loss:  tensor(24123.7344)\n",
      "Iteration: 47600 \tTotal Loss: tensor(19299.5293)\n",
      "\tBC Loss:  tensor(18.3221) \tNS PDE Loss:  tensor(19281.2070)\n",
      "Iteration: 47800 \tTotal Loss: tensor(19596.8340)\n",
      "\tBC Loss:  tensor(18.3310) \tNS PDE Loss:  tensor(19578.5039)\n",
      "Iteration: 48000 \tTotal Loss: tensor(19298.1562)\n",
      "\tBC Loss:  tensor(18.3542) \tNS PDE Loss:  tensor(19279.8027)\n",
      "Iteration: 48200 \tTotal Loss: tensor(18951.8984)\n",
      "\tBC Loss:  tensor(18.3857) \tNS PDE Loss:  tensor(18933.5137)\n",
      "Iteration: 48400 \tTotal Loss: tensor(21560.2793)\n",
      "\tBC Loss:  tensor(18.3873) \tNS PDE Loss:  tensor(21541.8926)\n",
      "Iteration: 48600 \tTotal Loss: tensor(21786.7773)\n",
      "\tBC Loss:  tensor(18.4022) \tNS PDE Loss:  tensor(21768.3750)\n",
      "Iteration: 48800 \tTotal Loss: tensor(18581.9023)\n",
      "\tBC Loss:  tensor(18.4150) \tNS PDE Loss:  tensor(18563.4883)\n",
      "Iteration: 49000 \tTotal Loss: tensor(18778.1816)\n",
      "\tBC Loss:  tensor(18.4275) \tNS PDE Loss:  tensor(18759.7539)\n",
      "Iteration: 49200 \tTotal Loss: tensor(21684.3613)\n",
      "\tBC Loss:  tensor(18.4236) \tNS PDE Loss:  tensor(21665.9375)\n",
      "Iteration: 49400 \tTotal Loss: tensor(18778.0078)\n",
      "\tBC Loss:  tensor(18.4488) \tNS PDE Loss:  tensor(18759.5586)\n",
      "Iteration: 49600 \tTotal Loss: tensor(20891.7832)\n",
      "\tBC Loss:  tensor(18.4547) \tNS PDE Loss:  tensor(20873.3281)\n",
      "Iteration: 49800 \tTotal Loss: tensor(21634.6230)\n",
      "\tBC Loss:  tensor(18.4540) \tNS PDE Loss:  tensor(21616.1699)\n",
      "Iteration: 50000 \tTotal Loss: tensor(18590.8574)\n",
      "\tBC Loss:  tensor(18.4846) \tNS PDE Loss:  tensor(18572.3730)\n",
      "Current Final Time: 0.1 Current Learning Rate:  0.0005\n",
      "Iteration: 200 \tTotal Loss: tensor(34979.1523)\n",
      "\tBC Loss:  tensor(19.4339) \tNS PDE Loss:  tensor(34959.7188)\n",
      "Iteration: 400 \tTotal Loss: tensor(32927.8242)\n",
      "\tBC Loss:  tensor(19.8196) \tNS PDE Loss:  tensor(32908.0039)\n",
      "Iteration: 600 \tTotal Loss: tensor(27612.5195)\n",
      "\tBC Loss:  tensor(20.1223) \tNS PDE Loss:  tensor(27592.3965)\n",
      "Iteration: 800 \tTotal Loss: tensor(25133.9336)\n",
      "\tBC Loss:  tensor(20.3461) \tNS PDE Loss:  tensor(25113.5879)\n",
      "Iteration: 1000 \tTotal Loss: tensor(23453.4160)\n",
      "\tBC Loss:  tensor(20.5372) \tNS PDE Loss:  tensor(23432.8789)\n",
      "Iteration: 1200 \tTotal Loss: tensor(22195.2383)\n",
      "\tBC Loss:  tensor(20.7026) \tNS PDE Loss:  tensor(22174.5352)\n",
      "Iteration: 1400 \tTotal Loss: tensor(21199.4648)\n",
      "\tBC Loss:  tensor(20.8428) \tNS PDE Loss:  tensor(21178.6211)\n",
      "Iteration: 1600 \tTotal Loss: tensor(20530.0020)\n",
      "\tBC Loss:  tensor(20.9652) \tNS PDE Loss:  tensor(20509.0371)\n",
      "Iteration: 1800 \tTotal Loss: tensor(19961.2852)\n",
      "\tBC Loss:  tensor(21.0702) \tNS PDE Loss:  tensor(19940.2148)\n",
      "Iteration: 2000 \tTotal Loss: tensor(19440.5762)\n",
      "\tBC Loss:  tensor(21.1577) \tNS PDE Loss:  tensor(19419.4180)\n",
      "Iteration: 2200 \tTotal Loss: tensor(19229.5469)\n",
      "\tBC Loss:  tensor(21.2157) \tNS PDE Loss:  tensor(19208.3320)\n",
      "Iteration: 2400 \tTotal Loss: tensor(18648.2539)\n",
      "\tBC Loss:  tensor(21.2727) \tNS PDE Loss:  tensor(18626.9805)\n",
      "Iteration: 2600 \tTotal Loss: tensor(18215.9023)\n",
      "\tBC Loss:  tensor(21.3172) \tNS PDE Loss:  tensor(18194.5859)\n",
      "Iteration: 2800 \tTotal Loss: tensor(18282.3027)\n",
      "\tBC Loss:  tensor(21.3539) \tNS PDE Loss:  tensor(18260.9492)\n",
      "Iteration: 3000 \tTotal Loss: tensor(18335.6309)\n",
      "\tBC Loss:  tensor(21.3893) \tNS PDE Loss:  tensor(18314.2422)\n",
      "Iteration: 3200 \tTotal Loss: tensor(17760.6309)\n",
      "\tBC Loss:  tensor(21.4231) \tNS PDE Loss:  tensor(17739.2070)\n",
      "Iteration: 3400 \tTotal Loss: tensor(17648.3574)\n",
      "\tBC Loss:  tensor(21.4548) \tNS PDE Loss:  tensor(17626.9023)\n",
      "Iteration: 3600 \tTotal Loss: tensor(17223.3281)\n",
      "\tBC Loss:  tensor(21.4853) \tNS PDE Loss:  tensor(17201.8438)\n",
      "Iteration: 3800 \tTotal Loss: tensor(17050.8555)\n",
      "\tBC Loss:  tensor(21.5134) \tNS PDE Loss:  tensor(17029.3418)\n",
      "Iteration: 4000 \tTotal Loss: tensor(17190.6172)\n",
      "\tBC Loss:  tensor(21.5397) \tNS PDE Loss:  tensor(17169.0781)\n",
      "Iteration: 4200 \tTotal Loss: tensor(16873.6211)\n",
      "\tBC Loss:  tensor(21.5636) \tNS PDE Loss:  tensor(16852.0566)\n",
      "Iteration: 4400 \tTotal Loss: tensor(16761.3691)\n",
      "\tBC Loss:  tensor(21.5853) \tNS PDE Loss:  tensor(16739.7832)\n",
      "Iteration: 4600 \tTotal Loss: tensor(15835.5283)\n",
      "\tBC Loss:  tensor(21.5893) \tNS PDE Loss:  tensor(15813.9395)\n",
      "Iteration: 4800 \tTotal Loss: tensor(16368.1240)\n",
      "\tBC Loss:  tensor(21.5959) \tNS PDE Loss:  tensor(16346.5283)\n",
      "Iteration: 5000 \tTotal Loss: tensor(16448.1289)\n",
      "\tBC Loss:  tensor(21.6130) \tNS PDE Loss:  tensor(16426.5156)\n",
      "Iteration: 5200 \tTotal Loss: tensor(16052.1221)\n",
      "\tBC Loss:  tensor(21.6300) \tNS PDE Loss:  tensor(16030.4922)\n",
      "Iteration: 5400 \tTotal Loss: tensor(15697.6191)\n",
      "\tBC Loss:  tensor(21.6457) \tNS PDE Loss:  tensor(15675.9736)\n",
      "Iteration: 5600 \tTotal Loss: tensor(15601.6074)\n",
      "\tBC Loss:  tensor(21.6608) \tNS PDE Loss:  tensor(15579.9463)\n",
      "Iteration: 5800 \tTotal Loss: tensor(15480.6104)\n",
      "\tBC Loss:  tensor(21.6746) \tNS PDE Loss:  tensor(15458.9355)\n",
      "Iteration: 6000 \tTotal Loss: tensor(15795.0732)\n",
      "\tBC Loss:  tensor(21.6861) \tNS PDE Loss:  tensor(15773.3867)\n",
      "Iteration: 6200 \tTotal Loss: tensor(15538.6738)\n",
      "\tBC Loss:  tensor(21.6956) \tNS PDE Loss:  tensor(15516.9785)\n",
      "Iteration: 6400 \tTotal Loss: tensor(15136.3955)\n",
      "\tBC Loss:  tensor(21.7034) \tNS PDE Loss:  tensor(15114.6924)\n",
      "Iteration: 6600 \tTotal Loss: tensor(15735.3418)\n",
      "\tBC Loss:  tensor(21.7046) \tNS PDE Loss:  tensor(15713.6377)\n",
      "Iteration: 6800 \tTotal Loss: tensor(15374.3496)\n",
      "\tBC Loss:  tensor(21.6945) \tNS PDE Loss:  tensor(15352.6553)\n",
      "Iteration: 7000 \tTotal Loss: tensor(14986.5400)\n",
      "\tBC Loss:  tensor(21.7064) \tNS PDE Loss:  tensor(14964.8340)\n",
      "Iteration: 7200 \tTotal Loss: tensor(14790.8145)\n",
      "\tBC Loss:  tensor(21.7115) \tNS PDE Loss:  tensor(14769.1025)\n",
      "Iteration: 7400 \tTotal Loss: tensor(14802.5107)\n",
      "\tBC Loss:  tensor(21.7259) \tNS PDE Loss:  tensor(14780.7852)\n",
      "Iteration: 7600 \tTotal Loss: tensor(14435.0059)\n",
      "\tBC Loss:  tensor(21.7387) \tNS PDE Loss:  tensor(14413.2676)\n",
      "Iteration: 7800 \tTotal Loss: tensor(14723.6338)\n",
      "\tBC Loss:  tensor(21.7499) \tNS PDE Loss:  tensor(14701.8838)\n",
      "Iteration: 8000 \tTotal Loss: tensor(14685.9863)\n",
      "\tBC Loss:  tensor(21.7608) \tNS PDE Loss:  tensor(14664.2256)\n",
      "Iteration: 8200 \tTotal Loss: tensor(14753.2031)\n",
      "\tBC Loss:  tensor(21.7703) \tNS PDE Loss:  tensor(14731.4326)\n",
      "Iteration: 8400 \tTotal Loss: tensor(14075.7080)\n",
      "\tBC Loss:  tensor(21.7789) \tNS PDE Loss:  tensor(14053.9287)\n",
      "Iteration: 8600 \tTotal Loss: tensor(14345.1445)\n",
      "\tBC Loss:  tensor(21.7867) \tNS PDE Loss:  tensor(14323.3574)\n",
      "Iteration: 8800 \tTotal Loss: tensor(14341.3721)\n",
      "\tBC Loss:  tensor(21.7931) \tNS PDE Loss:  tensor(14319.5791)\n",
      "Iteration: 9000 \tTotal Loss: tensor(14629.9355)\n",
      "\tBC Loss:  tensor(21.7982) \tNS PDE Loss:  tensor(14608.1377)\n",
      "Iteration: 9200 \tTotal Loss: tensor(22736.7344)\n",
      "\tBC Loss:  tensor(21.8036) \tNS PDE Loss:  tensor(22714.9316)\n",
      "Iteration: 9400 \tTotal Loss: tensor(13691.7686)\n",
      "\tBC Loss:  tensor(21.7891) \tNS PDE Loss:  tensor(13669.9795)\n",
      "Iteration: 9600 \tTotal Loss: tensor(13779.7109)\n",
      "\tBC Loss:  tensor(21.8037) \tNS PDE Loss:  tensor(13757.9072)\n",
      "Iteration: 9800 \tTotal Loss: tensor(13600.3525)\n",
      "\tBC Loss:  tensor(21.8137) \tNS PDE Loss:  tensor(13578.5391)\n",
      "Iteration: 10000 \tTotal Loss: tensor(13864.1123)\n",
      "\tBC Loss:  tensor(21.8246) \tNS PDE Loss:  tensor(13842.2881)\n",
      "Iteration: 10200 \tTotal Loss: tensor(13495.3125)\n",
      "\tBC Loss:  tensor(21.8353) \tNS PDE Loss:  tensor(13473.4775)\n",
      "Iteration: 10400 \tTotal Loss: tensor(13232.6602)\n",
      "\tBC Loss:  tensor(21.8456) \tNS PDE Loss:  tensor(13210.8145)\n",
      "Iteration: 10600 \tTotal Loss: tensor(13592.6074)\n",
      "\tBC Loss:  tensor(21.8560) \tNS PDE Loss:  tensor(13570.7510)\n",
      "Iteration: 10800 \tTotal Loss: tensor(13189.4932)\n",
      "\tBC Loss:  tensor(21.8663) \tNS PDE Loss:  tensor(13167.6270)\n",
      "Iteration: 11000 \tTotal Loss: tensor(13340.6523)\n",
      "\tBC Loss:  tensor(21.8756) \tNS PDE Loss:  tensor(13318.7764)\n",
      "Iteration: 11200 \tTotal Loss: tensor(13441.9688)\n",
      "\tBC Loss:  tensor(21.8736) \tNS PDE Loss:  tensor(13420.0947)\n",
      "Iteration: 11400 \tTotal Loss: tensor(13787.3896)\n",
      "\tBC Loss:  tensor(21.8820) \tNS PDE Loss:  tensor(13765.5078)\n",
      "Iteration: 11600 \tTotal Loss: tensor(13319.3779)\n",
      "\tBC Loss:  tensor(21.8901) \tNS PDE Loss:  tensor(13297.4873)\n",
      "Iteration: 11800 \tTotal Loss: tensor(13081.1133)\n",
      "\tBC Loss:  tensor(21.8992) \tNS PDE Loss:  tensor(13059.2139)\n",
      "Iteration: 12000 \tTotal Loss: tensor(13094.9395)\n",
      "\tBC Loss:  tensor(21.9072) \tNS PDE Loss:  tensor(13073.0322)\n",
      "Iteration: 12200 \tTotal Loss: tensor(12732.4443)\n",
      "\tBC Loss:  tensor(21.9118) \tNS PDE Loss:  tensor(12710.5322)\n",
      "Iteration: 12400 \tTotal Loss: tensor(12627.5498)\n",
      "\tBC Loss:  tensor(21.9278) \tNS PDE Loss:  tensor(12605.6221)\n",
      "Iteration: 12600 \tTotal Loss: tensor(12428.4756)\n",
      "\tBC Loss:  tensor(21.9368) \tNS PDE Loss:  tensor(12406.5391)\n",
      "Iteration: 12800 \tTotal Loss: tensor(12304.6680)\n",
      "\tBC Loss:  tensor(21.9485) \tNS PDE Loss:  tensor(12282.7197)\n",
      "Iteration: 13000 \tTotal Loss: tensor(13261.6504)\n",
      "\tBC Loss:  tensor(21.9603) \tNS PDE Loss:  tensor(13239.6904)\n",
      "Iteration: 13200 \tTotal Loss: tensor(12571.5400)\n",
      "\tBC Loss:  tensor(21.9724) \tNS PDE Loss:  tensor(12549.5674)\n",
      "Iteration: 13400 \tTotal Loss: tensor(12479.2695)\n",
      "\tBC Loss:  tensor(21.9841) \tNS PDE Loss:  tensor(12457.2852)\n",
      "Iteration: 13600 \tTotal Loss: tensor(12559.6514)\n",
      "\tBC Loss:  tensor(21.9951) \tNS PDE Loss:  tensor(12537.6562)\n",
      "Iteration: 13800 \tTotal Loss: tensor(12344.1113)\n",
      "\tBC Loss:  tensor(22.0046) \tNS PDE Loss:  tensor(12322.1064)\n",
      "Iteration: 14000 \tTotal Loss: tensor(12618.4395)\n",
      "\tBC Loss:  tensor(22.0148) \tNS PDE Loss:  tensor(12596.4248)\n",
      "Iteration: 14200 \tTotal Loss: tensor(12022.4199)\n",
      "\tBC Loss:  tensor(22.0261) \tNS PDE Loss:  tensor(12000.3936)\n",
      "Iteration: 14400 \tTotal Loss: tensor(12319.8330)\n",
      "\tBC Loss:  tensor(22.0379) \tNS PDE Loss:  tensor(12297.7949)\n",
      "Iteration: 14600 \tTotal Loss: tensor(12240.6680)\n",
      "\tBC Loss:  tensor(22.0489) \tNS PDE Loss:  tensor(12218.6191)\n",
      "Iteration: 14800 \tTotal Loss: tensor(12040.0742)\n",
      "\tBC Loss:  tensor(22.0507) \tNS PDE Loss:  tensor(12018.0234)\n",
      "Iteration: 15000 \tTotal Loss: tensor(11905.1982)\n",
      "\tBC Loss:  tensor(22.0642) \tNS PDE Loss:  tensor(11883.1338)\n",
      "Iteration: 15200 \tTotal Loss: tensor(11573.9688)\n",
      "\tBC Loss:  tensor(22.0760) \tNS PDE Loss:  tensor(11551.8926)\n",
      "Iteration: 15400 \tTotal Loss: tensor(11432.8828)\n",
      "\tBC Loss:  tensor(22.0881) \tNS PDE Loss:  tensor(11410.7949)\n",
      "Iteration: 15600 \tTotal Loss: tensor(11498.8906)\n",
      "\tBC Loss:  tensor(22.1011) \tNS PDE Loss:  tensor(11476.7900)\n",
      "Iteration: 15800 \tTotal Loss: tensor(11493.1152)\n",
      "\tBC Loss:  tensor(22.1138) \tNS PDE Loss:  tensor(11471.0020)\n",
      "Iteration: 16000 \tTotal Loss: tensor(11855.2422)\n",
      "\tBC Loss:  tensor(22.1267) \tNS PDE Loss:  tensor(11833.1152)\n",
      "Iteration: 16200 \tTotal Loss: tensor(11674.2256)\n",
      "\tBC Loss:  tensor(22.1401) \tNS PDE Loss:  tensor(11652.0859)\n",
      "Iteration: 16400 \tTotal Loss: tensor(11655.7314)\n",
      "\tBC Loss:  tensor(22.1538) \tNS PDE Loss:  tensor(11633.5781)\n",
      "Iteration: 16600 \tTotal Loss: tensor(11192.8525)\n",
      "\tBC Loss:  tensor(22.1677) \tNS PDE Loss:  tensor(11170.6846)\n",
      "Iteration: 16800 \tTotal Loss: tensor(11768.7324)\n",
      "\tBC Loss:  tensor(22.1765) \tNS PDE Loss:  tensor(11746.5557)\n",
      "Iteration: 17000 \tTotal Loss: tensor(11460.2900)\n",
      "\tBC Loss:  tensor(22.1890) \tNS PDE Loss:  tensor(11438.1006)\n",
      "Iteration: 17200 \tTotal Loss: tensor(10962.7930)\n",
      "\tBC Loss:  tensor(22.2031) \tNS PDE Loss:  tensor(10940.5898)\n",
      "Iteration: 17400 \tTotal Loss: tensor(10885.7031)\n",
      "\tBC Loss:  tensor(22.2187) \tNS PDE Loss:  tensor(10863.4844)\n",
      "Iteration: 17600 \tTotal Loss: tensor(13225.1670)\n",
      "\tBC Loss:  tensor(22.2554) \tNS PDE Loss:  tensor(13202.9111)\n",
      "Iteration: 17800 \tTotal Loss: tensor(11066.6816)\n",
      "\tBC Loss:  tensor(22.2731) \tNS PDE Loss:  tensor(11044.4082)\n",
      "Iteration: 18000 \tTotal Loss: tensor(10493.3555)\n",
      "\tBC Loss:  tensor(22.2854) \tNS PDE Loss:  tensor(10471.0703)\n",
      "Iteration: 18200 \tTotal Loss: tensor(11049.0605)\n",
      "\tBC Loss:  tensor(22.2933) \tNS PDE Loss:  tensor(11026.7676)\n",
      "Iteration: 18400 \tTotal Loss: tensor(10768.6162)\n",
      "\tBC Loss:  tensor(22.3157) \tNS PDE Loss:  tensor(10746.3008)\n",
      "Iteration: 18600 \tTotal Loss: tensor(10350.3379)\n",
      "\tBC Loss:  tensor(22.3301) \tNS PDE Loss:  tensor(10328.0078)\n",
      "Iteration: 18800 \tTotal Loss: tensor(10390.4189)\n",
      "\tBC Loss:  tensor(22.3456) \tNS PDE Loss:  tensor(10368.0732)\n",
      "Iteration: 19000 \tTotal Loss: tensor(11213.8594)\n",
      "\tBC Loss:  tensor(22.3612) \tNS PDE Loss:  tensor(11191.4980)\n",
      "Iteration: 19200 \tTotal Loss: tensor(11223.5869)\n",
      "\tBC Loss:  tensor(22.3773) \tNS PDE Loss:  tensor(11201.2100)\n",
      "Iteration: 19400 \tTotal Loss: tensor(10326.7217)\n",
      "\tBC Loss:  tensor(22.3930) \tNS PDE Loss:  tensor(10304.3291)\n",
      "Iteration: 19600 \tTotal Loss: tensor(10159.8672)\n",
      "\tBC Loss:  tensor(22.4093) \tNS PDE Loss:  tensor(10137.4580)\n",
      "Iteration: 19800 \tTotal Loss: tensor(10855.2451)\n",
      "\tBC Loss:  tensor(22.4229) \tNS PDE Loss:  tensor(10832.8223)\n",
      "Iteration: 20000 \tTotal Loss: tensor(10627.5303)\n",
      "\tBC Loss:  tensor(22.4394) \tNS PDE Loss:  tensor(10605.0908)\n",
      "Iteration: 20200 \tTotal Loss: tensor(10049.8359)\n",
      "\tBC Loss:  tensor(22.4551) \tNS PDE Loss:  tensor(10027.3809)\n",
      "Iteration: 20400 \tTotal Loss: tensor(10403.9385)\n",
      "\tBC Loss:  tensor(22.4691) \tNS PDE Loss:  tensor(10381.4697)\n",
      "Iteration: 20600 \tTotal Loss: tensor(9925.1357)\n",
      "\tBC Loss:  tensor(22.4829) \tNS PDE Loss:  tensor(9902.6533)\n",
      "Iteration: 20800 \tTotal Loss: tensor(10430.3467)\n",
      "\tBC Loss:  tensor(22.4985) \tNS PDE Loss:  tensor(10407.8477)\n",
      "Iteration: 21000 \tTotal Loss: tensor(11754.8408)\n",
      "\tBC Loss:  tensor(22.4957) \tNS PDE Loss:  tensor(11732.3447)\n",
      "Iteration: 21200 \tTotal Loss: tensor(10393.9199)\n",
      "\tBC Loss:  tensor(22.5434) \tNS PDE Loss:  tensor(10371.3770)\n",
      "Iteration: 21400 \tTotal Loss: tensor(10445.7109)\n",
      "\tBC Loss:  tensor(22.5660) \tNS PDE Loss:  tensor(10423.1445)\n",
      "Iteration: 21600 \tTotal Loss: tensor(10804.9209)\n",
      "\tBC Loss:  tensor(22.5861) \tNS PDE Loss:  tensor(10782.3350)\n",
      "Iteration: 21800 \tTotal Loss: tensor(10802.5400)\n",
      "\tBC Loss:  tensor(22.6033) \tNS PDE Loss:  tensor(10779.9365)\n",
      "Iteration: 22000 \tTotal Loss: tensor(63154.2148)\n",
      "\tBC Loss:  tensor(22.6175) \tNS PDE Loss:  tensor(63131.5977)\n",
      "Iteration: 22200 \tTotal Loss: tensor(10288.4297)\n",
      "\tBC Loss:  tensor(22.6182) \tNS PDE Loss:  tensor(10265.8115)\n",
      "Iteration: 22400 \tTotal Loss: tensor(10052.7549)\n",
      "\tBC Loss:  tensor(22.6438) \tNS PDE Loss:  tensor(10030.1113)\n",
      "Iteration: 22600 \tTotal Loss: tensor(9757.9307)\n",
      "\tBC Loss:  tensor(22.6660) \tNS PDE Loss:  tensor(9735.2646)\n",
      "Iteration: 22800 \tTotal Loss: tensor(9966.3135)\n",
      "\tBC Loss:  tensor(22.6874) \tNS PDE Loss:  tensor(9943.6260)\n",
      "Iteration: 23000 \tTotal Loss: tensor(9653.7480)\n",
      "\tBC Loss:  tensor(22.7093) \tNS PDE Loss:  tensor(9631.0391)\n",
      "Iteration: 23200 \tTotal Loss: tensor(9712.4492)\n",
      "\tBC Loss:  tensor(22.7127) \tNS PDE Loss:  tensor(9689.7363)\n",
      "Iteration: 23400 \tTotal Loss: tensor(9812.1025)\n",
      "\tBC Loss:  tensor(22.7370) \tNS PDE Loss:  tensor(9789.3652)\n",
      "Iteration: 23600 \tTotal Loss: tensor(9102.1406)\n",
      "\tBC Loss:  tensor(22.7753) \tNS PDE Loss:  tensor(9079.3652)\n",
      "Iteration: 23800 \tTotal Loss: tensor(9788.6445)\n",
      "\tBC Loss:  tensor(22.8005) \tNS PDE Loss:  tensor(9765.8438)\n",
      "Iteration: 24000 \tTotal Loss: tensor(9376.4492)\n",
      "\tBC Loss:  tensor(22.8203) \tNS PDE Loss:  tensor(9353.6289)\n",
      "Iteration: 24200 \tTotal Loss: tensor(14216.6621)\n",
      "\tBC Loss:  tensor(22.8294) \tNS PDE Loss:  tensor(14193.8330)\n",
      "Iteration: 24400 \tTotal Loss: tensor(9568.7656)\n",
      "\tBC Loss:  tensor(22.8695) \tNS PDE Loss:  tensor(9545.8965)\n",
      "Iteration: 24600 \tTotal Loss: tensor(9349.0830)\n",
      "\tBC Loss:  tensor(22.8911) \tNS PDE Loss:  tensor(9326.1924)\n",
      "Iteration: 24800 \tTotal Loss: tensor(9532.8848)\n",
      "\tBC Loss:  tensor(22.9123) \tNS PDE Loss:  tensor(9509.9727)\n",
      "Iteration: 25000 \tTotal Loss: tensor(8798.1514)\n",
      "\tBC Loss:  tensor(22.9310) \tNS PDE Loss:  tensor(8775.2207)\n",
      "Iteration: 25200 \tTotal Loss: tensor(8929.8447)\n",
      "\tBC Loss:  tensor(22.9383) \tNS PDE Loss:  tensor(8906.9062)\n",
      "Iteration: 25400 \tTotal Loss: tensor(9458.4541)\n",
      "\tBC Loss:  tensor(22.9636) \tNS PDE Loss:  tensor(9435.4902)\n",
      "Iteration: 25600 \tTotal Loss: tensor(9243.3555)\n",
      "\tBC Loss:  tensor(22.9893) \tNS PDE Loss:  tensor(9220.3662)\n",
      "Iteration: 25800 \tTotal Loss: tensor(8833.3369)\n",
      "\tBC Loss:  tensor(23.0140) \tNS PDE Loss:  tensor(8810.3232)\n",
      "Iteration: 26000 \tTotal Loss: tensor(8659.7920)\n",
      "\tBC Loss:  tensor(23.0366) \tNS PDE Loss:  tensor(8636.7549)\n",
      "Iteration: 26200 \tTotal Loss: tensor(9149.9844)\n",
      "\tBC Loss:  tensor(23.0491) \tNS PDE Loss:  tensor(9126.9355)\n",
      "Iteration: 26400 \tTotal Loss: tensor(9209.4404)\n",
      "\tBC Loss:  tensor(23.0731) \tNS PDE Loss:  tensor(9186.3672)\n",
      "Iteration: 26600 \tTotal Loss: tensor(9001.7344)\n",
      "\tBC Loss:  tensor(23.0949) \tNS PDE Loss:  tensor(8978.6396)\n",
      "Iteration: 26800 \tTotal Loss: tensor(9113.7451)\n",
      "\tBC Loss:  tensor(23.1164) \tNS PDE Loss:  tensor(9090.6289)\n",
      "Iteration: 27000 \tTotal Loss: tensor(8698.5957)\n",
      "\tBC Loss:  tensor(23.1351) \tNS PDE Loss:  tensor(8675.4609)\n",
      "Iteration: 27200 \tTotal Loss: tensor(9426.4658)\n",
      "\tBC Loss:  tensor(23.1541) \tNS PDE Loss:  tensor(9403.3115)\n",
      "Iteration: 27400 \tTotal Loss: tensor(10175.1377)\n",
      "\tBC Loss:  tensor(23.1791) \tNS PDE Loss:  tensor(10151.9590)\n",
      "Iteration: 27600 \tTotal Loss: tensor(8286.1123)\n",
      "\tBC Loss:  tensor(23.2131) \tNS PDE Loss:  tensor(8262.8994)\n",
      "Iteration: 27800 \tTotal Loss: tensor(8384.0342)\n",
      "\tBC Loss:  tensor(23.2335) \tNS PDE Loss:  tensor(8360.8008)\n",
      "Iteration: 28000 \tTotal Loss: tensor(8554.0439)\n",
      "\tBC Loss:  tensor(23.2550) \tNS PDE Loss:  tensor(8530.7891)\n",
      "Iteration: 28200 \tTotal Loss: tensor(8194.2148)\n",
      "\tBC Loss:  tensor(23.2664) \tNS PDE Loss:  tensor(8170.9487)\n",
      "Iteration: 28400 \tTotal Loss: tensor(8028.8218)\n",
      "\tBC Loss:  tensor(23.2939) \tNS PDE Loss:  tensor(8005.5278)\n",
      "Iteration: 28600 \tTotal Loss: tensor(8965.8203)\n",
      "\tBC Loss:  tensor(23.3182) \tNS PDE Loss:  tensor(8942.5020)\n",
      "Iteration: 28800 \tTotal Loss: tensor(8436.3408)\n",
      "\tBC Loss:  tensor(23.3406) \tNS PDE Loss:  tensor(8413.)\n",
      "Iteration: 29000 \tTotal Loss: tensor(8415.7256)\n",
      "\tBC Loss:  tensor(23.3619) \tNS PDE Loss:  tensor(8392.3633)\n",
      "Iteration: 29200 \tTotal Loss: tensor(9737.5332)\n",
      "\tBC Loss:  tensor(23.3720) \tNS PDE Loss:  tensor(9714.1611)\n",
      "Iteration: 29400 \tTotal Loss: tensor(8054.1846)\n",
      "\tBC Loss:  tensor(23.3979) \tNS PDE Loss:  tensor(8030.7866)\n",
      "Iteration: 29600 \tTotal Loss: tensor(7844.4922)\n",
      "\tBC Loss:  tensor(23.4224) \tNS PDE Loss:  tensor(7821.0698)\n",
      "Iteration: 29800 \tTotal Loss: tensor(8349.0029)\n",
      "\tBC Loss:  tensor(23.4462) \tNS PDE Loss:  tensor(8325.5566)\n",
      "Iteration: 30000 \tTotal Loss: tensor(7775.1309)\n",
      "\tBC Loss:  tensor(23.4670) \tNS PDE Loss:  tensor(7751.6641)\n",
      "Iteration: 30200 \tTotal Loss: tensor(7858.9238)\n",
      "\tBC Loss:  tensor(23.4691) \tNS PDE Loss:  tensor(7835.4546)\n",
      "Iteration: 30400 \tTotal Loss: tensor(7786.7236)\n",
      "\tBC Loss:  tensor(23.5002) \tNS PDE Loss:  tensor(7763.2236)\n",
      "Iteration: 30600 \tTotal Loss: tensor(7092.0996)\n",
      "\tBC Loss:  tensor(23.5272) \tNS PDE Loss:  tensor(7068.5723)\n",
      "Iteration: 30800 \tTotal Loss: tensor(7133.3359)\n",
      "\tBC Loss:  tensor(23.5526) \tNS PDE Loss:  tensor(7109.7832)\n",
      "Iteration: 31000 \tTotal Loss: tensor(7912.8711)\n",
      "\tBC Loss:  tensor(23.5760) \tNS PDE Loss:  tensor(7889.2949)\n",
      "Iteration: 31200 \tTotal Loss: tensor(7542.1440)\n",
      "\tBC Loss:  tensor(23.5987) \tNS PDE Loss:  tensor(7518.5454)\n",
      "Iteration: 31400 \tTotal Loss: tensor(7936.1924)\n",
      "\tBC Loss:  tensor(23.6142) \tNS PDE Loss:  tensor(7912.5781)\n",
      "Iteration: 31600 \tTotal Loss: tensor(7535.6631)\n",
      "\tBC Loss:  tensor(23.6301) \tNS PDE Loss:  tensor(7512.0332)\n",
      "Iteration: 31800 \tTotal Loss: tensor(8094.4697)\n",
      "\tBC Loss:  tensor(23.6567) \tNS PDE Loss:  tensor(8070.8130)\n",
      "Iteration: 32000 \tTotal Loss: tensor(8679.2764)\n",
      "\tBC Loss:  tensor(23.6775) \tNS PDE Loss:  tensor(8655.5986)\n",
      "Iteration: 32200 \tTotal Loss: tensor(9062.2549)\n",
      "\tBC Loss:  tensor(23.6908) \tNS PDE Loss:  tensor(9038.5645)\n",
      "Iteration: 32400 \tTotal Loss: tensor(6607.5601)\n",
      "\tBC Loss:  tensor(23.7200) \tNS PDE Loss:  tensor(6583.8398)\n",
      "Iteration: 32600 \tTotal Loss: tensor(7295.6201)\n",
      "\tBC Loss:  tensor(23.7523) \tNS PDE Loss:  tensor(7271.8677)\n",
      "Iteration: 32800 \tTotal Loss: tensor(7427.4990)\n",
      "\tBC Loss:  tensor(23.7820) \tNS PDE Loss:  tensor(7403.7168)\n",
      "Iteration: 33000 \tTotal Loss: tensor(7158.0981)\n",
      "\tBC Loss:  tensor(23.8085) \tNS PDE Loss:  tensor(7134.2896)\n",
      "Iteration: 33200 \tTotal Loss: tensor(7228.9512)\n",
      "\tBC Loss:  tensor(23.8339) \tNS PDE Loss:  tensor(7205.1172)\n",
      "Iteration: 33400 \tTotal Loss: tensor(7580.2798)\n",
      "\tBC Loss:  tensor(23.8555) \tNS PDE Loss:  tensor(7556.4243)\n",
      "Iteration: 33600 \tTotal Loss: tensor(6752.9946)\n",
      "\tBC Loss:  tensor(23.8772) \tNS PDE Loss:  tensor(6729.1172)\n",
      "Iteration: 33800 \tTotal Loss: tensor(6390.9775)\n",
      "\tBC Loss:  tensor(23.8982) \tNS PDE Loss:  tensor(6367.0796)\n",
      "Iteration: 34000 \tTotal Loss: tensor(7412.6050)\n",
      "\tBC Loss:  tensor(23.9178) \tNS PDE Loss:  tensor(7388.6870)\n",
      "Iteration: 34200 \tTotal Loss: tensor(6443.4512)\n",
      "\tBC Loss:  tensor(23.9384) \tNS PDE Loss:  tensor(6419.5127)\n",
      "Iteration: 34400 \tTotal Loss: tensor(8935.3145)\n",
      "\tBC Loss:  tensor(23.9499) \tNS PDE Loss:  tensor(8911.3643)\n",
      "Iteration: 34600 \tTotal Loss: tensor(7769.7588)\n",
      "\tBC Loss:  tensor(23.9702) \tNS PDE Loss:  tensor(7745.7886)\n",
      "Iteration: 34800 \tTotal Loss: tensor(8073.9312)\n",
      "\tBC Loss:  tensor(23.9938) \tNS PDE Loss:  tensor(8049.9375)\n",
      "Iteration: 35000 \tTotal Loss: tensor(6477.1206)\n",
      "\tBC Loss:  tensor(24.0203) \tNS PDE Loss:  tensor(6453.1001)\n",
      "Iteration: 35200 \tTotal Loss: tensor(7128.1699)\n",
      "\tBC Loss:  tensor(24.0365) \tNS PDE Loss:  tensor(7104.1333)\n",
      "Iteration: 35400 \tTotal Loss: tensor(6937.3159)\n",
      "\tBC Loss:  tensor(24.0612) \tNS PDE Loss:  tensor(6913.2549)\n",
      "Iteration: 35600 \tTotal Loss: tensor(5910.1187)\n",
      "\tBC Loss:  tensor(24.0866) \tNS PDE Loss:  tensor(5886.0322)\n",
      "Iteration: 35800 \tTotal Loss: tensor(7133.6426)\n",
      "\tBC Loss:  tensor(24.1117) \tNS PDE Loss:  tensor(7109.5308)\n",
      "Iteration: 36000 \tTotal Loss: tensor(7092.7095)\n",
      "\tBC Loss:  tensor(24.1329) \tNS PDE Loss:  tensor(7068.5767)\n",
      "Iteration: 36200 \tTotal Loss: tensor(7536.8408)\n",
      "\tBC Loss:  tensor(24.1323) \tNS PDE Loss:  tensor(7512.7085)\n",
      "Iteration: 36400 \tTotal Loss: tensor(6992.5654)\n",
      "\tBC Loss:  tensor(24.1483) \tNS PDE Loss:  tensor(6968.4170)\n",
      "Iteration: 36600 \tTotal Loss: tensor(6959.7583)\n",
      "\tBC Loss:  tensor(24.1825) \tNS PDE Loss:  tensor(6935.5757)\n",
      "Iteration: 36800 \tTotal Loss: tensor(6780.5713)\n",
      "\tBC Loss:  tensor(24.2173) \tNS PDE Loss:  tensor(6756.3540)\n",
      "Iteration: 37000 \tTotal Loss: tensor(6416.0273)\n",
      "\tBC Loss:  tensor(24.2446) \tNS PDE Loss:  tensor(6391.7827)\n",
      "Iteration: 37200 \tTotal Loss: tensor(5308.1128)\n",
      "\tBC Loss:  tensor(24.2515) \tNS PDE Loss:  tensor(5283.8613)\n",
      "Iteration: 37400 \tTotal Loss: tensor(6147.0083)\n",
      "\tBC Loss:  tensor(24.2800) \tNS PDE Loss:  tensor(6122.7285)\n",
      "Iteration: 37600 \tTotal Loss: tensor(5627.5757)\n",
      "\tBC Loss:  tensor(24.3107) \tNS PDE Loss:  tensor(5603.2651)\n",
      "Iteration: 37800 \tTotal Loss: tensor(7405.3384)\n",
      "\tBC Loss:  tensor(24.3359) \tNS PDE Loss:  tensor(7381.0024)\n",
      "Iteration: 38000 \tTotal Loss: tensor(5793.2012)\n",
      "\tBC Loss:  tensor(24.3590) \tNS PDE Loss:  tensor(5768.8423)\n",
      "Iteration: 38200 \tTotal Loss: tensor(7067.8477)\n",
      "\tBC Loss:  tensor(24.3776) \tNS PDE Loss:  tensor(7043.4702)\n",
      "Iteration: 38400 \tTotal Loss: tensor(5981.4771)\n",
      "\tBC Loss:  tensor(24.3968) \tNS PDE Loss:  tensor(5957.0801)\n",
      "Iteration: 38600 \tTotal Loss: tensor(5952.9497)\n",
      "\tBC Loss:  tensor(24.4155) \tNS PDE Loss:  tensor(5928.5342)\n",
      "Iteration: 38800 \tTotal Loss: tensor(5800.9429)\n",
      "\tBC Loss:  tensor(24.4333) \tNS PDE Loss:  tensor(5776.5098)\n",
      "Iteration: 39000 \tTotal Loss: tensor(5747.5088)\n",
      "\tBC Loss:  tensor(24.4576) \tNS PDE Loss:  tensor(5723.0513)\n",
      "Iteration: 39200 \tTotal Loss: tensor(5917.9951)\n",
      "\tBC Loss:  tensor(24.4760) \tNS PDE Loss:  tensor(5893.5190)\n",
      "Iteration: 39400 \tTotal Loss: tensor(5512.2905)\n",
      "\tBC Loss:  tensor(24.4986) \tNS PDE Loss:  tensor(5487.7920)\n",
      "Iteration: 39600 \tTotal Loss: tensor(5920.5908)\n",
      "\tBC Loss:  tensor(24.5226) \tNS PDE Loss:  tensor(5896.0684)\n",
      "Iteration: 39800 \tTotal Loss: tensor(7389.4751)\n",
      "\tBC Loss:  tensor(24.5439) \tNS PDE Loss:  tensor(7364.9312)\n",
      "Iteration: 40000 \tTotal Loss: tensor(5709.7217)\n",
      "\tBC Loss:  tensor(24.5654) \tNS PDE Loss:  tensor(5685.1562)\n",
      "Iteration: 40200 \tTotal Loss: tensor(5913.2983)\n",
      "\tBC Loss:  tensor(24.5864) \tNS PDE Loss:  tensor(5888.7119)\n",
      "Iteration: 40400 \tTotal Loss: tensor(5487.2817)\n",
      "\tBC Loss:  tensor(24.6073) \tNS PDE Loss:  tensor(5462.6743)\n",
      "Iteration: 40600 \tTotal Loss: tensor(5539.2183)\n",
      "\tBC Loss:  tensor(24.6272) \tNS PDE Loss:  tensor(5514.5908)\n",
      "Iteration: 40800 \tTotal Loss: tensor(6631.1567)\n",
      "\tBC Loss:  tensor(24.6183) \tNS PDE Loss:  tensor(6606.5386)\n",
      "Iteration: 41000 \tTotal Loss: tensor(5018.2085)\n",
      "\tBC Loss:  tensor(24.6288) \tNS PDE Loss:  tensor(4993.5796)\n",
      "Iteration: 41200 \tTotal Loss: tensor(5395.9307)\n",
      "\tBC Loss:  tensor(24.6627) \tNS PDE Loss:  tensor(5371.2681)\n",
      "Iteration: 41400 \tTotal Loss: tensor(6272.9648)\n",
      "\tBC Loss:  tensor(24.6905) \tNS PDE Loss:  tensor(6248.2744)\n",
      "Iteration: 41600 \tTotal Loss: tensor(5017.8296)\n",
      "\tBC Loss:  tensor(24.7088) \tNS PDE Loss:  tensor(4993.1206)\n",
      "Iteration: 41800 \tTotal Loss: tensor(5736.6191)\n",
      "\tBC Loss:  tensor(24.7242) \tNS PDE Loss:  tensor(5711.8950)\n",
      "Iteration: 42000 \tTotal Loss: tensor(5348.1904)\n",
      "\tBC Loss:  tensor(24.7412) \tNS PDE Loss:  tensor(5323.4492)\n",
      "Iteration: 42200 \tTotal Loss: tensor(5142.5254)\n",
      "\tBC Loss:  tensor(24.7511) \tNS PDE Loss:  tensor(5117.7744)\n",
      "Iteration: 42400 \tTotal Loss: tensor(6474.9346)\n",
      "\tBC Loss:  tensor(24.7664) \tNS PDE Loss:  tensor(6450.1680)\n",
      "Iteration: 42600 \tTotal Loss: tensor(6176.2539)\n",
      "\tBC Loss:  tensor(24.7805) \tNS PDE Loss:  tensor(6151.4736)\n",
      "Iteration: 42800 \tTotal Loss: tensor(5630.1567)\n",
      "\tBC Loss:  tensor(24.7938) \tNS PDE Loss:  tensor(5605.3628)\n",
      "Iteration: 43000 \tTotal Loss: tensor(5773.3711)\n",
      "\tBC Loss:  tensor(24.8050) \tNS PDE Loss:  tensor(5748.5659)\n",
      "Iteration: 43200 \tTotal Loss: tensor(4722.0908)\n",
      "\tBC Loss:  tensor(24.8171) \tNS PDE Loss:  tensor(4697.2739)\n",
      "Iteration: 43400 \tTotal Loss: tensor(4885.6978)\n",
      "\tBC Loss:  tensor(24.8335) \tNS PDE Loss:  tensor(4860.8643)\n",
      "Iteration: 43600 \tTotal Loss: tensor(4981.9668)\n",
      "\tBC Loss:  tensor(24.8495) \tNS PDE Loss:  tensor(4957.1172)\n",
      "Iteration: 43800 \tTotal Loss: tensor(4722.9824)\n",
      "\tBC Loss:  tensor(24.8679) \tNS PDE Loss:  tensor(4698.1147)\n",
      "Iteration: 44000 \tTotal Loss: tensor(5869.0601)\n",
      "\tBC Loss:  tensor(24.8816) \tNS PDE Loss:  tensor(5844.1782)\n",
      "Iteration: 44200 \tTotal Loss: tensor(4593.0547)\n",
      "\tBC Loss:  tensor(24.8874) \tNS PDE Loss:  tensor(4568.1675)\n",
      "Iteration: 44400 \tTotal Loss: tensor(5821.5151)\n",
      "\tBC Loss:  tensor(24.9019) \tNS PDE Loss:  tensor(5796.6133)\n",
      "Iteration: 44600 \tTotal Loss: tensor(5312.9580)\n",
      "\tBC Loss:  tensor(24.9147) \tNS PDE Loss:  tensor(5288.0435)\n",
      "Iteration: 44800 \tTotal Loss: tensor(4799.5762)\n",
      "\tBC Loss:  tensor(24.9225) \tNS PDE Loss:  tensor(4774.6538)\n",
      "Iteration: 45000 \tTotal Loss: tensor(5075.9829)\n",
      "\tBC Loss:  tensor(24.9301) \tNS PDE Loss:  tensor(5051.0527)\n",
      "Iteration: 45200 \tTotal Loss: tensor(5210.0781)\n",
      "\tBC Loss:  tensor(24.9103) \tNS PDE Loss:  tensor(5185.1680)\n",
      "Iteration: 45400 \tTotal Loss: tensor(4803.3389)\n",
      "\tBC Loss:  tensor(24.9098) \tNS PDE Loss:  tensor(4778.4292)\n",
      "Iteration: 45600 \tTotal Loss: tensor(5414.8501)\n",
      "\tBC Loss:  tensor(24.9307) \tNS PDE Loss:  tensor(5389.9194)\n",
      "Iteration: 45800 \tTotal Loss: tensor(4310.6323)\n",
      "\tBC Loss:  tensor(24.9512) \tNS PDE Loss:  tensor(4285.6812)\n",
      "Iteration: 46000 \tTotal Loss: tensor(4082.5801)\n",
      "\tBC Loss:  tensor(24.9677) \tNS PDE Loss:  tensor(4057.6123)\n",
      "Iteration: 46200 \tTotal Loss: tensor(4725.6675)\n",
      "\tBC Loss:  tensor(24.9776) \tNS PDE Loss:  tensor(4700.6899)\n",
      "Iteration: 46400 \tTotal Loss: tensor(4362.2212)\n",
      "\tBC Loss:  tensor(24.9831) \tNS PDE Loss:  tensor(4337.2383)\n",
      "Iteration: 46600 \tTotal Loss: tensor(4783.0566)\n",
      "\tBC Loss:  tensor(24.9853) \tNS PDE Loss:  tensor(4758.0713)\n",
      "Iteration: 46800 \tTotal Loss: tensor(4261.4482)\n",
      "\tBC Loss:  tensor(24.9898) \tNS PDE Loss:  tensor(4236.4585)\n",
      "Iteration: 47000 \tTotal Loss: tensor(5342.8623)\n",
      "\tBC Loss:  tensor(24.9813) \tNS PDE Loss:  tensor(5317.8809)\n",
      "Iteration: 47200 \tTotal Loss: tensor(4944.1167)\n",
      "\tBC Loss:  tensor(24.9724) \tNS PDE Loss:  tensor(4919.1440)\n",
      "Iteration: 47400 \tTotal Loss: tensor(4290.6826)\n",
      "\tBC Loss:  tensor(24.9689) \tNS PDE Loss:  tensor(4265.7139)\n",
      "Iteration: 47600 \tTotal Loss: tensor(6725.4341)\n",
      "\tBC Loss:  tensor(24.9701) \tNS PDE Loss:  tensor(6700.4639)\n",
      "Iteration: 47800 \tTotal Loss: tensor(4953.5449)\n",
      "\tBC Loss:  tensor(24.9881) \tNS PDE Loss:  tensor(4928.5566)\n",
      "Iteration: 48000 \tTotal Loss: tensor(4958.4609)\n",
      "\tBC Loss:  tensor(24.9996) \tNS PDE Loss:  tensor(4933.4614)\n",
      "Iteration: 48200 \tTotal Loss: tensor(5678.4365)\n",
      "\tBC Loss:  tensor(25.0056) \tNS PDE Loss:  tensor(5653.4312)\n",
      "Iteration: 48400 \tTotal Loss: tensor(4246.5879)\n",
      "\tBC Loss:  tensor(25.0084) \tNS PDE Loss:  tensor(4221.5796)\n",
      "Iteration: 48600 \tTotal Loss: tensor(3891.6675)\n",
      "\tBC Loss:  tensor(25.0080) \tNS PDE Loss:  tensor(3866.6594)\n",
      "Iteration: 48800 \tTotal Loss: tensor(4598.1401)\n",
      "\tBC Loss:  tensor(25.0072) \tNS PDE Loss:  tensor(4573.1328)\n",
      "Iteration: 49000 \tTotal Loss: tensor(3866.3757)\n",
      "\tBC Loss:  tensor(25.0044) \tNS PDE Loss:  tensor(3841.3713)\n",
      "Iteration: 49200 \tTotal Loss: tensor(4845.3262)\n",
      "\tBC Loss:  tensor(24.9820) \tNS PDE Loss:  tensor(4820.3442)\n",
      "Iteration: 49400 \tTotal Loss: tensor(4144.9800)\n",
      "\tBC Loss:  tensor(24.9687) \tNS PDE Loss:  tensor(4120.0112)\n",
      "Iteration: 49600 \tTotal Loss: tensor(4464.4648)\n",
      "\tBC Loss:  tensor(24.9655) \tNS PDE Loss:  tensor(4439.4995)\n",
      "Iteration: 49800 \tTotal Loss: tensor(3984.6743)\n",
      "\tBC Loss:  tensor(24.9712) \tNS PDE Loss:  tensor(3959.7031)\n",
      "Iteration: 50000 \tTotal Loss: tensor(5245.5708)\n",
      "\tBC Loss:  tensor(24.9887) \tNS PDE Loss:  tensor(5220.5820)\n",
      "Executing Pass 2\n",
      "Current Final Time: 0.01 Current Learning Rate:  0.0001\n",
      "Iteration: 200 \tTotal Loss: tensor(3450.5139)\n",
      "\tBC Loss:  tensor(24.8914) \tNS PDE Loss:  tensor(3425.6226)\n",
      "Iteration: 400 \tTotal Loss: tensor(5180.5918)\n",
      "\tBC Loss:  tensor(24.8967) \tNS PDE Loss:  tensor(5155.6953)\n",
      "Iteration: 600 \tTotal Loss: tensor(5114.1104)\n",
      "\tBC Loss:  tensor(24.8824) \tNS PDE Loss:  tensor(5089.2280)\n",
      "Iteration: 800 \tTotal Loss: tensor(3420.2786)\n",
      "\tBC Loss:  tensor(24.8643) \tNS PDE Loss:  tensor(3395.4143)\n",
      "Iteration: 1000 \tTotal Loss: tensor(5368.2637)\n",
      "\tBC Loss:  tensor(24.8414) \tNS PDE Loss:  tensor(5343.4224)\n",
      "Iteration: 1200 \tTotal Loss: tensor(3219.9829)\n",
      "\tBC Loss:  tensor(24.8164) \tNS PDE Loss:  tensor(3195.1665)\n",
      "Iteration: 1400 \tTotal Loss: tensor(4988.4658)\n",
      "\tBC Loss:  tensor(24.7880) \tNS PDE Loss:  tensor(4963.6777)\n",
      "Iteration: 1600 \tTotal Loss: tensor(4623.6519)\n",
      "\tBC Loss:  tensor(24.7658) \tNS PDE Loss:  tensor(4598.8862)\n",
      "Iteration: 1800 \tTotal Loss: tensor(6305.3335)\n",
      "\tBC Loss:  tensor(24.7409) \tNS PDE Loss:  tensor(6280.5928)\n",
      "Iteration: 2000 \tTotal Loss: tensor(3501.6262)\n",
      "\tBC Loss:  tensor(24.7164) \tNS PDE Loss:  tensor(3476.9099)\n",
      "Iteration: 2200 \tTotal Loss: tensor(5032.6929)\n",
      "\tBC Loss:  tensor(24.6941) \tNS PDE Loss:  tensor(5007.9985)\n",
      "Iteration: 2400 \tTotal Loss: tensor(3155.4663)\n",
      "\tBC Loss:  tensor(24.6682) \tNS PDE Loss:  tensor(3130.7981)\n",
      "Iteration: 2600 \tTotal Loss: tensor(5289.6382)\n",
      "\tBC Loss:  tensor(24.6419) \tNS PDE Loss:  tensor(5264.9961)\n",
      "Iteration: 2800 \tTotal Loss: tensor(3005.5654)\n",
      "\tBC Loss:  tensor(24.6198) \tNS PDE Loss:  tensor(2980.9456)\n",
      "Iteration: 3000 \tTotal Loss: tensor(2940.3018)\n",
      "\tBC Loss:  tensor(24.5980) \tNS PDE Loss:  tensor(2915.7039)\n",
      "Iteration: 3200 \tTotal Loss: tensor(4221.8325)\n",
      "\tBC Loss:  tensor(24.5744) \tNS PDE Loss:  tensor(4197.2583)\n",
      "Iteration: 3400 \tTotal Loss: tensor(3497.2190)\n",
      "\tBC Loss:  tensor(24.5504) \tNS PDE Loss:  tensor(3472.6685)\n",
      "Iteration: 3600 \tTotal Loss: tensor(4140.6187)\n",
      "\tBC Loss:  tensor(24.5263) \tNS PDE Loss:  tensor(4116.0923)\n",
      "Iteration: 3800 \tTotal Loss: tensor(2902.5938)\n",
      "\tBC Loss:  tensor(24.4990) \tNS PDE Loss:  tensor(2878.0947)\n",
      "Iteration: 4000 \tTotal Loss: tensor(2744.2908)\n",
      "\tBC Loss:  tensor(24.4755) \tNS PDE Loss:  tensor(2719.8152)\n",
      "Iteration: 4200 \tTotal Loss: tensor(3160.1699)\n",
      "\tBC Loss:  tensor(24.4531) \tNS PDE Loss:  tensor(3135.7168)\n",
      "Iteration: 4400 \tTotal Loss: tensor(2820.4482)\n",
      "\tBC Loss:  tensor(24.4312) \tNS PDE Loss:  tensor(2796.0171)\n",
      "Iteration: 4600 \tTotal Loss: tensor(2876.3762)\n",
      "\tBC Loss:  tensor(24.4080) \tNS PDE Loss:  tensor(2851.9683)\n",
      "Iteration: 4800 \tTotal Loss: tensor(2786.2310)\n",
      "\tBC Loss:  tensor(24.3861) \tNS PDE Loss:  tensor(2761.8447)\n",
      "Iteration: 5000 \tTotal Loss: tensor(3009.3445)\n",
      "\tBC Loss:  tensor(24.3674) \tNS PDE Loss:  tensor(2984.9771)\n",
      "Iteration: 5200 \tTotal Loss: tensor(3309.5029)\n",
      "\tBC Loss:  tensor(24.3444) \tNS PDE Loss:  tensor(3285.1584)\n",
      "Iteration: 5400 \tTotal Loss: tensor(3075.4050)\n",
      "\tBC Loss:  tensor(24.3218) \tNS PDE Loss:  tensor(3051.0833)\n",
      "Iteration: 5600 \tTotal Loss: tensor(4535.6592)\n",
      "\tBC Loss:  tensor(24.2995) \tNS PDE Loss:  tensor(4511.3599)\n",
      "Iteration: 5800 \tTotal Loss: tensor(3768.2380)\n",
      "\tBC Loss:  tensor(24.2798) \tNS PDE Loss:  tensor(3743.9583)\n",
      "Iteration: 6000 \tTotal Loss: tensor(2659.9807)\n",
      "\tBC Loss:  tensor(24.2578) \tNS PDE Loss:  tensor(2635.7229)\n",
      "Iteration: 6200 \tTotal Loss: tensor(2819.9199)\n",
      "\tBC Loss:  tensor(24.2355) \tNS PDE Loss:  tensor(2795.6843)\n",
      "Iteration: 6400 \tTotal Loss: tensor(3009.6326)\n",
      "\tBC Loss:  tensor(24.2142) \tNS PDE Loss:  tensor(2985.4185)\n",
      "Iteration: 6600 \tTotal Loss: tensor(2944.6931)\n",
      "\tBC Loss:  tensor(24.1914) \tNS PDE Loss:  tensor(2920.5017)\n",
      "Iteration: 6800 \tTotal Loss: tensor(3415.2974)\n",
      "\tBC Loss:  tensor(24.1696) \tNS PDE Loss:  tensor(3391.1279)\n",
      "Iteration: 7000 \tTotal Loss: tensor(2924.5696)\n",
      "\tBC Loss:  tensor(24.1478) \tNS PDE Loss:  tensor(2900.4219)\n",
      "Iteration: 7200 \tTotal Loss: tensor(2738.1255)\n",
      "\tBC Loss:  tensor(24.1266) \tNS PDE Loss:  tensor(2713.9988)\n",
      "Iteration: 7400 \tTotal Loss: tensor(2870.9385)\n",
      "\tBC Loss:  tensor(24.1032) \tNS PDE Loss:  tensor(2846.8352)\n",
      "Iteration: 7600 \tTotal Loss: tensor(3720.9905)\n",
      "\tBC Loss:  tensor(24.0824) \tNS PDE Loss:  tensor(3696.9080)\n",
      "Iteration: 7800 \tTotal Loss: tensor(2773.3799)\n",
      "\tBC Loss:  tensor(24.0609) \tNS PDE Loss:  tensor(2749.3191)\n",
      "Iteration: 8000 \tTotal Loss: tensor(3739.0225)\n",
      "\tBC Loss:  tensor(24.0409) \tNS PDE Loss:  tensor(3714.9814)\n",
      "Iteration: 8200 \tTotal Loss: tensor(3605.8359)\n",
      "\tBC Loss:  tensor(24.0219) \tNS PDE Loss:  tensor(3581.8140)\n",
      "Iteration: 8400 \tTotal Loss: tensor(4621.7104)\n",
      "\tBC Loss:  tensor(24.0025) \tNS PDE Loss:  tensor(4597.7080)\n",
      "Iteration: 8600 \tTotal Loss: tensor(2419.0103)\n",
      "\tBC Loss:  tensor(23.9806) \tNS PDE Loss:  tensor(2395.0298)\n",
      "Iteration: 8800 \tTotal Loss: tensor(2439.9573)\n",
      "\tBC Loss:  tensor(23.9637) \tNS PDE Loss:  tensor(2415.9937)\n",
      "Iteration: 9000 \tTotal Loss: tensor(2556.8320)\n",
      "\tBC Loss:  tensor(23.9432) \tNS PDE Loss:  tensor(2532.8889)\n",
      "Iteration: 9200 \tTotal Loss: tensor(3072.1558)\n",
      "\tBC Loss:  tensor(23.9257) \tNS PDE Loss:  tensor(3048.2300)\n",
      "Iteration: 9400 \tTotal Loss: tensor(3122.2197)\n",
      "\tBC Loss:  tensor(23.9100) \tNS PDE Loss:  tensor(3098.3098)\n",
      "Iteration: 9600 \tTotal Loss: tensor(2558.0605)\n",
      "\tBC Loss:  tensor(23.8898) \tNS PDE Loss:  tensor(2534.1707)\n",
      "Iteration: 9800 \tTotal Loss: tensor(4184.4678)\n",
      "\tBC Loss:  tensor(23.8668) \tNS PDE Loss:  tensor(4160.6011)\n",
      "Iteration: 10000 \tTotal Loss: tensor(4236.8857)\n",
      "\tBC Loss:  tensor(23.8481) \tNS PDE Loss:  tensor(4213.0376)\n",
      "Iteration: 10200 \tTotal Loss: tensor(3379.9758)\n",
      "\tBC Loss:  tensor(23.8298) \tNS PDE Loss:  tensor(3356.1460)\n",
      "Iteration: 10400 \tTotal Loss: tensor(2652.4744)\n",
      "\tBC Loss:  tensor(23.8140) \tNS PDE Loss:  tensor(2628.6604)\n",
      "Iteration: 10600 \tTotal Loss: tensor(2547.3076)\n",
      "\tBC Loss:  tensor(23.7925) \tNS PDE Loss:  tensor(2523.5151)\n",
      "Iteration: 10800 \tTotal Loss: tensor(3472.6294)\n",
      "\tBC Loss:  tensor(23.7742) \tNS PDE Loss:  tensor(3448.8552)\n",
      "Iteration: 11000 \tTotal Loss: tensor(2653.9680)\n",
      "\tBC Loss:  tensor(23.7597) \tNS PDE Loss:  tensor(2630.2083)\n",
      "Iteration: 11200 \tTotal Loss: tensor(3501.6838)\n",
      "\tBC Loss:  tensor(23.7409) \tNS PDE Loss:  tensor(3477.9429)\n",
      "Iteration: 11400 \tTotal Loss: tensor(3504.9026)\n",
      "\tBC Loss:  tensor(23.7266) \tNS PDE Loss:  tensor(3481.1760)\n",
      "Iteration: 11600 \tTotal Loss: tensor(2737.6338)\n",
      "\tBC Loss:  tensor(23.7083) \tNS PDE Loss:  tensor(2713.9255)\n",
      "Iteration: 11800 \tTotal Loss: tensor(3815.1672)\n",
      "\tBC Loss:  tensor(23.6922) \tNS PDE Loss:  tensor(3791.4751)\n",
      "Iteration: 12000 \tTotal Loss: tensor(2396.6768)\n",
      "\tBC Loss:  tensor(23.6742) \tNS PDE Loss:  tensor(2373.0027)\n",
      "Iteration: 12200 \tTotal Loss: tensor(2702.3691)\n",
      "\tBC Loss:  tensor(23.6602) \tNS PDE Loss:  tensor(2678.7090)\n",
      "Iteration: 12400 \tTotal Loss: tensor(3317.1101)\n",
      "\tBC Loss:  tensor(23.6428) \tNS PDE Loss:  tensor(3293.4673)\n",
      "Iteration: 12600 \tTotal Loss: tensor(2595.0408)\n",
      "\tBC Loss:  tensor(23.6291) \tNS PDE Loss:  tensor(2571.4116)\n",
      "Iteration: 12800 \tTotal Loss: tensor(2495.9651)\n",
      "\tBC Loss:  tensor(23.6112) \tNS PDE Loss:  tensor(2472.3540)\n",
      "Iteration: 13000 \tTotal Loss: tensor(2610.3062)\n",
      "\tBC Loss:  tensor(23.5956) \tNS PDE Loss:  tensor(2586.7104)\n",
      "Iteration: 13200 \tTotal Loss: tensor(2675.9778)\n",
      "\tBC Loss:  tensor(23.5807) \tNS PDE Loss:  tensor(2652.3970)\n",
      "Iteration: 13400 \tTotal Loss: tensor(4349.0615)\n",
      "\tBC Loss:  tensor(23.5663) \tNS PDE Loss:  tensor(4325.4951)\n",
      "Iteration: 13600 \tTotal Loss: tensor(3089.1951)\n",
      "\tBC Loss:  tensor(23.5523) \tNS PDE Loss:  tensor(3065.6428)\n",
      "Iteration: 13800 \tTotal Loss: tensor(2489.6667)\n",
      "\tBC Loss:  tensor(23.5376) \tNS PDE Loss:  tensor(2466.1292)\n",
      "Iteration: 14000 \tTotal Loss: tensor(2916.6938)\n",
      "\tBC Loss:  tensor(23.5253) \tNS PDE Loss:  tensor(2893.1685)\n",
      "Iteration: 14200 \tTotal Loss: tensor(2654.4631)\n",
      "\tBC Loss:  tensor(23.5085) \tNS PDE Loss:  tensor(2630.9546)\n",
      "Iteration: 14400 \tTotal Loss: tensor(2210.7905)\n",
      "\tBC Loss:  tensor(23.4955) \tNS PDE Loss:  tensor(2187.2952)\n",
      "Iteration: 14600 \tTotal Loss: tensor(2564.3691)\n",
      "\tBC Loss:  tensor(23.4795) \tNS PDE Loss:  tensor(2540.8896)\n",
      "Iteration: 14800 \tTotal Loss: tensor(2980.3164)\n",
      "\tBC Loss:  tensor(23.4631) \tNS PDE Loss:  tensor(2956.8533)\n",
      "Iteration: 15000 \tTotal Loss: tensor(4668.1494)\n",
      "\tBC Loss:  tensor(23.4481) \tNS PDE Loss:  tensor(4644.7012)\n",
      "Iteration: 15200 \tTotal Loss: tensor(2291.0332)\n",
      "\tBC Loss:  tensor(23.4288) \tNS PDE Loss:  tensor(2267.6045)\n",
      "Iteration: 15400 \tTotal Loss: tensor(2798.6511)\n",
      "\tBC Loss:  tensor(23.4080) \tNS PDE Loss:  tensor(2775.2432)\n",
      "Iteration: 15600 \tTotal Loss: tensor(2842.9082)\n",
      "\tBC Loss:  tensor(23.3927) \tNS PDE Loss:  tensor(2819.5154)\n",
      "Iteration: 15800 \tTotal Loss: tensor(3103.6208)\n",
      "\tBC Loss:  tensor(23.3788) \tNS PDE Loss:  tensor(3080.2419)\n",
      "Iteration: 16000 \tTotal Loss: tensor(3782.7363)\n",
      "\tBC Loss:  tensor(23.3627) \tNS PDE Loss:  tensor(3759.3735)\n",
      "Iteration: 16200 \tTotal Loss: tensor(3411.0254)\n",
      "\tBC Loss:  tensor(23.3487) \tNS PDE Loss:  tensor(3387.6768)\n",
      "Iteration: 16400 \tTotal Loss: tensor(2497.6460)\n",
      "\tBC Loss:  tensor(23.3331) \tNS PDE Loss:  tensor(2474.3127)\n",
      "Iteration: 16600 \tTotal Loss: tensor(3057.7422)\n",
      "\tBC Loss:  tensor(23.3229) \tNS PDE Loss:  tensor(3034.4192)\n",
      "Iteration: 16800 \tTotal Loss: tensor(3157.1267)\n",
      "\tBC Loss:  tensor(23.3077) \tNS PDE Loss:  tensor(3133.8191)\n",
      "Iteration: 17000 \tTotal Loss: tensor(2521.0620)\n",
      "\tBC Loss:  tensor(23.2920) \tNS PDE Loss:  tensor(2497.7700)\n",
      "Iteration: 17200 \tTotal Loss: tensor(2683.3862)\n",
      "\tBC Loss:  tensor(23.2789) \tNS PDE Loss:  tensor(2660.1072)\n",
      "Iteration: 17400 \tTotal Loss: tensor(2327.8821)\n",
      "\tBC Loss:  tensor(23.2592) \tNS PDE Loss:  tensor(2304.6228)\n",
      "Iteration: 17600 \tTotal Loss: tensor(3054.0903)\n",
      "\tBC Loss:  tensor(23.2424) \tNS PDE Loss:  tensor(3030.8479)\n",
      "Iteration: 17800 \tTotal Loss: tensor(3538.8826)\n",
      "\tBC Loss:  tensor(23.2269) \tNS PDE Loss:  tensor(3515.6558)\n",
      "Iteration: 18000 \tTotal Loss: tensor(3933.2607)\n",
      "\tBC Loss:  tensor(23.2123) \tNS PDE Loss:  tensor(3910.0486)\n",
      "Iteration: 18200 \tTotal Loss: tensor(2322.8579)\n",
      "\tBC Loss:  tensor(23.1962) \tNS PDE Loss:  tensor(2299.6616)\n",
      "Iteration: 18400 \tTotal Loss: tensor(2990.6160)\n",
      "\tBC Loss:  tensor(23.1786) \tNS PDE Loss:  tensor(2967.4373)\n",
      "Iteration: 18600 \tTotal Loss: tensor(2243.2151)\n",
      "\tBC Loss:  tensor(23.1653) \tNS PDE Loss:  tensor(2220.0498)\n",
      "Iteration: 18800 \tTotal Loss: tensor(2637.5920)\n",
      "\tBC Loss:  tensor(23.1522) \tNS PDE Loss:  tensor(2614.4399)\n",
      "Iteration: 19000 \tTotal Loss: tensor(3300.8135)\n",
      "\tBC Loss:  tensor(23.1389) \tNS PDE Loss:  tensor(3277.6746)\n",
      "Iteration: 19200 \tTotal Loss: tensor(3534.8115)\n",
      "\tBC Loss:  tensor(23.1260) \tNS PDE Loss:  tensor(3511.6855)\n",
      "Iteration: 19400 \tTotal Loss: tensor(3136.9995)\n",
      "\tBC Loss:  tensor(23.1092) \tNS PDE Loss:  tensor(3113.8904)\n",
      "Iteration: 19600 \tTotal Loss: tensor(2149.2617)\n",
      "\tBC Loss:  tensor(23.0939) \tNS PDE Loss:  tensor(2126.1677)\n",
      "Iteration: 19800 \tTotal Loss: tensor(2232.2576)\n",
      "\tBC Loss:  tensor(23.0726) \tNS PDE Loss:  tensor(2209.1851)\n",
      "Iteration: 20000 \tTotal Loss: tensor(3257.4722)\n",
      "\tBC Loss:  tensor(23.0543) \tNS PDE Loss:  tensor(3234.4180)\n",
      "Iteration: 20200 \tTotal Loss: tensor(2235.9595)\n",
      "\tBC Loss:  tensor(23.0419) \tNS PDE Loss:  tensor(2212.9177)\n",
      "Iteration: 20400 \tTotal Loss: tensor(2448.3779)\n",
      "\tBC Loss:  tensor(23.0258) \tNS PDE Loss:  tensor(2425.3521)\n",
      "Iteration: 20600 \tTotal Loss: tensor(2790.0349)\n",
      "\tBC Loss:  tensor(23.0079) \tNS PDE Loss:  tensor(2767.0271)\n",
      "Iteration: 20800 \tTotal Loss: tensor(3895.8823)\n",
      "\tBC Loss:  tensor(22.9929) \tNS PDE Loss:  tensor(3872.8894)\n",
      "Iteration: 21000 \tTotal Loss: tensor(2631.4539)\n",
      "\tBC Loss:  tensor(22.9781) \tNS PDE Loss:  tensor(2608.4758)\n",
      "Iteration: 21200 \tTotal Loss: tensor(2427.1138)\n",
      "\tBC Loss:  tensor(22.9657) \tNS PDE Loss:  tensor(2404.1482)\n",
      "Iteration: 21400 \tTotal Loss: tensor(3643.5535)\n",
      "\tBC Loss:  tensor(22.9527) \tNS PDE Loss:  tensor(3620.6008)\n",
      "Iteration: 21600 \tTotal Loss: tensor(2390.0762)\n",
      "\tBC Loss:  tensor(22.9406) \tNS PDE Loss:  tensor(2367.1355)\n",
      "Iteration: 21800 \tTotal Loss: tensor(2463.8022)\n",
      "\tBC Loss:  tensor(22.9247) \tNS PDE Loss:  tensor(2440.8774)\n",
      "Iteration: 22000 \tTotal Loss: tensor(2283.3604)\n",
      "\tBC Loss:  tensor(22.9094) \tNS PDE Loss:  tensor(2260.4509)\n",
      "Iteration: 22200 \tTotal Loss: tensor(2280.6299)\n",
      "\tBC Loss:  tensor(22.8962) \tNS PDE Loss:  tensor(2257.7336)\n",
      "Iteration: 22400 \tTotal Loss: tensor(2885.0325)\n",
      "\tBC Loss:  tensor(22.8820) \tNS PDE Loss:  tensor(2862.1504)\n",
      "Iteration: 22600 \tTotal Loss: tensor(2465.4590)\n",
      "\tBC Loss:  tensor(22.8664) \tNS PDE Loss:  tensor(2442.5925)\n",
      "Iteration: 22800 \tTotal Loss: tensor(2717.2773)\n",
      "\tBC Loss:  tensor(22.8532) \tNS PDE Loss:  tensor(2694.4241)\n",
      "Iteration: 23000 \tTotal Loss: tensor(2056.9934)\n",
      "\tBC Loss:  tensor(22.8411) \tNS PDE Loss:  tensor(2034.1523)\n",
      "Iteration: 23200 \tTotal Loss: tensor(2576.9150)\n",
      "\tBC Loss:  tensor(22.8275) \tNS PDE Loss:  tensor(2554.0876)\n",
      "Iteration: 23400 \tTotal Loss: tensor(2037.7552)\n",
      "\tBC Loss:  tensor(22.8171) \tNS PDE Loss:  tensor(2014.9382)\n",
      "Iteration: 23600 \tTotal Loss: tensor(2012.1565)\n",
      "\tBC Loss:  tensor(22.8006) \tNS PDE Loss:  tensor(1989.3560)\n",
      "Iteration: 23800 \tTotal Loss: tensor(2692.7595)\n",
      "\tBC Loss:  tensor(22.7854) \tNS PDE Loss:  tensor(2669.9741)\n",
      "Iteration: 24000 \tTotal Loss: tensor(2635.7959)\n",
      "\tBC Loss:  tensor(22.7700) \tNS PDE Loss:  tensor(2613.0259)\n",
      "Iteration: 24200 \tTotal Loss: tensor(2886.6912)\n",
      "\tBC Loss:  tensor(22.7572) \tNS PDE Loss:  tensor(2863.9341)\n",
      "Iteration: 24400 \tTotal Loss: tensor(2041.7518)\n",
      "\tBC Loss:  tensor(22.7408) \tNS PDE Loss:  tensor(2019.0111)\n",
      "Iteration: 24600 \tTotal Loss: tensor(3743.2651)\n",
      "\tBC Loss:  tensor(22.7265) \tNS PDE Loss:  tensor(3720.5386)\n",
      "Iteration: 24800 \tTotal Loss: tensor(2136.2498)\n",
      "\tBC Loss:  tensor(22.7137) \tNS PDE Loss:  tensor(2113.5361)\n",
      "Iteration: 25000 \tTotal Loss: tensor(2534.3333)\n",
      "\tBC Loss:  tensor(22.6974) \tNS PDE Loss:  tensor(2511.6357)\n",
      "Iteration: 25200 \tTotal Loss: tensor(2073.5945)\n",
      "\tBC Loss:  tensor(22.6828) \tNS PDE Loss:  tensor(2050.9116)\n",
      "Iteration: 25400 \tTotal Loss: tensor(2412.5007)\n",
      "\tBC Loss:  tensor(22.6705) \tNS PDE Loss:  tensor(2389.8301)\n",
      "Iteration: 25600 \tTotal Loss: tensor(2874.1960)\n",
      "\tBC Loss:  tensor(22.6560) \tNS PDE Loss:  tensor(2851.5400)\n",
      "Iteration: 25800 \tTotal Loss: tensor(2201.1643)\n",
      "\tBC Loss:  tensor(22.6400) \tNS PDE Loss:  tensor(2178.5244)\n",
      "Iteration: 26000 \tTotal Loss: tensor(2381.1218)\n",
      "\tBC Loss:  tensor(22.6235) \tNS PDE Loss:  tensor(2358.4983)\n",
      "Iteration: 26200 \tTotal Loss: tensor(2334.5361)\n",
      "\tBC Loss:  tensor(22.6108) \tNS PDE Loss:  tensor(2311.9253)\n",
      "Iteration: 26400 \tTotal Loss: tensor(2434.5708)\n",
      "\tBC Loss:  tensor(22.5979) \tNS PDE Loss:  tensor(2411.9729)\n",
      "Iteration: 26600 \tTotal Loss: tensor(2184.8809)\n",
      "\tBC Loss:  tensor(22.5835) \tNS PDE Loss:  tensor(2162.2974)\n",
      "Iteration: 26800 \tTotal Loss: tensor(2318.1191)\n",
      "\tBC Loss:  tensor(22.5688) \tNS PDE Loss:  tensor(2295.5503)\n",
      "Iteration: 27000 \tTotal Loss: tensor(2104.9978)\n",
      "\tBC Loss:  tensor(22.5571) \tNS PDE Loss:  tensor(2082.4407)\n",
      "Iteration: 27200 \tTotal Loss: tensor(2025.0924)\n",
      "\tBC Loss:  tensor(22.5451) \tNS PDE Loss:  tensor(2002.5472)\n",
      "Iteration: 27400 \tTotal Loss: tensor(2827.7336)\n",
      "\tBC Loss:  tensor(22.5306) \tNS PDE Loss:  tensor(2805.2031)\n",
      "Iteration: 27600 \tTotal Loss: tensor(2271.4009)\n",
      "\tBC Loss:  tensor(22.5167) \tNS PDE Loss:  tensor(2248.8843)\n",
      "Iteration: 27800 \tTotal Loss: tensor(2827.7285)\n",
      "\tBC Loss:  tensor(22.5049) \tNS PDE Loss:  tensor(2805.2236)\n",
      "Iteration: 28000 \tTotal Loss: tensor(2028.7292)\n",
      "\tBC Loss:  tensor(22.4939) \tNS PDE Loss:  tensor(2006.2354)\n",
      "Iteration: 28200 \tTotal Loss: tensor(1986.3065)\n",
      "\tBC Loss:  tensor(22.4798) \tNS PDE Loss:  tensor(1963.8268)\n",
      "Iteration: 28400 \tTotal Loss: tensor(2013.8679)\n",
      "\tBC Loss:  tensor(22.4647) \tNS PDE Loss:  tensor(1991.4032)\n",
      "Iteration: 28600 \tTotal Loss: tensor(2295.6309)\n",
      "\tBC Loss:  tensor(22.4496) \tNS PDE Loss:  tensor(2273.1814)\n",
      "Iteration: 28800 \tTotal Loss: tensor(2063.4426)\n",
      "\tBC Loss:  tensor(22.4343) \tNS PDE Loss:  tensor(2041.0083)\n",
      "Iteration: 29000 \tTotal Loss: tensor(1970.9219)\n",
      "\tBC Loss:  tensor(22.4224) \tNS PDE Loss:  tensor(1948.4995)\n",
      "Iteration: 29200 \tTotal Loss: tensor(1963.1287)\n",
      "\tBC Loss:  tensor(22.4110) \tNS PDE Loss:  tensor(1940.7177)\n",
      "Iteration: 29400 \tTotal Loss: tensor(2487.7632)\n",
      "\tBC Loss:  tensor(22.3964) \tNS PDE Loss:  tensor(2465.3667)\n",
      "Iteration: 29600 \tTotal Loss: tensor(2107.7732)\n",
      "\tBC Loss:  tensor(22.3806) \tNS PDE Loss:  tensor(2085.3926)\n",
      "Iteration: 29800 \tTotal Loss: tensor(2593.7336)\n",
      "\tBC Loss:  tensor(22.3646) \tNS PDE Loss:  tensor(2571.3689)\n",
      "Iteration: 30000 \tTotal Loss: tensor(1948.2970)\n",
      "\tBC Loss:  tensor(22.3501) \tNS PDE Loss:  tensor(1925.9469)\n",
      "Iteration: 30200 \tTotal Loss: tensor(2246.6555)\n",
      "\tBC Loss:  tensor(22.3354) \tNS PDE Loss:  tensor(2224.3201)\n",
      "Iteration: 30400 \tTotal Loss: tensor(3653.1780)\n",
      "\tBC Loss:  tensor(22.3213) \tNS PDE Loss:  tensor(3630.8567)\n",
      "Iteration: 30600 \tTotal Loss: tensor(3537.2700)\n",
      "\tBC Loss:  tensor(22.3081) \tNS PDE Loss:  tensor(3514.9619)\n",
      "Iteration: 30800 \tTotal Loss: tensor(1946.4518)\n",
      "\tBC Loss:  tensor(22.2960) \tNS PDE Loss:  tensor(1924.1558)\n",
      "Iteration: 31000 \tTotal Loss: tensor(2102.0659)\n",
      "\tBC Loss:  tensor(22.2831) \tNS PDE Loss:  tensor(2079.7827)\n",
      "Iteration: 31200 \tTotal Loss: tensor(2397.9348)\n",
      "\tBC Loss:  tensor(22.2706) \tNS PDE Loss:  tensor(2375.6643)\n",
      "Iteration: 31400 \tTotal Loss: tensor(2606.3789)\n",
      "\tBC Loss:  tensor(22.2582) \tNS PDE Loss:  tensor(2584.1206)\n",
      "Iteration: 31600 \tTotal Loss: tensor(2269.6785)\n",
      "\tBC Loss:  tensor(22.2474) \tNS PDE Loss:  tensor(2247.4312)\n",
      "Iteration: 31800 \tTotal Loss: tensor(2081.4905)\n",
      "\tBC Loss:  tensor(22.2329) \tNS PDE Loss:  tensor(2059.2576)\n",
      "Iteration: 32000 \tTotal Loss: tensor(2231.8347)\n",
      "\tBC Loss:  tensor(22.2164) \tNS PDE Loss:  tensor(2209.6184)\n",
      "Iteration: 32200 \tTotal Loss: tensor(1999.0353)\n",
      "\tBC Loss:  tensor(22.2062) \tNS PDE Loss:  tensor(1976.8291)\n",
      "Iteration: 32400 \tTotal Loss: tensor(2026.9935)\n",
      "\tBC Loss:  tensor(22.1906) \tNS PDE Loss:  tensor(2004.8030)\n",
      "Iteration: 32600 \tTotal Loss: tensor(2261.0566)\n",
      "\tBC Loss:  tensor(22.1753) \tNS PDE Loss:  tensor(2238.8813)\n",
      "Iteration: 32800 \tTotal Loss: tensor(2738.6284)\n",
      "\tBC Loss:  tensor(22.1612) \tNS PDE Loss:  tensor(2716.4673)\n",
      "Iteration: 33000 \tTotal Loss: tensor(3057.0640)\n",
      "\tBC Loss:  tensor(22.1479) \tNS PDE Loss:  tensor(3034.9160)\n",
      "Iteration: 33200 \tTotal Loss: tensor(1931.0713)\n",
      "\tBC Loss:  tensor(22.1358) \tNS PDE Loss:  tensor(1908.9355)\n",
      "Iteration: 33400 \tTotal Loss: tensor(2668.0493)\n",
      "\tBC Loss:  tensor(22.1223) \tNS PDE Loss:  tensor(2645.9270)\n",
      "Iteration: 33600 \tTotal Loss: tensor(2095.6902)\n",
      "\tBC Loss:  tensor(22.1068) \tNS PDE Loss:  tensor(2073.5833)\n",
      "Iteration: 33800 \tTotal Loss: tensor(2164.8672)\n",
      "\tBC Loss:  tensor(22.0947) \tNS PDE Loss:  tensor(2142.7725)\n",
      "Iteration: 34000 \tTotal Loss: tensor(2269.4287)\n",
      "\tBC Loss:  tensor(22.0800) \tNS PDE Loss:  tensor(2247.3486)\n",
      "Iteration: 34200 \tTotal Loss: tensor(1888.6260)\n",
      "\tBC Loss:  tensor(22.0667) \tNS PDE Loss:  tensor(1866.5593)\n",
      "Iteration: 34400 \tTotal Loss: tensor(2917.9333)\n",
      "\tBC Loss:  tensor(22.0550) \tNS PDE Loss:  tensor(2895.8784)\n",
      "Iteration: 34600 \tTotal Loss: tensor(1915.1792)\n",
      "\tBC Loss:  tensor(22.0398) \tNS PDE Loss:  tensor(1893.1394)\n",
      "Iteration: 34800 \tTotal Loss: tensor(2007.4611)\n",
      "\tBC Loss:  tensor(22.0255) \tNS PDE Loss:  tensor(1985.4355)\n",
      "Iteration: 35000 \tTotal Loss: tensor(2188.4194)\n",
      "\tBC Loss:  tensor(22.0095) \tNS PDE Loss:  tensor(2166.4099)\n",
      "Iteration: 35200 \tTotal Loss: tensor(2358.6323)\n",
      "\tBC Loss:  tensor(21.9972) \tNS PDE Loss:  tensor(2336.6353)\n",
      "Iteration: 35400 \tTotal Loss: tensor(1816.4597)\n",
      "\tBC Loss:  tensor(21.9852) \tNS PDE Loss:  tensor(1794.4746)\n",
      "Iteration: 35600 \tTotal Loss: tensor(2868.1431)\n",
      "\tBC Loss:  tensor(21.9698) \tNS PDE Loss:  tensor(2846.1733)\n",
      "Iteration: 35800 \tTotal Loss: tensor(2315.5398)\n",
      "\tBC Loss:  tensor(21.9574) \tNS PDE Loss:  tensor(2293.5825)\n",
      "Iteration: 36000 \tTotal Loss: tensor(2112.2000)\n",
      "\tBC Loss:  tensor(21.9412) \tNS PDE Loss:  tensor(2090.2588)\n",
      "Iteration: 36200 \tTotal Loss: tensor(2061.7266)\n",
      "\tBC Loss:  tensor(21.9274) \tNS PDE Loss:  tensor(2039.7991)\n",
      "Iteration: 36400 \tTotal Loss: tensor(2151.8926)\n",
      "\tBC Loss:  tensor(21.9152) \tNS PDE Loss:  tensor(2129.9773)\n",
      "Iteration: 36600 \tTotal Loss: tensor(1834.4872)\n",
      "\tBC Loss:  tensor(21.9033) \tNS PDE Loss:  tensor(1812.5839)\n",
      "Iteration: 36800 \tTotal Loss: tensor(3047.1829)\n",
      "\tBC Loss:  tensor(21.8905) \tNS PDE Loss:  tensor(3025.2922)\n",
      "Iteration: 37000 \tTotal Loss: tensor(1952.6904)\n",
      "\tBC Loss:  tensor(21.8758) \tNS PDE Loss:  tensor(1930.8147)\n",
      "Iteration: 37200 \tTotal Loss: tensor(2356.1006)\n",
      "\tBC Loss:  tensor(21.8620) \tNS PDE Loss:  tensor(2334.2385)\n",
      "Iteration: 37400 \tTotal Loss: tensor(2014.8063)\n",
      "\tBC Loss:  tensor(21.8509) \tNS PDE Loss:  tensor(1992.9553)\n",
      "Iteration: 37600 \tTotal Loss: tensor(3148.2222)\n",
      "\tBC Loss:  tensor(21.8395) \tNS PDE Loss:  tensor(3126.3826)\n",
      "Iteration: 37800 \tTotal Loss: tensor(2536.9363)\n",
      "\tBC Loss:  tensor(21.8236) \tNS PDE Loss:  tensor(2515.1125)\n",
      "Iteration: 38000 \tTotal Loss: tensor(3671.8167)\n",
      "\tBC Loss:  tensor(21.8117) \tNS PDE Loss:  tensor(3650.0049)\n",
      "Iteration: 38200 \tTotal Loss: tensor(2189.5669)\n",
      "\tBC Loss:  tensor(21.8002) \tNS PDE Loss:  tensor(2167.7668)\n",
      "Iteration: 38400 \tTotal Loss: tensor(2005.7654)\n",
      "\tBC Loss:  tensor(21.7864) \tNS PDE Loss:  tensor(1983.9790)\n",
      "Iteration: 38600 \tTotal Loss: tensor(2866.9136)\n",
      "\tBC Loss:  tensor(21.7734) \tNS PDE Loss:  tensor(2845.1401)\n",
      "Iteration: 38800 \tTotal Loss: tensor(1806.6129)\n",
      "\tBC Loss:  tensor(21.7640) \tNS PDE Loss:  tensor(1784.8489)\n",
      "Iteration: 39000 \tTotal Loss: tensor(3183.2546)\n",
      "\tBC Loss:  tensor(21.7489) \tNS PDE Loss:  tensor(3161.5056)\n",
      "Iteration: 39200 \tTotal Loss: tensor(2023.5651)\n",
      "\tBC Loss:  tensor(21.7353) \tNS PDE Loss:  tensor(2001.8297)\n",
      "Iteration: 39400 \tTotal Loss: tensor(1868.1328)\n",
      "\tBC Loss:  tensor(21.7258) \tNS PDE Loss:  tensor(1846.4070)\n",
      "Iteration: 39600 \tTotal Loss: tensor(1768.1294)\n",
      "\tBC Loss:  tensor(21.7107) \tNS PDE Loss:  tensor(1746.4187)\n",
      "Iteration: 39800 \tTotal Loss: tensor(2397.7327)\n",
      "\tBC Loss:  tensor(21.7002) \tNS PDE Loss:  tensor(2376.0325)\n",
      "Iteration: 40000 \tTotal Loss: tensor(2790.0381)\n",
      "\tBC Loss:  tensor(21.6875) \tNS PDE Loss:  tensor(2768.3506)\n",
      "Iteration: 40200 \tTotal Loss: tensor(1930.1875)\n",
      "\tBC Loss:  tensor(21.6831) \tNS PDE Loss:  tensor(1908.5044)\n",
      "Iteration: 40400 \tTotal Loss: tensor(2512.0671)\n",
      "\tBC Loss:  tensor(21.6694) \tNS PDE Loss:  tensor(2490.3977)\n",
      "Iteration: 40600 \tTotal Loss: tensor(1865.3571)\n",
      "\tBC Loss:  tensor(21.6573) \tNS PDE Loss:  tensor(1843.6997)\n",
      "Iteration: 40800 \tTotal Loss: tensor(2051.1157)\n",
      "\tBC Loss:  tensor(21.6435) \tNS PDE Loss:  tensor(2029.4722)\n",
      "Iteration: 41000 \tTotal Loss: tensor(1902.9231)\n",
      "\tBC Loss:  tensor(21.6342) \tNS PDE Loss:  tensor(1881.2889)\n",
      "Iteration: 41200 \tTotal Loss: tensor(2433.3718)\n",
      "\tBC Loss:  tensor(21.6225) \tNS PDE Loss:  tensor(2411.7493)\n",
      "Iteration: 41400 \tTotal Loss: tensor(1928.8403)\n",
      "\tBC Loss:  tensor(21.6129) \tNS PDE Loss:  tensor(1907.2274)\n",
      "Iteration: 41600 \tTotal Loss: tensor(1935.4163)\n",
      "\tBC Loss:  tensor(21.5998) \tNS PDE Loss:  tensor(1913.8165)\n",
      "Iteration: 41800 \tTotal Loss: tensor(1885.0256)\n",
      "\tBC Loss:  tensor(21.5878) \tNS PDE Loss:  tensor(1863.4379)\n",
      "Iteration: 42000 \tTotal Loss: tensor(2765.6318)\n",
      "\tBC Loss:  tensor(21.5793) \tNS PDE Loss:  tensor(2744.0525)\n",
      "Iteration: 42200 \tTotal Loss: tensor(1920.2494)\n",
      "\tBC Loss:  tensor(21.5689) \tNS PDE Loss:  tensor(1898.6804)\n",
      "Iteration: 42400 \tTotal Loss: tensor(1771.5439)\n",
      "\tBC Loss:  tensor(21.5590) \tNS PDE Loss:  tensor(1749.9850)\n",
      "Iteration: 42600 \tTotal Loss: tensor(1890.9470)\n",
      "\tBC Loss:  tensor(21.5481) \tNS PDE Loss:  tensor(1869.3989)\n",
      "Iteration: 42800 \tTotal Loss: tensor(1893.6301)\n",
      "\tBC Loss:  tensor(21.5370) \tNS PDE Loss:  tensor(1872.0931)\n",
      "Iteration: 43000 \tTotal Loss: tensor(2415.5513)\n",
      "\tBC Loss:  tensor(21.5269) \tNS PDE Loss:  tensor(2394.0244)\n",
      "Iteration: 43200 \tTotal Loss: tensor(1650.5444)\n",
      "\tBC Loss:  tensor(21.5178) \tNS PDE Loss:  tensor(1629.0266)\n",
      "Iteration: 43400 \tTotal Loss: tensor(2260.8320)\n",
      "\tBC Loss:  tensor(21.5093) \tNS PDE Loss:  tensor(2239.3228)\n",
      "Iteration: 43600 \tTotal Loss: tensor(2308.8835)\n",
      "\tBC Loss:  tensor(21.4980) \tNS PDE Loss:  tensor(2287.3855)\n",
      "Iteration: 43800 \tTotal Loss: tensor(2344.5720)\n",
      "\tBC Loss:  tensor(21.4876) \tNS PDE Loss:  tensor(2323.0845)\n",
      "Iteration: 44000 \tTotal Loss: tensor(1732.9198)\n",
      "\tBC Loss:  tensor(21.4760) \tNS PDE Loss:  tensor(1711.4438)\n",
      "Iteration: 44200 \tTotal Loss: tensor(1724.8831)\n",
      "\tBC Loss:  tensor(21.4646) \tNS PDE Loss:  tensor(1703.4185)\n",
      "Iteration: 44400 \tTotal Loss: tensor(2270.0837)\n",
      "\tBC Loss:  tensor(21.4522) \tNS PDE Loss:  tensor(2248.6316)\n",
      "Iteration: 44600 \tTotal Loss: tensor(2697.0374)\n",
      "\tBC Loss:  tensor(21.4436) \tNS PDE Loss:  tensor(2675.5938)\n",
      "Iteration: 44800 \tTotal Loss: tensor(3626.4639)\n",
      "\tBC Loss:  tensor(21.4290) \tNS PDE Loss:  tensor(3605.0349)\n",
      "Iteration: 45000 \tTotal Loss: tensor(2681.7871)\n",
      "\tBC Loss:  tensor(21.4210) \tNS PDE Loss:  tensor(2660.3662)\n",
      "Iteration: 45200 \tTotal Loss: tensor(2081.4097)\n",
      "\tBC Loss:  tensor(21.4089) \tNS PDE Loss:  tensor(2060.0007)\n",
      "Iteration: 45400 \tTotal Loss: tensor(1747.6057)\n",
      "\tBC Loss:  tensor(21.3964) \tNS PDE Loss:  tensor(1726.2094)\n",
      "Iteration: 45600 \tTotal Loss: tensor(1792.3047)\n",
      "\tBC Loss:  tensor(21.3876) \tNS PDE Loss:  tensor(1770.9171)\n",
      "Iteration: 45800 \tTotal Loss: tensor(2729.9731)\n",
      "\tBC Loss:  tensor(21.3742) \tNS PDE Loss:  tensor(2708.5989)\n",
      "Iteration: 46000 \tTotal Loss: tensor(2084.1743)\n",
      "\tBC Loss:  tensor(21.3648) \tNS PDE Loss:  tensor(2062.8096)\n",
      "Iteration: 46200 \tTotal Loss: tensor(2602.1384)\n",
      "\tBC Loss:  tensor(21.3539) \tNS PDE Loss:  tensor(2580.7844)\n",
      "Iteration: 46400 \tTotal Loss: tensor(2008.7350)\n",
      "\tBC Loss:  tensor(21.3388) \tNS PDE Loss:  tensor(1987.3962)\n",
      "Iteration: 46600 \tTotal Loss: tensor(2732.5552)\n",
      "\tBC Loss:  tensor(21.3271) \tNS PDE Loss:  tensor(2711.2280)\n",
      "Iteration: 46800 \tTotal Loss: tensor(3534.3450)\n",
      "\tBC Loss:  tensor(21.3159) \tNS PDE Loss:  tensor(3513.0291)\n",
      "Iteration: 47000 \tTotal Loss: tensor(2058.2671)\n",
      "\tBC Loss:  tensor(21.3087) \tNS PDE Loss:  tensor(2036.9584)\n",
      "Iteration: 47200 \tTotal Loss: tensor(1810.1659)\n",
      "\tBC Loss:  tensor(21.2951) \tNS PDE Loss:  tensor(1788.8707)\n",
      "Iteration: 47400 \tTotal Loss: tensor(1666.9198)\n",
      "\tBC Loss:  tensor(21.2834) \tNS PDE Loss:  tensor(1645.6364)\n",
      "Iteration: 47600 \tTotal Loss: tensor(3951.9822)\n",
      "\tBC Loss:  tensor(21.2754) \tNS PDE Loss:  tensor(3930.7068)\n",
      "Iteration: 47800 \tTotal Loss: tensor(1900.8123)\n",
      "\tBC Loss:  tensor(21.2624) \tNS PDE Loss:  tensor(1879.5499)\n",
      "Iteration: 48000 \tTotal Loss: tensor(2454.8335)\n",
      "\tBC Loss:  tensor(21.2511) \tNS PDE Loss:  tensor(2433.5825)\n",
      "Iteration: 48200 \tTotal Loss: tensor(2120.0728)\n",
      "\tBC Loss:  tensor(21.2406) \tNS PDE Loss:  tensor(2098.8320)\n",
      "Iteration: 48400 \tTotal Loss: tensor(1682.4249)\n",
      "\tBC Loss:  tensor(21.2300) \tNS PDE Loss:  tensor(1661.1949)\n",
      "Iteration: 48600 \tTotal Loss: tensor(1788.3280)\n",
      "\tBC Loss:  tensor(21.2197) \tNS PDE Loss:  tensor(1767.1084)\n",
      "Iteration: 48800 \tTotal Loss: tensor(1786.9047)\n",
      "\tBC Loss:  tensor(21.2092) \tNS PDE Loss:  tensor(1765.6954)\n",
      "Iteration: 49000 \tTotal Loss: tensor(1646.0444)\n",
      "\tBC Loss:  tensor(21.1996) \tNS PDE Loss:  tensor(1624.8448)\n",
      "Iteration: 49200 \tTotal Loss: tensor(2259.6179)\n",
      "\tBC Loss:  tensor(21.1888) \tNS PDE Loss:  tensor(2238.4292)\n",
      "Iteration: 49400 \tTotal Loss: tensor(2026.4163)\n",
      "\tBC Loss:  tensor(21.1760) \tNS PDE Loss:  tensor(2005.2402)\n",
      "Iteration: 49600 \tTotal Loss: tensor(1700.1818)\n",
      "\tBC Loss:  tensor(21.1648) \tNS PDE Loss:  tensor(1679.0170)\n",
      "Iteration: 49800 \tTotal Loss: tensor(1688.7756)\n",
      "\tBC Loss:  tensor(21.1533) \tNS PDE Loss:  tensor(1667.6224)\n",
      "Iteration: 50000 \tTotal Loss: tensor(1701.8223)\n",
      "\tBC Loss:  tensor(21.1437) \tNS PDE Loss:  tensor(1680.6786)\n",
      "Current Final Time: 0.1 Current Learning Rate:  0.0001\n",
      "Iteration: 200 \tTotal Loss: tensor(27913.9844)\n",
      "\tBC Loss:  tensor(21.1954) \tNS PDE Loss:  tensor(27892.7891)\n",
      "Iteration: 400 \tTotal Loss: tensor(22829.5117)\n",
      "\tBC Loss:  tensor(21.1886) \tNS PDE Loss:  tensor(22808.3223)\n",
      "Iteration: 600 \tTotal Loss: tensor(17717.7832)\n",
      "\tBC Loss:  tensor(21.1707) \tNS PDE Loss:  tensor(17696.6133)\n",
      "Iteration: 800 \tTotal Loss: tensor(15108.5420)\n",
      "\tBC Loss:  tensor(21.1462) \tNS PDE Loss:  tensor(15087.3955)\n",
      "Iteration: 1000 \tTotal Loss: tensor(16182.9619)\n",
      "\tBC Loss:  tensor(21.1317) \tNS PDE Loss:  tensor(16161.8301)\n",
      "Iteration: 1200 \tTotal Loss: tensor(17947.0723)\n",
      "\tBC Loss:  tensor(21.1091) \tNS PDE Loss:  tensor(17925.9629)\n",
      "Iteration: 1400 \tTotal Loss: tensor(14043.3838)\n",
      "\tBC Loss:  tensor(21.0730) \tNS PDE Loss:  tensor(14022.3105)\n",
      "Iteration: 1600 \tTotal Loss: tensor(13825.4229)\n",
      "\tBC Loss:  tensor(21.0264) \tNS PDE Loss:  tensor(13804.3965)\n",
      "Iteration: 1800 \tTotal Loss: tensor(15162.0723)\n",
      "\tBC Loss:  tensor(20.9721) \tNS PDE Loss:  tensor(15141.1006)\n",
      "Iteration: 2000 \tTotal Loss: tensor(10417.0439)\n",
      "\tBC Loss:  tensor(20.9177) \tNS PDE Loss:  tensor(10396.1260)\n",
      "Iteration: 2200 \tTotal Loss: tensor(21964.3340)\n",
      "\tBC Loss:  tensor(20.8599) \tNS PDE Loss:  tensor(21943.4746)\n",
      "Iteration: 2400 \tTotal Loss: tensor(13899.4961)\n",
      "\tBC Loss:  tensor(20.8065) \tNS PDE Loss:  tensor(13878.6895)\n",
      "Iteration: 2600 \tTotal Loss: tensor(12503.0273)\n",
      "\tBC Loss:  tensor(20.7446) \tNS PDE Loss:  tensor(12482.2832)\n",
      "Iteration: 2800 \tTotal Loss: tensor(11552.8213)\n",
      "\tBC Loss:  tensor(20.6755) \tNS PDE Loss:  tensor(11532.1455)\n",
      "Iteration: 3000 \tTotal Loss: tensor(11568.6709)\n",
      "\tBC Loss:  tensor(20.5959) \tNS PDE Loss:  tensor(11548.0752)\n",
      "Iteration: 3200 \tTotal Loss: tensor(12638.6289)\n",
      "\tBC Loss:  tensor(20.5029) \tNS PDE Loss:  tensor(12618.1260)\n",
      "Iteration: 3400 \tTotal Loss: tensor(8792.1797)\n",
      "\tBC Loss:  tensor(20.4208) \tNS PDE Loss:  tensor(8771.7588)\n",
      "Iteration: 3600 \tTotal Loss: tensor(6453.0732)\n",
      "\tBC Loss:  tensor(20.3630) \tNS PDE Loss:  tensor(6432.7104)\n",
      "Iteration: 3800 \tTotal Loss: tensor(7747.1484)\n",
      "\tBC Loss:  tensor(20.3228) \tNS PDE Loss:  tensor(7726.8257)\n",
      "Iteration: 4000 \tTotal Loss: tensor(6702.3950)\n",
      "\tBC Loss:  tensor(20.2927) \tNS PDE Loss:  tensor(6682.1025)\n",
      "Iteration: 4200 \tTotal Loss: tensor(6699.1787)\n",
      "\tBC Loss:  tensor(20.2717) \tNS PDE Loss:  tensor(6678.9072)\n",
      "Iteration: 4400 \tTotal Loss: tensor(6243.9297)\n",
      "\tBC Loss:  tensor(20.2416) \tNS PDE Loss:  tensor(6223.6880)\n",
      "Iteration: 4600 \tTotal Loss: tensor(8857.4414)\n",
      "\tBC Loss:  tensor(20.2245) \tNS PDE Loss:  tensor(8837.2168)\n",
      "Iteration: 4800 \tTotal Loss: tensor(7288.6973)\n",
      "\tBC Loss:  tensor(20.2012) \tNS PDE Loss:  tensor(7268.4961)\n",
      "Iteration: 5000 \tTotal Loss: tensor(4833.7026)\n",
      "\tBC Loss:  tensor(20.1769) \tNS PDE Loss:  tensor(4813.5259)\n",
      "Iteration: 5200 \tTotal Loss: tensor(11697.3740)\n",
      "\tBC Loss:  tensor(20.1520) \tNS PDE Loss:  tensor(11677.2217)\n",
      "Iteration: 5400 \tTotal Loss: tensor(7535.8169)\n",
      "\tBC Loss:  tensor(20.1289) \tNS PDE Loss:  tensor(7515.6880)\n",
      "Iteration: 5600 \tTotal Loss: tensor(10282.2109)\n",
      "\tBC Loss:  tensor(20.1078) \tNS PDE Loss:  tensor(10262.1035)\n",
      "Iteration: 5800 \tTotal Loss: tensor(4068.6174)\n",
      "\tBC Loss:  tensor(20.0831) \tNS PDE Loss:  tensor(4048.5342)\n",
      "Iteration: 6000 \tTotal Loss: tensor(14644.0107)\n",
      "\tBC Loss:  tensor(20.0650) \tNS PDE Loss:  tensor(14623.9453)\n",
      "Iteration: 6200 \tTotal Loss: tensor(9343.5762)\n",
      "\tBC Loss:  tensor(20.0448) \tNS PDE Loss:  tensor(9323.5312)\n",
      "Iteration: 6400 \tTotal Loss: tensor(4429.3140)\n",
      "\tBC Loss:  tensor(20.0267) \tNS PDE Loss:  tensor(4409.2871)\n",
      "Iteration: 6600 \tTotal Loss: tensor(5135.6792)\n",
      "\tBC Loss:  tensor(20.0079) \tNS PDE Loss:  tensor(5115.6714)\n",
      "Iteration: 6800 \tTotal Loss: tensor(9399.0342)\n",
      "\tBC Loss:  tensor(19.9886) \tNS PDE Loss:  tensor(9379.0459)\n",
      "Iteration: 7000 \tTotal Loss: tensor(12449.3545)\n",
      "\tBC Loss:  tensor(19.9711) \tNS PDE Loss:  tensor(12429.3838)\n",
      "Iteration: 7200 \tTotal Loss: tensor(3493.9529)\n",
      "\tBC Loss:  tensor(19.9491) \tNS PDE Loss:  tensor(3474.0039)\n",
      "Iteration: 7400 \tTotal Loss: tensor(5694.0049)\n",
      "\tBC Loss:  tensor(19.9317) \tNS PDE Loss:  tensor(5674.0732)\n",
      "Iteration: 7600 \tTotal Loss: tensor(10311.7354)\n",
      "\tBC Loss:  tensor(19.9137) \tNS PDE Loss:  tensor(10291.8213)\n",
      "Iteration: 7800 \tTotal Loss: tensor(13819.1758)\n",
      "\tBC Loss:  tensor(19.8993) \tNS PDE Loss:  tensor(13799.2764)\n",
      "Iteration: 8000 \tTotal Loss: tensor(10071.2910)\n",
      "\tBC Loss:  tensor(19.8818) \tNS PDE Loss:  tensor(10051.4092)\n",
      "Iteration: 8200 \tTotal Loss: tensor(4985.6045)\n",
      "\tBC Loss:  tensor(19.8650) \tNS PDE Loss:  tensor(4965.7393)\n",
      "Iteration: 8400 \tTotal Loss: tensor(10768.9043)\n",
      "\tBC Loss:  tensor(19.8485) \tNS PDE Loss:  tensor(10749.0557)\n",
      "Iteration: 8600 \tTotal Loss: tensor(6199.9248)\n",
      "\tBC Loss:  tensor(19.8352) \tNS PDE Loss:  tensor(6180.0898)\n",
      "Iteration: 8800 \tTotal Loss: tensor(7807.8882)\n",
      "\tBC Loss:  tensor(19.8153) \tNS PDE Loss:  tensor(7788.0728)\n",
      "Iteration: 9000 \tTotal Loss: tensor(5400.1714)\n",
      "\tBC Loss:  tensor(19.7944) \tNS PDE Loss:  tensor(5380.3770)\n",
      "Iteration: 9200 \tTotal Loss: tensor(7050.4097)\n",
      "\tBC Loss:  tensor(19.7747) \tNS PDE Loss:  tensor(7030.6348)\n",
      "Iteration: 9400 \tTotal Loss: tensor(7040.6699)\n",
      "\tBC Loss:  tensor(19.7585) \tNS PDE Loss:  tensor(7020.9116)\n",
      "Iteration: 9600 \tTotal Loss: tensor(4503.0039)\n",
      "\tBC Loss:  tensor(19.7408) \tNS PDE Loss:  tensor(4483.2632)\n",
      "Iteration: 9800 \tTotal Loss: tensor(7186.7915)\n",
      "\tBC Loss:  tensor(19.7212) \tNS PDE Loss:  tensor(7167.0703)\n",
      "Iteration: 10000 \tTotal Loss: tensor(10792.9121)\n",
      "\tBC Loss:  tensor(19.7026) \tNS PDE Loss:  tensor(10773.2100)\n",
      "Iteration: 10200 \tTotal Loss: tensor(6988.0967)\n",
      "\tBC Loss:  tensor(19.6839) \tNS PDE Loss:  tensor(6968.4126)\n",
      "Iteration: 10400 \tTotal Loss: tensor(9278.7148)\n",
      "\tBC Loss:  tensor(19.6672) \tNS PDE Loss:  tensor(9259.0479)\n",
      "Iteration: 10600 \tTotal Loss: tensor(5419.4272)\n",
      "\tBC Loss:  tensor(19.6475) \tNS PDE Loss:  tensor(5399.7798)\n",
      "Iteration: 10800 \tTotal Loss: tensor(7879.4517)\n",
      "\tBC Loss:  tensor(19.6304) \tNS PDE Loss:  tensor(7859.8213)\n",
      "Iteration: 11000 \tTotal Loss: tensor(4141.5757)\n",
      "\tBC Loss:  tensor(19.6105) \tNS PDE Loss:  tensor(4121.9653)\n",
      "Iteration: 11200 \tTotal Loss: tensor(6432.1162)\n",
      "\tBC Loss:  tensor(19.5968) \tNS PDE Loss:  tensor(6412.5195)\n",
      "Iteration: 11400 \tTotal Loss: tensor(6451.2007)\n",
      "\tBC Loss:  tensor(19.5768) \tNS PDE Loss:  tensor(6431.6240)\n",
      "Iteration: 11600 \tTotal Loss: tensor(6727.8872)\n",
      "\tBC Loss:  tensor(19.5588) \tNS PDE Loss:  tensor(6708.3286)\n",
      "Iteration: 11800 \tTotal Loss: tensor(6979.9468)\n",
      "\tBC Loss:  tensor(19.5384) \tNS PDE Loss:  tensor(6960.4082)\n",
      "Iteration: 12000 \tTotal Loss: tensor(8692.5566)\n",
      "\tBC Loss:  tensor(19.5205) \tNS PDE Loss:  tensor(8673.0361)\n",
      "Iteration: 12200 \tTotal Loss: tensor(4956.5864)\n",
      "\tBC Loss:  tensor(19.4982) \tNS PDE Loss:  tensor(4937.0884)\n",
      "Iteration: 12400 \tTotal Loss: tensor(7379.7295)\n",
      "\tBC Loss:  tensor(19.4806) \tNS PDE Loss:  tensor(7360.2490)\n",
      "Iteration: 12600 \tTotal Loss: tensor(8178.8589)\n",
      "\tBC Loss:  tensor(19.4616) \tNS PDE Loss:  tensor(8159.3975)\n",
      "Iteration: 12800 \tTotal Loss: tensor(4460.8057)\n",
      "\tBC Loss:  tensor(19.4430) \tNS PDE Loss:  tensor(4441.3628)\n",
      "Iteration: 13000 \tTotal Loss: tensor(7782.3296)\n",
      "\tBC Loss:  tensor(19.4259) \tNS PDE Loss:  tensor(7762.9038)\n",
      "Iteration: 13200 \tTotal Loss: tensor(8052.3384)\n",
      "\tBC Loss:  tensor(19.4079) \tNS PDE Loss:  tensor(8032.9307)\n",
      "Iteration: 13400 \tTotal Loss: tensor(10215.6865)\n",
      "\tBC Loss:  tensor(19.3880) \tNS PDE Loss:  tensor(10196.2988)\n",
      "Iteration: 13600 \tTotal Loss: tensor(7047.9141)\n",
      "\tBC Loss:  tensor(19.3701) \tNS PDE Loss:  tensor(7028.5439)\n",
      "Iteration: 13800 \tTotal Loss: tensor(4848.6616)\n",
      "\tBC Loss:  tensor(19.3470) \tNS PDE Loss:  tensor(4829.3145)\n",
      "Iteration: 14000 \tTotal Loss: tensor(5030.1240)\n",
      "\tBC Loss:  tensor(19.3339) \tNS PDE Loss:  tensor(5010.7900)\n",
      "Iteration: 14200 \tTotal Loss: tensor(5990.9990)\n",
      "\tBC Loss:  tensor(19.3091) \tNS PDE Loss:  tensor(5971.6899)\n",
      "Iteration: 14400 \tTotal Loss: tensor(8142.4883)\n",
      "\tBC Loss:  tensor(19.2826) \tNS PDE Loss:  tensor(8123.2056)\n",
      "Iteration: 14600 \tTotal Loss: tensor(3841.6514)\n",
      "\tBC Loss:  tensor(19.2677) \tNS PDE Loss:  tensor(3822.3838)\n",
      "Iteration: 14800 \tTotal Loss: tensor(5011.4673)\n",
      "\tBC Loss:  tensor(19.2425) \tNS PDE Loss:  tensor(4992.2246)\n",
      "Iteration: 15000 \tTotal Loss: tensor(3556.9458)\n",
      "\tBC Loss:  tensor(19.2276) \tNS PDE Loss:  tensor(3537.7183)\n",
      "Iteration: 15200 \tTotal Loss: tensor(9055.2119)\n",
      "\tBC Loss:  tensor(19.2109) \tNS PDE Loss:  tensor(9036.0010)\n",
      "Iteration: 15400 \tTotal Loss: tensor(6044.7109)\n",
      "\tBC Loss:  tensor(19.1930) \tNS PDE Loss:  tensor(6025.5181)\n",
      "Iteration: 15600 \tTotal Loss: tensor(7853.4053)\n",
      "\tBC Loss:  tensor(19.1721) \tNS PDE Loss:  tensor(7834.2329)\n",
      "Iteration: 15800 \tTotal Loss: tensor(7861.5576)\n",
      "\tBC Loss:  tensor(19.1557) \tNS PDE Loss:  tensor(7842.4019)\n",
      "Iteration: 16000 \tTotal Loss: tensor(4553.2534)\n",
      "\tBC Loss:  tensor(19.1398) \tNS PDE Loss:  tensor(4534.1138)\n",
      "Iteration: 16200 \tTotal Loss: tensor(5291.7378)\n",
      "\tBC Loss:  tensor(19.1233) \tNS PDE Loss:  tensor(5272.6147)\n",
      "Iteration: 16400 \tTotal Loss: tensor(5172.5190)\n",
      "\tBC Loss:  tensor(19.1040) \tNS PDE Loss:  tensor(5153.4150)\n",
      "Iteration: 16600 \tTotal Loss: tensor(3420.4221)\n",
      "\tBC Loss:  tensor(19.0836) \tNS PDE Loss:  tensor(3401.3386)\n",
      "Iteration: 16800 \tTotal Loss: tensor(6192.9941)\n",
      "\tBC Loss:  tensor(19.0635) \tNS PDE Loss:  tensor(6173.9307)\n",
      "Iteration: 17000 \tTotal Loss: tensor(6394.7900)\n",
      "\tBC Loss:  tensor(19.0441) \tNS PDE Loss:  tensor(6375.7461)\n",
      "Iteration: 17200 \tTotal Loss: tensor(7265.0034)\n",
      "\tBC Loss:  tensor(19.0295) \tNS PDE Loss:  tensor(7245.9741)\n",
      "Iteration: 17400 \tTotal Loss: tensor(5475.1479)\n",
      "\tBC Loss:  tensor(19.0072) \tNS PDE Loss:  tensor(5456.1406)\n",
      "Iteration: 17600 \tTotal Loss: tensor(5903.3940)\n",
      "\tBC Loss:  tensor(18.9914) \tNS PDE Loss:  tensor(5884.4028)\n",
      "Iteration: 17800 \tTotal Loss: tensor(4593.7090)\n",
      "\tBC Loss:  tensor(18.9730) \tNS PDE Loss:  tensor(4574.7358)\n",
      "Iteration: 18000 \tTotal Loss: tensor(4276.3247)\n",
      "\tBC Loss:  tensor(18.9562) \tNS PDE Loss:  tensor(4257.3687)\n",
      "Iteration: 18200 \tTotal Loss: tensor(4649.4233)\n",
      "\tBC Loss:  tensor(18.9419) \tNS PDE Loss:  tensor(4630.4814)\n",
      "Iteration: 18400 \tTotal Loss: tensor(4211.9346)\n",
      "\tBC Loss:  tensor(18.9209) \tNS PDE Loss:  tensor(4193.0137)\n",
      "Iteration: 18600 \tTotal Loss: tensor(6560.3999)\n",
      "\tBC Loss:  tensor(18.9069) \tNS PDE Loss:  tensor(6541.4932)\n",
      "Iteration: 18800 \tTotal Loss: tensor(9378.4072)\n",
      "\tBC Loss:  tensor(18.8924) \tNS PDE Loss:  tensor(9359.5146)\n",
      "Iteration: 19000 \tTotal Loss: tensor(7932.2578)\n",
      "\tBC Loss:  tensor(18.8761) \tNS PDE Loss:  tensor(7913.3818)\n",
      "Iteration: 19200 \tTotal Loss: tensor(3871.6423)\n",
      "\tBC Loss:  tensor(18.8579) \tNS PDE Loss:  tensor(3852.7844)\n",
      "Iteration: 19400 \tTotal Loss: tensor(9104.4619)\n",
      "\tBC Loss:  tensor(18.8423) \tNS PDE Loss:  tensor(9085.6191)\n",
      "Iteration: 19600 \tTotal Loss: tensor(4966.7490)\n",
      "\tBC Loss:  tensor(18.8284) \tNS PDE Loss:  tensor(4947.9209)\n",
      "Iteration: 19800 \tTotal Loss: tensor(5598.3818)\n",
      "\tBC Loss:  tensor(18.8116) \tNS PDE Loss:  tensor(5579.5703)\n",
      "Iteration: 20000 \tTotal Loss: tensor(7083.5186)\n",
      "\tBC Loss:  tensor(18.7986) \tNS PDE Loss:  tensor(7064.7197)\n",
      "Iteration: 20200 \tTotal Loss: tensor(7490.3794)\n",
      "\tBC Loss:  tensor(18.7807) \tNS PDE Loss:  tensor(7471.5986)\n",
      "Iteration: 20400 \tTotal Loss: tensor(4496.2065)\n",
      "\tBC Loss:  tensor(18.7565) \tNS PDE Loss:  tensor(4477.4502)\n",
      "Iteration: 20600 \tTotal Loss: tensor(6783.9634)\n",
      "\tBC Loss:  tensor(18.7406) \tNS PDE Loss:  tensor(6765.2227)\n",
      "Iteration: 20800 \tTotal Loss: tensor(5796.6392)\n",
      "\tBC Loss:  tensor(18.7279) \tNS PDE Loss:  tensor(5777.9111)\n",
      "Iteration: 21000 \tTotal Loss: tensor(8450.9492)\n",
      "\tBC Loss:  tensor(18.7141) \tNS PDE Loss:  tensor(8432.2354)\n",
      "Iteration: 21200 \tTotal Loss: tensor(4537.0723)\n",
      "\tBC Loss:  tensor(18.6988) \tNS PDE Loss:  tensor(4518.3735)\n",
      "Iteration: 21400 \tTotal Loss: tensor(5090.5425)\n",
      "\tBC Loss:  tensor(18.6820) \tNS PDE Loss:  tensor(5071.8604)\n",
      "Iteration: 21600 \tTotal Loss: tensor(3515.6797)\n",
      "\tBC Loss:  tensor(18.6664) \tNS PDE Loss:  tensor(3497.0132)\n",
      "Iteration: 21800 \tTotal Loss: tensor(8229.1621)\n",
      "\tBC Loss:  tensor(18.6484) \tNS PDE Loss:  tensor(8210.5137)\n",
      "Iteration: 22000 \tTotal Loss: tensor(3918.1016)\n",
      "\tBC Loss:  tensor(18.6325) \tNS PDE Loss:  tensor(3899.4690)\n",
      "Iteration: 22200 \tTotal Loss: tensor(4040.1428)\n",
      "\tBC Loss:  tensor(18.6248) \tNS PDE Loss:  tensor(4021.5181)\n",
      "Iteration: 22400 \tTotal Loss: tensor(6450.6235)\n",
      "\tBC Loss:  tensor(18.6110) \tNS PDE Loss:  tensor(6432.0127)\n",
      "Iteration: 22600 \tTotal Loss: tensor(6020.6313)\n",
      "\tBC Loss:  tensor(18.6017) \tNS PDE Loss:  tensor(6002.0298)\n",
      "Iteration: 22800 \tTotal Loss: tensor(5708.1548)\n",
      "\tBC Loss:  tensor(18.5873) \tNS PDE Loss:  tensor(5689.5674)\n",
      "Iteration: 23000 \tTotal Loss: tensor(6089.7729)\n",
      "\tBC Loss:  tensor(18.5695) \tNS PDE Loss:  tensor(6071.2036)\n",
      "Iteration: 23200 \tTotal Loss: tensor(8036.5312)\n",
      "\tBC Loss:  tensor(18.5591) \tNS PDE Loss:  tensor(8017.9722)\n",
      "Iteration: 23400 \tTotal Loss: tensor(5934.5977)\n",
      "\tBC Loss:  tensor(18.5469) \tNS PDE Loss:  tensor(5916.0508)\n",
      "Iteration: 23600 \tTotal Loss: tensor(7151.8525)\n",
      "\tBC Loss:  tensor(18.5309) \tNS PDE Loss:  tensor(7133.3218)\n",
      "Iteration: 23800 \tTotal Loss: tensor(3562.7727)\n",
      "\tBC Loss:  tensor(18.5173) \tNS PDE Loss:  tensor(3544.2554)\n",
      "Iteration: 24000 \tTotal Loss: tensor(6929.5806)\n",
      "\tBC Loss:  tensor(18.5029) \tNS PDE Loss:  tensor(6911.0776)\n",
      "Iteration: 24200 \tTotal Loss: tensor(6961.3638)\n",
      "\tBC Loss:  tensor(18.4891) \tNS PDE Loss:  tensor(6942.8745)\n",
      "Iteration: 24400 \tTotal Loss: tensor(5369.3501)\n",
      "\tBC Loss:  tensor(18.4742) \tNS PDE Loss:  tensor(5350.8760)\n",
      "Iteration: 24600 \tTotal Loss: tensor(4880.0840)\n",
      "\tBC Loss:  tensor(18.4641) \tNS PDE Loss:  tensor(4861.6196)\n",
      "Iteration: 24800 \tTotal Loss: tensor(8109.4775)\n",
      "\tBC Loss:  tensor(18.4537) \tNS PDE Loss:  tensor(8091.0239)\n",
      "Iteration: 25000 \tTotal Loss: tensor(4457.0254)\n",
      "\tBC Loss:  tensor(18.4406) \tNS PDE Loss:  tensor(4438.5850)\n",
      "Iteration: 25200 \tTotal Loss: tensor(6549.6328)\n",
      "\tBC Loss:  tensor(18.4215) \tNS PDE Loss:  tensor(6531.2114)\n",
      "Iteration: 25400 \tTotal Loss: tensor(3699.3254)\n",
      "\tBC Loss:  tensor(18.4095) \tNS PDE Loss:  tensor(3680.9160)\n",
      "Iteration: 25600 \tTotal Loss: tensor(3368.6169)\n",
      "\tBC Loss:  tensor(18.3963) \tNS PDE Loss:  tensor(3350.2207)\n",
      "Iteration: 25800 \tTotal Loss: tensor(6294.8716)\n",
      "\tBC Loss:  tensor(18.3851) \tNS PDE Loss:  tensor(6276.4863)\n",
      "Iteration: 26000 \tTotal Loss: tensor(5034.0137)\n",
      "\tBC Loss:  tensor(18.3704) \tNS PDE Loss:  tensor(5015.6431)\n",
      "Iteration: 26200 \tTotal Loss: tensor(4373.1475)\n",
      "\tBC Loss:  tensor(18.3545) \tNS PDE Loss:  tensor(4354.7930)\n",
      "Iteration: 26400 \tTotal Loss: tensor(3929.6172)\n",
      "\tBC Loss:  tensor(18.3414) \tNS PDE Loss:  tensor(3911.2759)\n",
      "Iteration: 26600 \tTotal Loss: tensor(4613.9199)\n",
      "\tBC Loss:  tensor(18.3251) \tNS PDE Loss:  tensor(4595.5947)\n",
      "Iteration: 26800 \tTotal Loss: tensor(5422.1812)\n",
      "\tBC Loss:  tensor(18.3086) \tNS PDE Loss:  tensor(5403.8726)\n",
      "Iteration: 27000 \tTotal Loss: tensor(4184.4253)\n",
      "\tBC Loss:  tensor(18.2975) \tNS PDE Loss:  tensor(4166.1279)\n",
      "Iteration: 27200 \tTotal Loss: tensor(4059.5911)\n",
      "\tBC Loss:  tensor(18.2834) \tNS PDE Loss:  tensor(4041.3076)\n",
      "Iteration: 27400 \tTotal Loss: tensor(4035.0063)\n",
      "\tBC Loss:  tensor(18.2714) \tNS PDE Loss:  tensor(4016.7349)\n",
      "Iteration: 27600 \tTotal Loss: tensor(9459.0244)\n",
      "\tBC Loss:  tensor(18.2633) \tNS PDE Loss:  tensor(9440.7607)\n",
      "Iteration: 27800 \tTotal Loss: tensor(4761.6777)\n",
      "\tBC Loss:  tensor(18.2533) \tNS PDE Loss:  tensor(4743.4243)\n",
      "Iteration: 28000 \tTotal Loss: tensor(4278.6304)\n",
      "\tBC Loss:  tensor(18.2403) \tNS PDE Loss:  tensor(4260.3901)\n",
      "Iteration: 28200 \tTotal Loss: tensor(3051.5791)\n",
      "\tBC Loss:  tensor(18.2279) \tNS PDE Loss:  tensor(3033.3513)\n",
      "Iteration: 28400 \tTotal Loss: tensor(6772.7412)\n",
      "\tBC Loss:  tensor(18.2132) \tNS PDE Loss:  tensor(6754.5278)\n",
      "Iteration: 28600 \tTotal Loss: tensor(5899.9575)\n",
      "\tBC Loss:  tensor(18.1974) \tNS PDE Loss:  tensor(5881.7603)\n",
      "Iteration: 28800 \tTotal Loss: tensor(3805.4380)\n",
      "\tBC Loss:  tensor(18.1857) \tNS PDE Loss:  tensor(3787.2522)\n",
      "Iteration: 29000 \tTotal Loss: tensor(7354.0400)\n",
      "\tBC Loss:  tensor(18.1706) \tNS PDE Loss:  tensor(7335.8696)\n",
      "Iteration: 29200 \tTotal Loss: tensor(5042.5122)\n",
      "\tBC Loss:  tensor(18.1576) \tNS PDE Loss:  tensor(5024.3545)\n",
      "Iteration: 29400 \tTotal Loss: tensor(3994.5669)\n",
      "\tBC Loss:  tensor(18.1458) \tNS PDE Loss:  tensor(3976.4211)\n",
      "Iteration: 29600 \tTotal Loss: tensor(7816.3911)\n",
      "\tBC Loss:  tensor(18.1312) \tNS PDE Loss:  tensor(7798.2598)\n",
      "Iteration: 29800 \tTotal Loss: tensor(6826.9492)\n",
      "\tBC Loss:  tensor(18.1208) \tNS PDE Loss:  tensor(6808.8286)\n",
      "Iteration: 30000 \tTotal Loss: tensor(4055.7991)\n",
      "\tBC Loss:  tensor(18.1145) \tNS PDE Loss:  tensor(4037.6846)\n",
      "Iteration: 30200 \tTotal Loss: tensor(4090.7319)\n",
      "\tBC Loss:  tensor(18.1030) \tNS PDE Loss:  tensor(4072.6289)\n",
      "Iteration: 30400 \tTotal Loss: tensor(5944.5410)\n",
      "\tBC Loss:  tensor(18.0858) \tNS PDE Loss:  tensor(5926.4551)\n",
      "Iteration: 30600 \tTotal Loss: tensor(3103.3694)\n",
      "\tBC Loss:  tensor(18.0712) \tNS PDE Loss:  tensor(3085.2981)\n",
      "Iteration: 30800 \tTotal Loss: tensor(6742.6089)\n",
      "\tBC Loss:  tensor(18.0571) \tNS PDE Loss:  tensor(6724.5518)\n",
      "Iteration: 31000 \tTotal Loss: tensor(7841.2593)\n",
      "\tBC Loss:  tensor(18.0456) \tNS PDE Loss:  tensor(7823.2139)\n",
      "Iteration: 31200 \tTotal Loss: tensor(4957.4780)\n",
      "\tBC Loss:  tensor(18.0318) \tNS PDE Loss:  tensor(4939.4463)\n",
      "Iteration: 31400 \tTotal Loss: tensor(5629.1855)\n",
      "\tBC Loss:  tensor(18.0202) \tNS PDE Loss:  tensor(5611.1655)\n",
      "Iteration: 31600 \tTotal Loss: tensor(6713.4575)\n",
      "\tBC Loss:  tensor(18.0062) \tNS PDE Loss:  tensor(6695.4512)\n",
      "Iteration: 31800 \tTotal Loss: tensor(7423.8813)\n",
      "\tBC Loss:  tensor(17.9954) \tNS PDE Loss:  tensor(7405.8857)\n",
      "Iteration: 32000 \tTotal Loss: tensor(3855.5168)\n",
      "\tBC Loss:  tensor(17.9827) \tNS PDE Loss:  tensor(3837.5342)\n",
      "Iteration: 32200 \tTotal Loss: tensor(6220.3408)\n",
      "\tBC Loss:  tensor(17.9698) \tNS PDE Loss:  tensor(6202.3711)\n",
      "Iteration: 32400 \tTotal Loss: tensor(4639.7812)\n",
      "\tBC Loss:  tensor(17.9541) \tNS PDE Loss:  tensor(4621.8271)\n",
      "Iteration: 32600 \tTotal Loss: tensor(3089.2021)\n",
      "\tBC Loss:  tensor(17.9401) \tNS PDE Loss:  tensor(3071.2620)\n",
      "Iteration: 32800 \tTotal Loss: tensor(4361.8301)\n",
      "\tBC Loss:  tensor(17.9325) \tNS PDE Loss:  tensor(4343.8975)\n",
      "Iteration: 33000 \tTotal Loss: tensor(3808.4165)\n",
      "\tBC Loss:  tensor(17.9198) \tNS PDE Loss:  tensor(3790.4968)\n",
      "Iteration: 33200 \tTotal Loss: tensor(5579.8945)\n",
      "\tBC Loss:  tensor(17.9098) \tNS PDE Loss:  tensor(5561.9849)\n",
      "Iteration: 33400 \tTotal Loss: tensor(3185.2273)\n",
      "\tBC Loss:  tensor(17.8947) \tNS PDE Loss:  tensor(3167.3325)\n",
      "Iteration: 33600 \tTotal Loss: tensor(3451.4099)\n",
      "\tBC Loss:  tensor(17.8834) \tNS PDE Loss:  tensor(3433.5264)\n",
      "Iteration: 33800 \tTotal Loss: tensor(3706.4573)\n",
      "\tBC Loss:  tensor(17.8731) \tNS PDE Loss:  tensor(3688.5842)\n",
      "Iteration: 34000 \tTotal Loss: tensor(4365.8125)\n",
      "\tBC Loss:  tensor(17.8604) \tNS PDE Loss:  tensor(4347.9521)\n",
      "Iteration: 34200 \tTotal Loss: tensor(7335.2725)\n",
      "\tBC Loss:  tensor(17.8438) \tNS PDE Loss:  tensor(7317.4287)\n",
      "Iteration: 34400 \tTotal Loss: tensor(8339.9346)\n",
      "\tBC Loss:  tensor(17.8339) \tNS PDE Loss:  tensor(8322.1006)\n",
      "Iteration: 34600 \tTotal Loss: tensor(3204.2844)\n",
      "\tBC Loss:  tensor(17.8205) \tNS PDE Loss:  tensor(3186.4639)\n",
      "Iteration: 34800 \tTotal Loss: tensor(3661.8091)\n",
      "\tBC Loss:  tensor(17.8079) \tNS PDE Loss:  tensor(3644.0012)\n",
      "Iteration: 35000 \tTotal Loss: tensor(5227.2139)\n",
      "\tBC Loss:  tensor(17.7920) \tNS PDE Loss:  tensor(5209.4219)\n",
      "Iteration: 35200 \tTotal Loss: tensor(6972.0957)\n",
      "\tBC Loss:  tensor(17.7761) \tNS PDE Loss:  tensor(6954.3198)\n",
      "Iteration: 35400 \tTotal Loss: tensor(8457.4160)\n",
      "\tBC Loss:  tensor(17.7687) \tNS PDE Loss:  tensor(8439.6475)\n",
      "Iteration: 35600 \tTotal Loss: tensor(11128.6094)\n",
      "\tBC Loss:  tensor(17.7544) \tNS PDE Loss:  tensor(11110.8555)\n",
      "Iteration: 35800 \tTotal Loss: tensor(4852.0112)\n",
      "\tBC Loss:  tensor(17.7421) \tNS PDE Loss:  tensor(4834.2690)\n",
      "Iteration: 36000 \tTotal Loss: tensor(4508.9453)\n",
      "\tBC Loss:  tensor(17.7300) \tNS PDE Loss:  tensor(4491.2153)\n",
      "Iteration: 36200 \tTotal Loss: tensor(4098.6465)\n",
      "\tBC Loss:  tensor(17.7180) \tNS PDE Loss:  tensor(4080.9287)\n",
      "Iteration: 36400 \tTotal Loss: tensor(6960.6890)\n",
      "\tBC Loss:  tensor(17.7050) \tNS PDE Loss:  tensor(6942.9839)\n",
      "Iteration: 36600 \tTotal Loss: tensor(8511.1641)\n",
      "\tBC Loss:  tensor(17.6888) \tNS PDE Loss:  tensor(8493.4756)\n",
      "Iteration: 36800 \tTotal Loss: tensor(5667.4243)\n",
      "\tBC Loss:  tensor(17.6763) \tNS PDE Loss:  tensor(5649.7480)\n",
      "Iteration: 37000 \tTotal Loss: tensor(2838.1184)\n",
      "\tBC Loss:  tensor(17.6619) \tNS PDE Loss:  tensor(2820.4565)\n",
      "Iteration: 37200 \tTotal Loss: tensor(3919.0754)\n",
      "\tBC Loss:  tensor(17.6460) \tNS PDE Loss:  tensor(3901.4294)\n",
      "Iteration: 37400 \tTotal Loss: tensor(8825.3887)\n",
      "\tBC Loss:  tensor(17.6344) \tNS PDE Loss:  tensor(8807.7539)\n",
      "Iteration: 37600 \tTotal Loss: tensor(5468.7070)\n",
      "\tBC Loss:  tensor(17.6252) \tNS PDE Loss:  tensor(5451.0820)\n",
      "Iteration: 37800 \tTotal Loss: tensor(3855.9929)\n",
      "\tBC Loss:  tensor(17.6099) \tNS PDE Loss:  tensor(3838.3831)\n",
      "Iteration: 38000 \tTotal Loss: tensor(2808.9148)\n",
      "\tBC Loss:  tensor(17.5956) \tNS PDE Loss:  tensor(2791.3191)\n",
      "Iteration: 38200 \tTotal Loss: tensor(5685.1768)\n",
      "\tBC Loss:  tensor(17.5811) \tNS PDE Loss:  tensor(5667.5957)\n",
      "Iteration: 38400 \tTotal Loss: tensor(3066.4312)\n",
      "\tBC Loss:  tensor(17.5702) \tNS PDE Loss:  tensor(3048.8611)\n",
      "Iteration: 38600 \tTotal Loss: tensor(3610.2551)\n",
      "\tBC Loss:  tensor(17.5568) \tNS PDE Loss:  tensor(3592.6982)\n",
      "Iteration: 38800 \tTotal Loss: tensor(5927.2808)\n",
      "\tBC Loss:  tensor(17.5472) \tNS PDE Loss:  tensor(5909.7334)\n",
      "Iteration: 39000 \tTotal Loss: tensor(4382.2080)\n",
      "\tBC Loss:  tensor(17.5335) \tNS PDE Loss:  tensor(4364.6743)\n",
      "Iteration: 39200 \tTotal Loss: tensor(4840.8760)\n",
      "\tBC Loss:  tensor(17.5240) \tNS PDE Loss:  tensor(4823.3521)\n",
      "Iteration: 39400 \tTotal Loss: tensor(2922.4387)\n",
      "\tBC Loss:  tensor(17.5083) \tNS PDE Loss:  tensor(2904.9304)\n",
      "Iteration: 39600 \tTotal Loss: tensor(3431.2322)\n",
      "\tBC Loss:  tensor(17.4969) \tNS PDE Loss:  tensor(3413.7354)\n",
      "Iteration: 39800 \tTotal Loss: tensor(6260.3652)\n",
      "\tBC Loss:  tensor(17.4844) \tNS PDE Loss:  tensor(6242.8809)\n",
      "Iteration: 40000 \tTotal Loss: tensor(5210.9443)\n",
      "\tBC Loss:  tensor(17.4701) \tNS PDE Loss:  tensor(5193.4741)\n",
      "Iteration: 40200 \tTotal Loss: tensor(5363.3770)\n",
      "\tBC Loss:  tensor(17.4575) \tNS PDE Loss:  tensor(5345.9194)\n",
      "Iteration: 40400 \tTotal Loss: tensor(4185.4565)\n",
      "\tBC Loss:  tensor(17.4475) \tNS PDE Loss:  tensor(4168.0093)\n",
      "Iteration: 40600 \tTotal Loss: tensor(3553.3691)\n",
      "\tBC Loss:  tensor(17.4357) \tNS PDE Loss:  tensor(3535.9333)\n",
      "Iteration: 40800 \tTotal Loss: tensor(5001.0708)\n",
      "\tBC Loss:  tensor(17.4270) \tNS PDE Loss:  tensor(4983.6440)\n",
      "Iteration: 41000 \tTotal Loss: tensor(5175.0977)\n",
      "\tBC Loss:  tensor(17.4118) \tNS PDE Loss:  tensor(5157.6860)\n",
      "Iteration: 41200 \tTotal Loss: tensor(6671.9805)\n",
      "\tBC Loss:  tensor(17.4003) \tNS PDE Loss:  tensor(6654.5801)\n",
      "Iteration: 41400 \tTotal Loss: tensor(6731.6387)\n",
      "\tBC Loss:  tensor(17.3851) \tNS PDE Loss:  tensor(6714.2534)\n",
      "Iteration: 41600 \tTotal Loss: tensor(2936.7593)\n",
      "\tBC Loss:  tensor(17.3768) \tNS PDE Loss:  tensor(2919.3826)\n",
      "Iteration: 41800 \tTotal Loss: tensor(2746.0420)\n",
      "\tBC Loss:  tensor(17.3660) \tNS PDE Loss:  tensor(2728.6760)\n",
      "Iteration: 42000 \tTotal Loss: tensor(4698.8789)\n",
      "\tBC Loss:  tensor(17.3556) \tNS PDE Loss:  tensor(4681.5234)\n",
      "Iteration: 42200 \tTotal Loss: tensor(4345.0601)\n",
      "\tBC Loss:  tensor(17.3420) \tNS PDE Loss:  tensor(4327.7183)\n",
      "Iteration: 42400 \tTotal Loss: tensor(3971.3550)\n",
      "\tBC Loss:  tensor(17.3319) \tNS PDE Loss:  tensor(3954.0232)\n",
      "Iteration: 42600 \tTotal Loss: tensor(4314.1855)\n",
      "\tBC Loss:  tensor(17.3189) \tNS PDE Loss:  tensor(4296.8667)\n",
      "Iteration: 42800 \tTotal Loss: tensor(3120.5054)\n",
      "\tBC Loss:  tensor(17.2997) \tNS PDE Loss:  tensor(3103.2056)\n",
      "Iteration: 43000 \tTotal Loss: tensor(4406.5254)\n",
      "\tBC Loss:  tensor(17.2844) \tNS PDE Loss:  tensor(4389.2412)\n",
      "Iteration: 43200 \tTotal Loss: tensor(3515.0737)\n",
      "\tBC Loss:  tensor(17.2745) \tNS PDE Loss:  tensor(3497.7993)\n",
      "Iteration: 43400 \tTotal Loss: tensor(3097.8206)\n",
      "\tBC Loss:  tensor(17.2588) \tNS PDE Loss:  tensor(3080.5618)\n",
      "Iteration: 43600 \tTotal Loss: tensor(4081.4409)\n",
      "\tBC Loss:  tensor(17.2447) \tNS PDE Loss:  tensor(4064.1963)\n",
      "Iteration: 43800 \tTotal Loss: tensor(3113.1792)\n",
      "\tBC Loss:  tensor(17.2340) \tNS PDE Loss:  tensor(3095.9453)\n",
      "Iteration: 44000 \tTotal Loss: tensor(4616.8550)\n",
      "\tBC Loss:  tensor(17.2166) \tNS PDE Loss:  tensor(4599.6382)\n",
      "Iteration: 44200 \tTotal Loss: tensor(5281.8145)\n",
      "\tBC Loss:  tensor(17.2099) \tNS PDE Loss:  tensor(5264.6045)\n",
      "Iteration: 44400 \tTotal Loss: tensor(7470.0854)\n",
      "\tBC Loss:  tensor(17.1977) \tNS PDE Loss:  tensor(7452.8877)\n",
      "Iteration: 44600 \tTotal Loss: tensor(4853.8018)\n",
      "\tBC Loss:  tensor(17.1896) \tNS PDE Loss:  tensor(4836.6123)\n",
      "Iteration: 44800 \tTotal Loss: tensor(3343.1499)\n",
      "\tBC Loss:  tensor(17.1693) \tNS PDE Loss:  tensor(3325.9805)\n",
      "Iteration: 45000 \tTotal Loss: tensor(4367.3726)\n",
      "\tBC Loss:  tensor(17.1560) \tNS PDE Loss:  tensor(4350.2168)\n",
      "Iteration: 45200 \tTotal Loss: tensor(5180.0674)\n",
      "\tBC Loss:  tensor(17.1376) \tNS PDE Loss:  tensor(5162.9297)\n",
      "Iteration: 45400 \tTotal Loss: tensor(4509.2856)\n",
      "\tBC Loss:  tensor(17.1277) \tNS PDE Loss:  tensor(4492.1577)\n",
      "Iteration: 45600 \tTotal Loss: tensor(8011.9893)\n",
      "\tBC Loss:  tensor(17.1089) \tNS PDE Loss:  tensor(7994.8804)\n",
      "Iteration: 45800 \tTotal Loss: tensor(3073.0652)\n",
      "\tBC Loss:  tensor(17.0992) \tNS PDE Loss:  tensor(3055.9661)\n",
      "Iteration: 46000 \tTotal Loss: tensor(3228.0127)\n",
      "\tBC Loss:  tensor(17.0878) \tNS PDE Loss:  tensor(3210.9248)\n",
      "Iteration: 46200 \tTotal Loss: tensor(5474.8833)\n",
      "\tBC Loss:  tensor(17.0809) \tNS PDE Loss:  tensor(5457.8022)\n",
      "Iteration: 46400 \tTotal Loss: tensor(4452.4087)\n",
      "\tBC Loss:  tensor(17.0668) \tNS PDE Loss:  tensor(4435.3418)\n",
      "Iteration: 46600 \tTotal Loss: tensor(4177.0640)\n",
      "\tBC Loss:  tensor(17.0541) \tNS PDE Loss:  tensor(4160.0098)\n",
      "Iteration: 46800 \tTotal Loss: tensor(4281.6943)\n",
      "\tBC Loss:  tensor(17.0360) \tNS PDE Loss:  tensor(4264.6582)\n",
      "Iteration: 47000 \tTotal Loss: tensor(6591.3892)\n",
      "\tBC Loss:  tensor(17.0214) \tNS PDE Loss:  tensor(6574.3677)\n",
      "Iteration: 47200 \tTotal Loss: tensor(5352.7100)\n",
      "\tBC Loss:  tensor(17.0059) \tNS PDE Loss:  tensor(5335.7041)\n",
      "Iteration: 47400 \tTotal Loss: tensor(5179.8657)\n",
      "\tBC Loss:  tensor(16.9912) \tNS PDE Loss:  tensor(5162.8745)\n",
      "Iteration: 47600 \tTotal Loss: tensor(4251.9351)\n",
      "\tBC Loss:  tensor(16.9770) \tNS PDE Loss:  tensor(4234.9580)\n",
      "Iteration: 47800 \tTotal Loss: tensor(4265.8525)\n",
      "\tBC Loss:  tensor(16.9636) \tNS PDE Loss:  tensor(4248.8892)\n",
      "Iteration: 48000 \tTotal Loss: tensor(3974.8582)\n",
      "\tBC Loss:  tensor(16.9504) \tNS PDE Loss:  tensor(3957.9077)\n",
      "Iteration: 48200 \tTotal Loss: tensor(4854.7021)\n",
      "\tBC Loss:  tensor(16.9380) \tNS PDE Loss:  tensor(4837.7642)\n",
      "Iteration: 48400 \tTotal Loss: tensor(3619.8018)\n",
      "\tBC Loss:  tensor(16.9272) \tNS PDE Loss:  tensor(3602.8745)\n",
      "Iteration: 48600 \tTotal Loss: tensor(3367.7090)\n",
      "\tBC Loss:  tensor(16.9126) \tNS PDE Loss:  tensor(3350.7964)\n",
      "Iteration: 48800 \tTotal Loss: tensor(5253.2319)\n",
      "\tBC Loss:  tensor(16.9047) \tNS PDE Loss:  tensor(5236.3271)\n",
      "Iteration: 49000 \tTotal Loss: tensor(2779.7710)\n",
      "\tBC Loss:  tensor(16.8957) \tNS PDE Loss:  tensor(2762.8752)\n",
      "Iteration: 49200 \tTotal Loss: tensor(3380.5383)\n",
      "\tBC Loss:  tensor(16.8847) \tNS PDE Loss:  tensor(3363.6536)\n",
      "Iteration: 49400 \tTotal Loss: tensor(3732.9824)\n",
      "\tBC Loss:  tensor(16.8740) \tNS PDE Loss:  tensor(3716.1084)\n",
      "Iteration: 49600 \tTotal Loss: tensor(4279.5684)\n",
      "\tBC Loss:  tensor(16.8638) \tNS PDE Loss:  tensor(4262.7046)\n",
      "Iteration: 49800 \tTotal Loss: tensor(3585.6230)\n",
      "\tBC Loss:  tensor(16.8490) \tNS PDE Loss:  tensor(3568.7739)\n",
      "Iteration: 50000 \tTotal Loss: tensor(6918.5513)\n",
      "\tBC Loss:  tensor(16.8389) \tNS PDE Loss:  tensor(6901.7124)\n",
      "Total Time:\t 52627.93518900871 \n",
      "Pass 1 Time:\t 26698.899261951447 \n",
      "Pass 2 Time:\t 52627.93142795563 \n",
      "Pass 3 Time:\t -1719359225.949075 \n",
      "Pass 4 Time:\t -1719359225.949075\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "\n",
    "\n",
    "#Call model of layers and its forward step\n",
    "from Forward_with_Layer_Setting import Net\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#Call training functions of Loss functions\n",
    "from NSpde_loss import lossNSpde \n",
    "from BoundaryLoss import lossBdry\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_network(IC_Only_Train):\n",
    "    \n",
    "    net = Net()\n",
    "    net = net.to(device)\n",
    "\n",
    "    #Load Training Points\n",
    "    x_domain, y_domain, t_zero, x_Bdry, y_Bdry, x_l_Bdry, x_u_Bdry, y_l_Bdry, y_u_Bdry = twoDimTrainPts(net, Domain_collocation = int(1000), Bdry_collocation = int(100))\n",
    "    \n",
    "    start = time.time()\n",
    "    '''\n",
    "    #Start Training only on IC\n",
    "    if IC_Only_Train == True:\n",
    "        print('Training Only on the Initial Condition')\n",
    "        Create_IC_Parameters(x_domain, y_domain, t_zero, 13000, 10**-3, 'IC_Only.pt', record_loss = 100, print_loss = 1000)\n",
    "        IC_Done = time.time()\n",
    "        print('IC Time:\\t', IC_Done-start)\n",
    "        return 0\n",
    "    '''    \n",
    "    time_vec = [0, 0, 0, 0]\n",
    "    \n",
    "    #Set final times for running training\n",
    "    time_slices = np.array([.01,.1]) #, .25, .5, 1\n",
    "    \n",
    "    #attempt to load IC if it exists\n",
    "    try:\n",
    "        net.load_state_dict(torch.load(\"IC_Only.pt\"))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    global epsilon #used to track loss\n",
    "    epsilon = []\n",
    "    \n",
    "    print('Training PDE')\n",
    "    \n",
    "    for i in range(2): #4\n",
    "        #Set loop to optimize in progressively smaller learning rates\n",
    "        if i == 0:\n",
    "            #First loop uses progressively increasing time intervals\n",
    "            print('Executing Pass 1')\n",
    "            iterations = 50000\n",
    "            learning_rate = 5*10**-4    \n",
    "        elif i == 1:\n",
    "            print('Executing Pass 2')\n",
    "            #time_slices = time_slices[-1]\n",
    "            iterations = 50000\n",
    "            learning_rate = 10**-4\n",
    "        elif i == 2:\n",
    "            print('Executing Pass 3')\n",
    "            iterations = 2\n",
    "            learning_rate = 10**-5\n",
    "        elif i ==3:\n",
    "            print('Executing Pass 4')\n",
    "            iterations = 2\n",
    "            learning_rate = 10**-6\n",
    "        \n",
    "        training_loop(net, x_domain, y_domain, t_zero, x_Bdry, y_Bdry, x_l_Bdry, x_u_Bdry, \n",
    "                      y_l_Bdry, y_u_Bdry, time_slices, iterations, learning_rate, IC_coefficient = 1000, record_loss = 100, print_loss = 200)\n",
    "        torch.save(net.state_dict(), f\"NNlayers_Bubble_{i}.pt\")\n",
    "        np.savetxt('epsilon.txt', epsilon)\n",
    "        time_vec[i] = time.time()\n",
    "\n",
    "    np.savetxt('epsilon.txt', epsilon)\n",
    "    \n",
    "    end = time.time()\n",
    "\n",
    "    print(\"Total Time:\\t\", end-start, '\\nPass 1 Time:\\t', time_vec[0]-start, '\\nPass 2 Time:\\t', time_vec[1]-start, '\\nPass 3 Time:\\t', time_vec[2]-start, '\\nPass 4 Time:\\t', time_vec[3]-start)\n",
    "\n",
    "\n",
    "def twoDimTrainPts(net, Domain_collocation, Bdry_collocation):\n",
    "    #Set of all the recorded xy variables as base data for chasing during training\n",
    "    \n",
    "    # Domain boundary in the range [0, 1]x[0, 2] and time in [0, 1].\n",
    "    x_l = net.x1_l\n",
    "    x_u = net.x1_u\n",
    "    y_l = net.x2_l\n",
    "    y_u = net.x2_u\n",
    "\n",
    "    #time starts at lower bound 0, ends at upper bouund updated in slices\n",
    "    t_l = 0\n",
    "\n",
    "    #Pick IC/Mv Bdry/NSpde Condition Training Random Points in Numpy\n",
    "    x_domain = np.random.uniform(low= x_l, high=x_u, size=(Domain_collocation, 1)) \n",
    "    y_domain = np.random.uniform(low= y_l, high=y_u, size=(Domain_collocation, 1)) \n",
    "    \n",
    "    #Move to pytorch tensors\n",
    "    x_domain = Variable(torch.from_numpy(x_domain).float(), requires_grad=True).to(device)\n",
    "    y_domain = Variable(torch.from_numpy(y_domain).float(), requires_grad=True).to(device)\n",
    "    \n",
    "    #Pick IC Training t starting points to make tensor\n",
    "    t_zero = Variable(torch.zeros_like(x_domain), requires_grad=True).to(device)\n",
    "\n",
    "    #Pick BC Training Random Points in Numpy\n",
    "    x_Bdry = np.random.uniform(low=x_l, high=x_u, size=(Bdry_collocation,1))\n",
    "    y_Bdry = np.random.uniform(low=y_l, high=y_u, size=(Bdry_collocation,1))       \n",
    "    \n",
    "    #Move to pytorch tensors\n",
    "    x_Bdry= Variable(torch.from_numpy(x_Bdry).float(), requires_grad=True).to(device)\n",
    "    y_Bdry = Variable(torch.from_numpy(y_Bdry).float(), requires_grad=True).to(device)\n",
    "    \n",
    "    ##Pick pts to make tensor for No-Slip Boundary Condition\n",
    "    x_l_Bdry = Variable(x_l * torch.ones_like(x_Bdry), requires_grad=True).to(device)\n",
    "    x_u_Bdry = Variable(x_u * torch.ones_like(x_Bdry), requires_grad=True).to(device)\n",
    "    y_l_Bdry = Variable(y_l * torch.ones_like(x_Bdry), requires_grad=True).to(device)\n",
    "    y_u_Bdry = Variable(y_u * torch.ones_like(x_Bdry), requires_grad=True).to(device)\n",
    "    \n",
    "            \n",
    "    return x_domain, y_domain, t_zero, x_Bdry, y_Bdry, x_l_Bdry, x_u_Bdry, y_l_Bdry, y_u_Bdry\n",
    "    \n",
    "def tsliceTrainPts(net, Domain_collocation, Bdry_collocation, final_time):\n",
    "    #Set of all the recorded t variable as base data for chasing during training\n",
    "\n",
    "    #time starts at lower bound 0, ends at upper bouund updated in slices\n",
    "    t_l = net.t_l\n",
    "\n",
    "    #Pick IC/Mv Bdry/NSpde Condition Training Random Points in Numpy\n",
    "    t_domain = np.random.uniform(low=t_l, high=final_time, size=(Domain_collocation, 1))\n",
    "    \n",
    "    #Move to pytorch tensors\n",
    "    t_domain = Variable(torch.from_numpy(t_domain).float(), requires_grad=True).to(device)\n",
    "\n",
    "    #Pick IC Training t starting points to make tensor\n",
    "    t_zero = Variable(torch.zeros_like(t_domain), requires_grad=True).to(device)\n",
    "\n",
    "    #Pick BC Training Random Points in Numpy\n",
    "    t_Bdry = np.random.uniform(low=t_l, high=final_time, size=(Bdry_collocation,1))\n",
    "    \n",
    "    #Move to pytorch tensors\n",
    "    t_Bdry = Variable(torch.from_numpy(t_Bdry).float(), requires_grad=True).to(device)\n",
    "        \n",
    "    return t_domain, t_Bdry\n",
    "    \n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "                    \n",
    "\n",
    "def training_loop(net, x_domain, y_domain, t_zero, x_Bdry, y_Bdry, x_l_Bdry, x_u_Bdry, y_l_Bdry, y_u_Bdry, time_slices, iterations, learning_rate, IC_coefficient, record_loss, print_loss):\n",
    "    global epsilon\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    #learning rate update\n",
    "    for g in net.optimizer.param_groups:\n",
    "        g['lr'] = learning_rate\n",
    "    \n",
    "    for final_time in time_slices:\n",
    "        \n",
    "        with torch.autograd.no_grad():\n",
    "            print(\"Current Final Time:\", final_time, \"Current Learning Rate: \", get_lr(net.optimizer))  \n",
    "        \n",
    "        indicator = False\n",
    "        reset_regularization = 1000\n",
    "        \n",
    "        #Iterate over these points\n",
    "        \n",
    "        t_domain, t_Bdry = tsliceTrainPts(net, Domain_collocation = int(1000), Bdry_collocation = int(100), final_time = final_time)    \n",
    "        for epoch in range(1, iterations+1):\n",
    "            # Loss calculation based on partial differential equation (PDE) \n",
    "            \n",
    "            if epoch%reset_regularization == 0:\n",
    "                indicator = False\n",
    "    \n",
    "            if epoch%reset_regularization != 0: #To detect error on forward/Backward, add hashtag on this whole line, and\n",
    "            #with torch.autograd.detect_anomaly(): #use this line alternatively by deleting hashtag.\n",
    "                \n",
    "                ###Training steps\n",
    "                # Resetting gradients to zero\n",
    "                net.optimizer.zero_grad()\n",
    "            \n",
    "                #Loss based on Boundary Condition (Containing No-Slip and Free-slip)\n",
    "                mse_BC = lossBdry(net, x_Bdry, y_Bdry, t_Bdry, x_l_Bdry, x_u_Bdry, y_l_Bdry, y_u_Bdry)\n",
    "                # Gradient Norm Clipping\n",
    "                torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm= 5*10**2, norm_type=2, error_if_nonfinite=False)\n",
    "\n",
    "                #Loss based on PDE\n",
    "                mse_NS = lossNSpde(net, x_domain, y_domain, t_domain)\n",
    "                # Gradient Norm Clipping\n",
    "                torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm= 5*10**2, norm_type=2, error_if_nonfinite=False)\n",
    "\n",
    "            \n",
    "                if indicator == False:\n",
    "                    indicator = True\n",
    "                    \n",
    "                    BC_regular = mse_BC.detach()\n",
    "                    pde_regular = mse_NS.detach()\n",
    "                    \n",
    "                \n",
    "                raw_loss =  mse_BC + mse_NS \n",
    "            \n",
    "                #mse_IC = mse_IC/IC_regular\n",
    "                #mse_BC = mse_BC/BC_regular\n",
    "                #mse_NS = mse_NS/pde_regular\n",
    "                #mse_MvBdry = mse_MvBdry/MvBdry_regular\n",
    "            \n",
    "                #Combine all Loss functions\n",
    "                loss = mse_BC + mse_NS \n",
    "            \n",
    "                loss.backward()\n",
    "            # Gradient Norm Clipping\n",
    "            torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm= 5*10**2, norm_type=2, error_if_nonfinite=False)\n",
    "\n",
    "            #Gradient Value Clipping\n",
    "            #nn.utils.clip_grad_value_(net.parameters(), clip_value=1.0)\n",
    "            net.optimizer.step()\n",
    "            \n",
    "            #Print Loss every 1000 Epochs\n",
    "            with torch.autograd.no_grad():\n",
    "                if epoch%record_loss == 0:\n",
    "                    epsilon = np.append(epsilon, raw_loss.cpu().detach().numpy())\n",
    "                if epoch%print_loss == 0:\n",
    "                    print(\"Iteration:\", epoch, \"\\tTotal Loss:\", loss.data)\n",
    "                    print(\"\\tBC Loss: \", mse_BC.data, \"\\tNS PDE Loss: \", mse_NS.data)\n",
    "\n",
    "            \n",
    "                \n",
    "\n",
    "create_network(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be064db9-312a-4337-9f2e-03e27fe51ece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32ce6a2-7126-4467-97b8-dec6b6087cf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
